namespace metax.c #:
  /# The implementation of Meta in Meta.
  /#
  /#  - This codebase is implemented in itself. That is, it defines
  /#    the Meta compiler, and the code produced by this code is what parses
  /#    this code (there is a reason the project is named Meta, after all)
  /# 
  /#  - Meta source code compiled by this code is written into
  /#    <<repository_path>>/<metalang>/<baselang>
  /#     - by convention, the notation <<var>> means something obtained from
  /#       ~/.config/metameta, and the notation <var> means something obtained
  /#       from flags.
  /#
  /#  - The top-level namespace for Meta is metax so that we can use the 
  /#    pseudovar 'meta' to refer to metaclass instance without having them hide
  /#    the namespace (if it were named 'meta' instead').
  /#
  /#  - The $METAROOT/lib/metastrap.py file is critically important to the
  /#    proper functioning of Meta, and needs to exist in PYTHONPATH.
  /#
  /#  - The python code needs to work in both python2 and python3
  /#      - see https://python-future.org/compatible_idioms.html
  /#
  /#  Life Of A MetaFile
  /#  - Create an instance of metax.c.Compiler, specifying metal and basel
  /#     - this results in Meta(Meta) and Meta(X) being parsed, for X==metal,
  /#       via Compiler.metalangNamed(), and involving bootstrapping because
  /#       they involve parsing a MetaFile.
  /#  - Invoke Compiler.parseMeta(), which
  /#     - creates a MetaFile
  /#     - invokes MetaFile.parseMeta() with a metalang-specific Context
  /#       instance.
  /#  - MetaFile.parseMeta()
  /#     - creates a copy of the passed-in Context (every MetaFile has its own
  /#       Context instance so that the Context can store the metafile and
  /#       compiler instances).
  /#     - creates a FileConstruct and associated scope:, then invokes
  /#       MetaFile.parseComplexBlock to populate that scope with the top-level
  /#       constructs in the metafile.
  /#  - MetaFile.parseComplexBlock()
  /#     - creates a ConsGroup instance representing all legal tokens within
  /#       the complex block based on the set of legal constructs within the
  /#       block.
  /#     - repeatedly parses constructs via MetaFile.parseConstruct until
  /#       an explicit or implicit end-of-block is encountered.
  /#  - MetaFile.parseConstruct()
  /#     - skips empty lines and updates precount (or postcount of parent if
  /#       last)
  /#     - consumes feature tokens until a primary key token is found
  /#     - obtains the primary attribute value handling optional values and
  /#       replacer semantics
  /#     - creates an Attribute to represent the primary attribute (do not
  /#       register)
  /#     - creates an instance of some subclass of Construct (as recording in
  /#       the ConsInfo associated with the primary key token), registering into
  /#       parent scope.
  /#     - validate legality of all previously parsed feature tokens now that
  /#       we've identified the construct, create FeatureAttribute instances and
  /#       register them in the newly created construct.
  /#     - register the primary attribute created above
  /#     - iterate until an explicit or implicit end of construct is found,
  /#       invoking MetaFile.parseSecondaryAttribute() to create and register
  /#       secondary attributes with the construct.
  /#  - MetaFile.parseSecondaryAttribute()
  /#     - Obtain the secondary key (handling autokey semantics) by invoking
  /#       MetaFile.peekSecondaryToken()
  /#     - Detect end-of-construct terminator and return special values
  /#     - Create an instance of a subclass of Attribute based on the value type
  /#       of the attribute BEFORE we have parsed the value (all Attribute
  /#       subclasses must handle a null value)
  /#     - Perform type-specific parsing of the secondary attribute value.
  /#     - Set the value of the Attribute instance created above.
  /#     - The termcode of the passed-in construct instance is changed from
  /#       TERM_UNINIT to 0<=<16 if a terminator (implicit or explicit) is
  /#       found.
  /#
  /#   - More notes:
  /#    - Every time ${file}.meta file is compiled:
  /#      - the file .${file}.${suffix}.files is created, containing all of the
  /#        files generated during compilation.  Used to detect old files that
  /#        should be deleted because of changes in the .meta file.
  /#      - if ./.meta does not exist, it is made a symlink to
  /#        <<repository_path>>
  /#      - for every namespace nm.sp defined within ${file}.meta
  /#         - for every class C defined within nm.sp
  /#            - ./.meta/oopl/${baselang}/nm/sp/${C}.${suff} is created
  /#              (except when ${suff} is 'py', in which case
  /#               ./.meta/oopl/${baselang}/nm/sp/.${C}.py is created,
  /#               and ./.meta/oopl/${baselang}/nm/sp/__init__.py merges all
  /#               classes into a python module aka meta namespace).
  /#
  /#  VARIABLE CONVENTIONS:
  /#  - basel = the id of a base language
  /#  - metal = the id of a meta language
  /#  - baselang = a BaseLanguageConstruct instance
  /#  - metalang = a MetaLanguageConstruct instance
  /#  - cons = the id of a construct
  /#  - kind = the kind of a construct
  /#  - construct = a Construct instance
  /#  - attribute = an Attribute instance
  /#  - metafile = a MetaFile instance
  /#  - metac = a Compiler instance
  /#
  /#  IMPORTANT:
  /#
  /#   - This code should have ZERO direct dependence on any baselang I/O
  /#     functionality (e.g. in python, no dependence on 'os', 'glob', 'shutil',
  /#     'tempfile', etc. All such funtionality is wrapped in
  /#     metax.fs.Filesystem, and one should always use compiler.fs().* to
  /#     perform I/O.
  /#
  /#  NEW IDEAS:
  /#
  /#   - No tests: block on namespace or class. Instead, a class can be marked
  /#     as 'test' or 'user' within namespaces, and a method/field can be marked
  /#     as 'meta', 'test' or 'user' within a class.
  /#
  /#   - The same token can be both a feature value and secondary key (but same
  /#    token cannot be both a feature value and feature key, and all feature
  /#    values across all feature keys in a construct must be unique).
  /#
  /#   - The same token can be both a construct kind (aka primary key) and a
  /#    secondary key (for a different construct), but no feature key or feature
  /#    value can be the same as a construct kind.
  /#
  /#   - Support for non-indenting scope blocks;
  /#
  /#           namespace nm.sp scope >>
  /#           class Person scope >>
  /#           method f : int >>
  /#             ...
  /#           end method f;
  /#           end class Person;
  /#           end namespace nm.sp;
  /#
  /#     All complex blocks besides scope still require indenting, which
  /#     suggests we should minimize the occurrence of such blocks. The 'config'
  /#     and 'comment' blocks stay, but maybe we should favor constructs within
  /#     scope: over other complex-valued secondary attributes? e.g. Should we
  /#     move the 'run' attribute to a 'run' construct?
  /#
  /#     An alternative to the above approach would be to support constructs
  /#     at higher levels and implicitly insert them. Better approach!
  /#
  /#           namespace nm.sp scope;
  /#           class Person;
  /#
  /#           method f : int scope:
  /#             ...
  /#           end method f;
  /#
  /#     In the above
  /#       - 'class' is allowed to appear at File level, and is implicitly
  /#         added to the preceding 'namespace'.
  /#       - 'method' is allowed to appear at class level, and is implicitly
  /#         added to the preceding 'class'.
  /#       - In Meta(Doc):
  /#           h1 title "Part1";
  /#           h2 title "Sub1";
  /#           h2 title "Sub2";
  /#           h1 title "Part2";
  /#         we can determine whether a section is to be inserted into the
  /#         preceeding one or added as a sibling based on level.
  /#          - Sub1 is added in Part1
  /#          - Sub2 is NOT added inside Sub1, but rather Part1
  /#          - Part2 is NOT added inside Part1, but rather the parent File.
  /#
  /# Implementation notes (add keywords here to find when searching):
  /#  - implicit field value initialization in initializers occurs in
  /#    BaseLanguageOopl.initCode()
scope:

  class Error < metax.root.Error;

  nometanotest
  class InternalError < Error;

  nometanotest
  class InvalidType < Error;

  nometanotest
  class MissingConstruct < Error;

  nometanotest
  class MissingAttribute < Error;

  nometanotest
  class UnusedException < Error;

  nometanotest
  class InvariantViolated < Error;

  nometanotest
  class InvalidAttributeType < Error;

  nometanotest
  class ConflictingFeatureValues < Error;

  native #:
    These are currently required because Meta is not properly parsing
      params:
        var default : any = metax.c.REQUIRED;
    Only the 'Meta' is being parsed, and the '.REQUIRED' is being silently
    ignored.
  scope:
    ERROR = -1234567891
    REQUIRED = -1234567892
    LOOKUP = -1234567893
    SPECIAL = -1234567894
    EMPTY = -1234567895
    SELF = -1234567896

    /# What to store in termcode when the terminator has not yet been
    /# initialized.
    /#  - this is different from '0', which means "verified that terminator is
    /#    implicit"
    /#  - this used to be -1, but we want to pack termcode and termline together
    /#    so we avoid negative numbers at least until field packing exists and
    /#    supports negative numbers (if we decide to allow them in packed
    /#    fields).
    TERM_UNINIT = 16
    SUFFIX = '.meta'
    SPECIAL_PREFIX_RE = re.compile(r'^\s*>\|')
    SPECIAL_PREFIX_RE2 = re.compile(r'^\s*>\|(?P<line>.*)')
    SPECIAL_CHILD_DIR = '.meta'
    INTERPOLATION_RE = re.compile(r'\$\{\"(?P<varstr>[^\"]+)\"\}')
    VAR_RE = re.compile(r'\$\{(?P<var>[^\}]+)\}')

    /# Must be something that cannot conflict with a sub-namespace or class.
    /# IMPORTANT: This is hardcoded in root.meta! CODETANGLE(resource_dir)
    RESOURCES_SUBDIR = '.__resources'
    /# See https://www.python.org/dev/peps/pep-3147/ for a discussion of what
    /# __pycache__ is for.
    PYCACHE = '__pycache__'

    METAX_CMD_NAME = 'MetaxCLI'
    METAX_ENTRY_NAME = 'MetaxEntry'

    /# The following is used to identify whether a given path represents a
    /# Meta source file or not:
    /#  - if match files, not a meta source file, else:
    /#  - group 'base' will contain the non-suffix portion of the meta path
    /#    (which will be a full path if the input path was full, and will be
    /#    a basename without suffix if the input was a basename).
    /#  - group 'metasuffix' contains the portion of the suffix AFTER '.meta'.
    /#     - should be empty or a baselang name or abbrev
    /#     - may be legacy value '2'
    /#     - using (?P<metasuffix>\S+) is problematic because it matches
    /#       against something like wmh.metastr.Banner in a command like
    /#         % metac run wmh.metastr.Banner
    /#     - in general, we probably want the regexp to be very specific
    /#       rather than being quite general.
    /#     - we may want to provide a means of distinguishing between
    /#         file.metacc   <--- baselang within Meta(Oopl)
    /#         file.metadoc  <--- a generic file in Meta(Doc)
    /#       we have been assuming that
    /#         file.meta
    /#       is a Meta(Oopl) doc, but do we want to support 
    /#         file.metaoopl
    /#       and what about
    /#         file.metaooplpy
    /#         file.metadochtml
    SUFFIX_RE = re.compile(
      '(?P<base>(?:\S+/)?[^.]+)\.meta(?P<metasuffix>[a-z]*)$')

    /# TODO(wmh): Move this someplace better!
    def PathFromMeta(metapath, suffix):
      """Convert a legal meta source path to some other suffixed path."""
      m = SUFFIX_RE.match(metapath)
      if not m:
        raise Error('Path "%s" is not a legal meta source file.' % metapath)
      result = m.group('base') + suffix
      return result

    /# Provide a means of debugging control flow.
    D = metax.logs.SimpleLogs({
      'parse': 0,
      /# expand tracks expandMeta:
      /#  - set to 1 to see the overall flow of expandMeta() calls.
      /#  - set to 2 to see more details
      'expand': 0,
      'imports': 0,
      'translate': 0,
      'compile': 0,
    })

    /# TODO(wmh): Move this someplace cleaner. For example, metax.logs.
    def dsep(
      title='', end=False, prefix=False, width=80, delim='#', subtitle=None,
      fp=sys.stdout
    ):
      """Print a named start/end separator

      Args:
        title: str
          The title/name of the separator
        end: bool
          If true, this is the end separator (else start).
        prefix: bool
          If true, add a 'Start' or 'End' prefix to title based on 'end'
        width: int
          How many chars total in the separator
        delim: str
          The char to use in the separator.
        subtitle: str
          What to print on a separate line below the separator.
        fp: file
          Where to write the separator.

      Returns: str
      """
      if title:
        if prefix:
          p = 'End  ' if end else 'Start'
          inside = ' ' + prefix + ' ' + title + ' '
        else:
          inside = ' ' + title + ' '
      else:
        inside = ''
      dsize = width - len(inside)
      if dsize < 0:
        fp.write(inside + '\n')
      else:
        left = dsize // 2
        fp.write('%s%s%s\n' % (delim * left, inside, delim * (dsize - left)))
      if subtitle:
        fp.write(subtitle + '\n')
  end native;

  class Line #:
    A single line of a Meta file.

    This is a (start,end) pair within the entire file contents.
  assocs:
    cls assoc metax.logs.SimpleLogs;
  scope:

    field text : str #:
      The string representing entire file.
    field start : int #:
      Index within contents of start of line
      Invariant: start == 0 or contents[start-1] == '\n'
    field end : int #:
      Index within contents of end of line.
      Invariant: contents[end] == '\n'
    field num : int #:
      The line number of this line (starting from 1)
    field indent : int #:
      How many spaces between start and first non-space character on line.
      If end == start+1, indent is 0.

    lifecycle params:
      var text -> text;
      var start -> start;
      var end -> end;
      var num -> num;
      var indent -> indent;
    scope:
      assert text[end] == '\n'
      if start > 0:
        assert text[start-1] == '\n'
    setup:
      text = (
        'class Person scope:\n'
        '  field name : str;\n'
        '\n'
        'end class;\n'
      )
      self.text = text
      lines = metax.c.Line.FromText(text)
      self.line = lines[0]
      self.line2 = lines[1]
      self.line3 = lines[2]
      self.line4 = lines[3]
    test:
      test.iseq(0, test.line.indent())
      test.iseq(2, test.line2.indent())
      test.iseq(0, test.line3.indent())
      test.iseq(0, test.line4.indent())
    end;

    method line : str #:
      The full line (including indent, excluding newline) unless start
      is provided as an offset.
    params:
      var start : int = -1 #:
        First position to return. If negative, uses self._start. Note that this
        is absolute (i.e. relative to text, not the current line).
    scope:
      if start < 0:
        start = self._start
      return self._text[start:self._end]
    test:
      test.iseq('class Person scope:', test.line.line())
      test.iseq('  field name : str;', test.line2.line())
      test.iseq('name : str;', test.line2.line(start=28))
    end method line;

    method empty : bool #:
      Returns true if line contains only whitespace.
    scope:
      return self._start + self._indent == self._end
    test:
      test.isfalse(test.line.empty())
      test.isfalse(test.line2.empty())
      test.istrue(test.line3.empty())
    end method empty;

    method inblock : bool #:
      Returns true if this line is in the block with a given indent.
    params:
      var indent : int #:
        Only a line whose indent is greater-equal this value, or that is
        empty, is considered in block.
    scope:
      return self._indent >= indent or self.empty()
    test:
      test.isfalse(test.line.inblock(2))
      test.istrue(test.line2.inblock(2))
      test.istrue(test.line3.inblock(2))
      test.isfalse(test.line4.inblock(2))
    end method inblock;

    method asStr : str #:
      String representation of this instance.
    scope:
      return '%4d:%2d:%s' % (
        self.num(), self.indent(), self.text()[self.start():self.end()])
    test:
      test.iseq('   1: 0:class Person scope:', test.line.asStr())
      test.iseq('   2: 2:  field name : str;', test.line2.asStr())
      test.iseq('   3: 0:', test.line3.asStr())
    end method asStr;

    meta
    method FromText : vec<Line> #:
      Obtain a list of Line instances given text of a metafile.
    params:
      var text : str;
    scope:
      result = []
      n = len(text)
      start = 0
      num = 0
      while True:
        /# Parse a single line of text.

        /# Establish amount of intentation in this line.
        indent = 0
        while text[start + indent] == ' ':
          indent += 1

        /# Scan to end of line.
        i = start + indent
        while text[i] != '\n':
          i += 1

        /# Create a Line instance.
        num += 1
        line = cls(text, start, i, num, indent)
        result.append(line)

        /# Prepare for parsing next line.
        i += 1
        if i >= n: break
        start = i

      return result
    test:
      /# TODO(wmh): This is an example of where having tests for meta methods
      /# be defined in a separate (meta) class is problematic ... the TestCase
      /# class and all of its initialized state is not available to this
      /# method.
      text = 'class Person scope:\n  field name : str;\n'
      lines = metax.c.Line.FromText(text)
      test.iseq(2, len(lines))
      test.iseq('   2: 2:  field name : str;', lines[1].asStr())
    end method FromText;

  end class Line;

  class SymbolTable #:
    Maintain a collection of symbol/construct mappings, supporting inheritance.
  scope:

    field construct : Construct #:
      The construct that owns this symboltable.
      TODO(wmh): This should be a weak reference.

    field parent : SymbolTable #:
      The parent symboltable. NamespaceConstructs have a null parent in their
      symbol table, but ClassConstruct symbol tables reference the symbol table
      of their namespace, MethodConstruct symbol tables reference the
      symbol table of their class, and statement constructs that introduce
      lexical blocks (loop, switch, etc.) reference their parent symtables).

    field symbols : @map<str,map> #:
      Maps symbol name to symbol data. The data is a map with keys:
        construct: Construct
          May be a VarConstruct, a MethodConstruct, a ClassConstruct, or a
          a NamespaceConstruct.
        source: Construct
          Where the symbol was obtained from
        note: str (optional)
          Human-readable notes about the symbol

    lifecycle params:
      var construct -> construct;
      var parent -> parent;
    scope:
    setup:
      test.defineClassAndMethods('py')
      TypeInst = metax.c.Type.Instance

      context = test.context

      /# Namespace symbol tables contain:
      /#  - symbols for each class defined within the namespace.
      /#  - symbols of dependent namespaces.
      test.ntable = metax.c.SymbolTable(test.namespace, None)
      test.ntable.register(test.klass.id(), test.klass)

      /# Class symbol tables contain:
      /#  - methods defined on them (user classes have user methods,
      /#    meta classes have meta methods)
      /#  - fields defined on them (user classes have user fields,
      /#    meta classes have meta fields). The raw field name is stored.
      /#
      /# This symbol table is used when establishing what symbols are legal
      /# at a call-site whose receiver is of class type C ... only symbols
      /# in the symbol table of C are legal.
      test.ctable = metax.c.SymbolTable(test.klass, test.ntable)
      test.ctable.register(test.method.id(), test.method)
      test.ctable.register(test.method2.id(), test.method2)
      test.ctable.register(test.initializer.id(), test.initializer)

      /# Method symbol tables contain:
      /#  - all parameters
      /#  - all local variables not within lexically scoped blocks.
      /#  - the special receiver pseudovar ('self' or 'test' or 'meta')
      /#  - (not?) meta-level fields/methods within user-level class method.
      /#  - DOES NOT inherit from class symboltable directly (indirectly
      /#    via the special receiver pseudovar).
      /#
      /# This symbol table is used when resolving variable references within
      /# method scope (e.g. default values of params, super args, local vars,
      /# etc.). If we have:
      /#     method f params:
      /#       var a : int = b;
      /#     super (a, C)
      /#     scope:
      /#       var f : int = g;
      /#     end;
      /# we need to be able to "see" variables 'b', 'C' and 'g' from the method
      /# symbol table in order for the syntax to be legal.
      test.mtable = metax.c.SymbolTable(test.method, None)
      test.mtable.register(
        'height',
        metax.oopl.VarConstruct.NewFromData(
          'height', context, termcode=1,
          secondaries=[(':', TypeInst('real'))]))
      test.mtable.register(
        'name',
        metax.oopl.VarConstruct.NewFromData(
          'name', context, termcode=1,
          secondaries=[(':', TypeInst('str'))]))
      test.mtable.register(
        'self',
        metax.oopl.VarConstruct.NewFromData(
          'self', context, termcode=1,
          secondaries=[(':', TypeInst(test.klass.fqn()))]))
    end;

    method allSymbols : map<str,Construct> #:
      All symbols transitively visible within this table.
    scope:
      result = {}
      table = self
      while table is not None:
        symbols = table.symbols()
        for symbol, data in symbols.items():
          if symbol not in result:
            result[symbol] = data
        table = table.parent()
      return result
    test:
      test.iseqvec(
        ['Card'],
        sorted(test.ntable.allSymbols().keys()))
      test.iseqvec(
        ['Card', '__init__', 'f', 'show'],
        sorted(test.ctable.allSymbols().keys()))
      test.iseqvec(
        ['height', 'name', 'self'],
        sorted(test.mtable.allSymbols().keys()))
    end method allSymbols;

    method findInfo : map #:
      Resolve a symbol into its associated map. See field symbols for details.
    params:
      var symbol : str #:
        The symbol to resolve.
    scope:
      result = None
      table = self
      while result is None and table:
        result = table.symbols().get(symbol, None)
        table = table.parent()
      return result
    test:
      test.iseq('height', test.mtable.findInfo('height')['construct'].id())
      test.iseq('f', test.ctable.findInfo('f')['construct'].id())
      test.iseq('Card', test.ctable.findInfo('Card')['construct'].id())
      test.isnull(test.ctable.findInfo('not-a-symbol'))
    end method findInfo;

    method find : Construct #:
      Resolve a symbol into its associated construct.
    params:
      var symbol : str #:
        The symbol to resolve.
    scope:
      result = None
      table = self
      while result is None and table:
        result = table.symbols().get(symbol, None)
        table = table.parent()
      return result['construct'] if result else None
    test:
      test.iseq('height', test.mtable.find('height').id())
      test.iseq('f', test.ctable.find('f').id())
      test.iseq('Card', test.ctable.find('Card').id())
      test.isnull(test.ctable.find('not-a-symbol'))
    end method find;

    method register #:
      Register a symbol with this table.
    params:
      var symbol : str #:
        The symbol name.
      var construct : Construct #:
        The construct associated with the symbol.
      var source : Construct = null #:
        Where this symbol is defined.  This param is almost always null,
        because self.construct() is almost always the value to use.
      var note : str = null #:
        Any human-readable notes associated with the symbol.
    scope:
      symbols = self.symbols()
      if symbol in symbols:
        raise Error(
          'Attempt to re-register %s within %s' %
          (symbol, self.construct().kindfqn()))
      if source is None:
        source = self.construct()
      data = {'construct': construct, 'source': source}
      if note:
        data['note'] = note
      symbols[symbol] = data
    test:
      /# register was called in setup.
      test.iseq(3, len(test.mtable.symbols()))
    end method register;

    method show #:
      Print out a symbol table
    params:
      var fp : ostream = out #:
        Where to write output
      var indent : str = '' #:
        Indentation before each line of output.
      var full : bool = false #:
        If true, show inherited symbols too.
      var width : int = -1 #:
        The amount of space reserved for symbol names in output.
        If negative, width of longest symbol is used.
    scope:
      construct = self.construct()
      symbols = self.allSymbols() if full else self.symbols()
      subindent = indent + '  '
      fp.write(u'%sSymbolTable for %s:\n' % (indent, construct.kindfqn()))
      if symbols:
        if width < 0:
          width = max([len(s) for s in symbols])
        for symbol in sorted(symbols):
          data = symbols[symbol]
          construct = data['construct']
          location = u' (%s)' % data['source'].kind() if full else ''
          notestr = data.get('note', None)
          note = ' [%s]' % notestr if notestr else ''
          fp.write(
            u'%s%s = %s%s%s\n' %
            (subindent, symbol.ljust(width), construct.kindfqn(), location,
             note))
      else:
        fp.write(u'%s  empty\n' % indent)
    test:
      fp = test.fp()
      test.mtable.show(fp=fp, width=20)
      test.mtable.show(fp=fp, full=True, width=20)
      test.ctable.show(fp=fp)
      test.ctable.show(fp=fp, full=True)

      test.iseqtext(
        >|"""SymbolTable for method nm.sp.Card.show:
        >|  height               = var height
        >|  name                 = var name
        >|  self                 = var self
        >|SymbolTable for method nm.sp.Card.show:
        >|  height               = var height (method)
        >|  name                 = var name (method)
        >|  self                 = var self (method)
        >|SymbolTable for class nm.sp.Card:
        >|  __init__ = method nm.sp.Card.__init__
        >|  f        = method nm.sp.Card.f
        >|  show     = method nm.sp.Card.show
        >|SymbolTable for class nm.sp.Card:
        >|  Card     = class nm.sp.Card (namespace)
        >|  __init__ = method nm.sp.Card.__init__ (class)
        >|  f        = method nm.sp.Card.f (class)
        >|  show     = method nm.sp.Card.show (class)
        >|""",
        test.out())
    end method show;

  end class SymbolTable;

  class ExprParser #:
    Parses expressions of the following forms:
     - num        : [-+0-9]
     - id         : [a-zA-Z_]
     - paren      : '(' ... ')'
       - plist
       - bool
     - str        : ' or \"
     - list       : '['
     - hash       : '{'
     - call       : '@'
     - unit       : '<' ... '>'
  assocs:
    std assoc re;
    std test assoc pprint;
    lib assoc metax.units;
  scope:

    field source : MetaFile #:
      The MetaFile within which the expr resides.
    field row : int #:
      The line with source of the current position within the expr (from 0).
    field col : int #:
      The index within current row of the current position in the expr (from 0).
    field start : tuple<int,int> #:
      The row/col of the start of the expr.
    field errors : @vec<str> #:
      The collection of errors encountered during parsing.
    field line : str #:
      This is source[row].  If null, it means EOF has been reached.
    field terms : @vec<str> #:
      Maintains the list of terminators during recursive parsing of nested
      expressions like list, plist and hash.

    lifecycle params:
      var source -> source;
      var row -> row = 0;
      var col -> col = 0;
    scope<py>:
      assert isinstance(source, MetaFile)

      self.startIs((row, col))
      self.terms().append(';')
      self.set(row=row, col=col)
    clinit:
      /# Map chars to functions for parsing exprs identified by the char.
      cmap = {}
      cls.CharMap = cmap
      cmap['@'] = cls._parseCall
      cmap['('] = cls._parseParen
      cmap['<'] = cls._parseUnit
      cmap['{'] = cls._parseHash
      cmap['['] = cls._parseList
      cmap['\"'] = cls._parseStr
      cmap["'"] = cls._parseStr
      cmap['-'] = cls._parseNum
      cmap['+'] = cls._parseNum
      for i in range(ord('0'), ord('9')+1):
        cmap[chr(i)] = cls._parseNum
      cmap['_'] = cls._parseVar
      for i in range(ord('a'), ord('z')+1):
        cmap[chr(i)] = cls._parseVar
      for i in range(ord('A'), ord('Z')+1):
        cmap[chr(i)] = cls._parseVar

      cls.TERMCHARS = list(',;)]}')

      cls.LEGAL_OP_CHARS = frozenset(list('+-*/%=!<>|&^~'))

      cls.BOOL_OP_RE = re.compile(r'^(?P<op>and|or|<|<=|>|>=|==)(?P<after>.)')

      /# NOTE: ExprParser._parseNum() relies on NUM_RE not being fixed at the
      /# end (e.g. do not add a '$').
      /#  - TODO(wmh): Why is it necessary to not fix? That is resulting in it
      /#    not matching properly if we change '(?:0|[1-9]\d*)' to
      /#    '(?:0?|[1-9]\d*)'
      cls.NUM_RE = re.compile(
        r'^([+-]?(?:0|[1-9]\d*))((?:\.\d*)?)(?:[eE]([-+]?\d+))?')

      cls.ENUM_RE = re.compile(r'^(?P<sep>[^<>]?)<(?P<spec>.*)>$')

      cls.ID_PREFIX_RE = re.compile(
        r'(?P<meta>meta!|!)?(?P<id>[a-zA-Z_][a-zA-Z0-9_]*)')

      cls.ID_RE = re.compile(
        /# TODO(wmh): Remove the 'meta!' and '!' clauses ... not needed in v2?
        r'^(?P<meta>meta!|!)?'
        r'(?P<id>[a-zA-Z_][a-zA-Z0-9_]*)'
        /# The :get notation is a hack to allow method ids to end with :get.
        /# A workaround for the fact that field constructs generate a
        /# getter with the same name, but Meta does not allow the same id
        /# to appear in the same scope.  We distinguish with :get and strip
        /# off the :get when we go to generate code. In the interests of
        /# consistency, we suffix setters and reffers similarly although they
        /# do not have the same name conflict as getters. It may, however,
        /# be useful to distinguish between fooIs (a user-provided method)
        /# and fooIs:set (a auto-generated setter for a user-provided field).
        r'(?:[:](?P<spec>get|set|ref))?$')

      cls.XID_RE = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_.]*$')
    end;

    method numrows : int #:
      Number of rows in source.
    scope:
      return len(self.source().lines())
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq(3, eprs.numrows())
    end method numrows;

    method pos : tuple<int,int,char> #:
      Returns current row, col and char
    scope:
      return (self.row(), self.col(), self.peek())
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq((0, 0, 'a'), eprs.pos())
      eprs.set(row=2, col=1)
      test.iseq((2, 1, 'd'), eprs.pos())
    end method pos;

    method current : tuple<str,int> #:
      The current row text and index within that row. Same semantics as is
      returned by skipws().
    scope:
      return (self.line(), self.col())
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq(('a \n', 0), eprs.current())
      eprs.set(row=2, col=1)
      test.iseq(('cd\n', 1), eprs.current())
    end method current;

    method peek : char #:
      Return the current character without advancing.
    scope:
      return self.line()[self.col()]
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq('a', eprs.peek())
      eprs.set(row=2, col=1)
      test.iseq('d', eprs.peek())
    end method peek;

    method getc : char #:
      Obtain current char and advance to next.
    scope:
      line, col = self.current()
      result = line[col]
      if result == '\n':
        /# Advance to next line
        row = self.row()
        row += 1
        numrows = self.numrows()
        if row >= numrows:
          /# EOF
          self.rowIs(-1)
          self.lineIs(None)
        else:
          self.set(row=row, col=0)
      else:
        self.colIs(col + 1)
      return result
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq('a', eprs.getc())
      test.iseq(' ', eprs.getc())
      test.iseq('\n', eprs.getc())
      test.iseq('b', eprs.getc())
      test.iseq('\n', eprs.getc())
      test.iseq('c', eprs.getc())
      test.iseq('d', eprs.getc())
      test.iseq('\n', eprs.getc())
      test.isnull(eprs.line())
    end method getc;

    method set #:
      Set row and/or col.  If row is specified by col is not, col is set to 0
      (start of new row).

      Any attempt to map source()[row] to a string of text should go thru
      this method, so that we have a single place to abstract away the
      exact implementation of source(). In old code, it is a list of Line,
      although the new test code assumes a list of str. We will need to decide
      how to represent the lines as we migrate to Meta.
    params:
      var row : int = -1;
      var col : int = -1;
    scope:
      if row >= 0:
        self.rowIs(row)
        newline = self.source().lines()[row].line() + '\n'
        self.lineIs(newline)
        if col < 0:
          col = 0
      if col >= 0:
        self.colIs(col)
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq((0, 0, 'a'), eprs.pos())
      eprs.set(row=2, col=1)
      test.iseq((2, 1, 'd'), eprs.pos())
    end method set;

    method reset #:
      Return this eprs to its state upon first being created. e.g. not parsed,
      row and col at start row/col.
    scope:
      srow, scol = self.start()
      self.rowIs(srow)
      self.colIs(scol)
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 'a \nb\ncd\n'), row=2, col=1)
      eprs.set(row=0, col=0)
      test.iseq((0, 0, 'a'), eprs.pos())
      eprs.reset()
      test.iseq((2, 1, ' '), eprs.pos())
    end method reset;

    method summary #:
      Print out a summary of current state of expr.
    params:
      var fp : ostream = out #:
        Where to write summary.
      var verbose : bool = false #:
        If true, print out all source lines, otherwise print out the 5 lines
        before and after the current line.
    scope:
      start = self.start()
      crow, ccol, _ = self.pos()
      fp.write(
        'ExprParser starts at R%dC%d, currrently at R%dC%d seeing "%s"\n' %
        (start[0], start[1], self.row(), self.col(),
        self.peek().replace(u'\n', u'\\n')))

      nrows = self.numrows()
      start = 0 if verbose else max(0, self.row() - 5)
      end = nrows if verbose else min(nrows, self.row() + 5)
      for row in range(start, end):
        /# We use set() here so that we have a single place within which to
        /# abstract away details about the exact structure of 'source'.
        self.set(row=row)
        fp.write(u'  [%3d] %s' % (row, self.line()))
      fp.write(u'        ' + '0123456789' * 7 + '\n')

      errors = self.errors()
      if errors:
        fp.write('ERRORS:\n')
        for e in errors:
          fp.write(u'  ' + e + '\n')

      /# Reinstate position we entered this method at.
      self.set(row=crow, col=ccol)
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))

      fp = test.fp()
      eprs.summary(fp=fp, verbose=False)
      test.startswith(
        'ExprParser starts at R0C0, currrently at R0C0 seeing "a"',
        fp.getvalue())

      eprs.set(row=2, col=1)
      fp = test.fp()
      eprs.summary(fp=fp, verbose=False)
      test.startswith(
         'ExprParser starts at R0C0, currrently at R2C1 seeing "d"',
         fp.getvalue())
    end method summary;

    method error #:
      Record an error during parsing
    params:
      var msg : str;
      var attribute : metax.attr.Attribute = null;
    scope:
      /# TODO(wmh): Support attributes (more meaningful data in metafile
      /# output).
      self.errors().append('R%dC%d: %s' % (self.row(), self.col(), msg))
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.iseq([], eprs.errors())
      eprs.error('This is a test')
      test.iseq(['R0C0: This is a test'], eprs.errors())
    end method error;

    method clearErrors #:
      Remove all recorded errors.
    scope:
      self.errorsIs([])
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      eprs.error('error1')
      eprs.error('error2')
      eprs.error('error3')
      test.iseq(3, len(eprs.errors()))
      eprs.clearErrors()
      test.iseq(0, len(eprs.errors()))
    end method clearErrors;

    method errorText : str #:
      A string containing all reported errors.
    scope:
      return '\n'.join(self._errors) if self._errors else None
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'a \nb\ncd\n'))
      test.isnull(eprs.errorText())
      eprs.error('this is an error')
      test.iseq('R0C0: this is an error', eprs.errorText())
      eprs.error('this is a second error')
      test.iseq(
        'R0C0: this is an error\n'
        'R0C0: this is a second error',
        eprs.errorText())
    end method errorText;

    method skipws : tuple<str,int> #:
      Advance past whitespace.

      Returns:
       [0] the current line
       [1] the current column within the current line
    params:
      var nonl : bool = false #:
        If True, stop if newline encountered.
    scope:
      done = False
      line, i = self.current()
      n = len(line)
      while i < n:
        c = line[i]
        if c == ' ':
          /# advance past
          i += 1
        elif c == '\n':
          if nonl:
            /# We are not to advance past newlines
            break
          else:
            /# advance to next line and continue
            self.colIs(i)
            assert self.getc() == '\n'
            line = self.line()
            if line is None:
              /# We are at EOF
              done = True
              break
            n = len(line)
            i = 0
        else:
          /# Non-whitespace ... stop.
          break
      self.colIs(i)
      return (self.line(), self.col())
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(
          None, None, 'abc\n  def   more \n      \n  \n   abc\n'))

      /# Test normal skipping
      eprs.skipws()
      test.iseq((0, 0, 'a'), eprs.pos())
      eprs.set(row=1)
      test.iseq(('  def   more \n', 2), eprs.skipws())
      test.iseq((1, 2, 'd'), eprs.pos())
      eprs.set(1, 5)
      test.iseq(('  def   more \n', 8), eprs.skipws())
      test.iseq((1, 8, 'm'), eprs.pos())
      eprs.set(1, 12)
      test.iseq(('   abc\n', 3), eprs.skipws())
      test.iseq((4, 3, 'a'), eprs.pos())

      /# Test nonl=True
      eprs.set(row=2)
      test.iseq(('      \n', 6), eprs.skipws(nonl=True))
      test.iseq((2, 6, '\n'), eprs.pos())
    end method skipws;

    method text : str #:
      Obtain text in a specified region.
    params:
      var srow : int #:
        start row
      var scol : int #:
        start col
      var erow : int #:
        end row (inclusive)
      var ecol : int #:
        end col (inclusive!)
    scope:
      result = ''
      metafile = self.source()
      lines = metafile.lines()
      text = metafile.text()
      start = lines[srow]
      end = lines[erow]
      result = text[start.start() + scol:end.start() + ecol + 1]
      return result
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 'a lad had a fall\nin the hall\nwith a keg\n'))

      test.iseq('lad had', eprs.text(0, 2, 0, 8))
      test.iseqtext('lad had a fall\nin the ha', eprs.text(0, 2, 1, 8))
      test.iseqtext(
        'lad had a fall\nin the hall\nwith a ke', eprs.text(0, 2, 2, 8))
    end method text;

    method parse : Expr #:
      Parse this expression.

      Invariants:
       - self.current() is the index of self.line() at which to start. This
         character be be whitespace (it is consumed initially)
       - upon return, self.current() will usually be exactly one char past
         the end of the expression (e.g. it may be on whitespace, which is
         not consumed at the end of this method).

      Returns:
        null is returned in two situations:
          1) If an error occurs during parsing (errors are writting to
             self.errors())
          2) If an end-of-expression character is seen after initial white
             space has been consumed. This is most commonly seen if there is
             a trailing comma after the last element in a list, plist or hash.
        One can distinguish between the above two situations by checking whether
        self.errors() has any elements.

        Otherwise, returns an Expr instance.
    params:
      var nonl : bool = false #:
        If true, do not go past newline
      var attribute : Attribute = null #:
        The attribute that this Expr is associated with. Currently optional,
        but may become required. Useful in some situations for deciding how
        to interpret syntax. For example, an expression starting with '('
        can be either a plist, or a boolexpr. The only usecase for plist is
        the 'super' attribute, so knowing the attribute would allow us to
        efficiently determine which parsing method to use if '(' is seen.
    scope:
      result = None
      terms = self.terms()

      /# Skip whitespace
      line, i = self.skipws(nonl=nonl)
      c = line[i]
      func = ExprParser.CharMap.get(c, None)

      if c == '\n':
        /# Only possible if nonl is true, and means we failed to find an
        /# expression
        self.error('No expression found on this line')
        result = None

      elif c == terms[-1]:
        /# We are currently parsing a complex expression that is terminated
        /# when character c is encountered.
        result = None

      elif func is False:
        /# This is special indicator informing us that 'c' represents an
        /# end-of-expression character.  This commonly occurs when a trailing
        /# comma apears after the last element in a plist, list or hash.
        /# It is not an error ... we just indicate that we are done parsing
        /# the multi-valued expression by returning None to the caller.
        result = None

      elif func:
        /# line[i] is a non-whitespace char that uniquely identifies the
        /# expression to parse.

        /# Establish the kind of expr being parsed.
        fname = func.func_name if sys.version_info.major < 3 else func.__name__
        assert fname.startswith('_parse')
        kind = fname[6:].lower()

        /# Remember where this expression starts.
        srow, scol, _ = self.pos()

        /# Invoke the kind-specific parsing function.
        expr = func(self, attribute=attribute)

        /# Special casing
        if kind == 'paren':
          kind = 'plist' if isinstance(expr, list) else 'bool'

        /# Establish result
        if expr is None:
          /# An error occurred (already written to field 'errors')
          result = None
        else:
          col = self.col() - 1
          if col < 0:
            raise Error('Can this happen?')
          else:
            /# print('Here with kind=%s srow=%d scol=%d erow=%d ecol=%d' % (
            /#   kind, srow, scol, self.row(), col))
            text = self.text(srow, scol, self.row(), col)
          result = Expr(kind, text, expr)

      else:
        /# line[i] is not the initial char in any legal expression.
        self.error('Char "%s" does not start any expression' % c)
        result = None

      return result
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, ' 1   apple"hello"\n'))

      test.iseq('<kind=num str=1 expr=1>', str(eprs.parse()))
      test.iseq('<kind=var str=apple expr=apple>', str(eprs.parse()))
      test.iseq('<kind=str str="hello" expr="hello">', str(eprs.parse()))
      /# TODO(wmh): More tests needed, for all kinds of expressions, with
      /# edgecases!
    end method parse;

    protected
    method _parseNum : double #:
      Parse a number.

      The current position must start the number (e.g. no whitespace is
      skipped).

      This will never advance the row, but will advance col if a number
      was found (if not found, col not affected).
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      line, i = self.current()
      /# line[i] assumed to be in [-+0-9] without verification

      /# TODO(wmh): How efficient is python about text[i:]?  Is it making
      /# a copy, or just returning a datastructure starting at an index within
      /# previously interned space?  If it is poorly implemented, is there some
      /# way to start the query at index i that doesn't use text[i:] and
      /# doesn't require us to compile a regexp each time thru this func?
      numstr = line[i:]
      m = MetaExprParser.NUM_RE.match(numstr)
      if m:
        ival, fraction, exponent = m.groups()
        if fraction or exponent:
          expr = float(ival + fraction + (('e' + exponent) if exponent else ''))
        else:
          expr = int(ival)
        self.colIs(self.col() + m.end())
      else:
        self.error('Failed to match a number: "%s"' % numstr)
        expr = None

      return expr
    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '  \n  10\n'))
      eprs.set(row=1, col=2)
      test.iseq(10, eprs._parseNum())
      test.iseq((1, 4, '\n'), eprs.pos())
      eprs.set(col=0)
      test.iseq((1, 0, ' '), eprs.pos())
      test.isnull(eprs._parseNum())
      test.iseq(['R1C0: Failed to match a number: "  10\n"'], eprs.errors())
      test.iseq((1, 0, ' '), eprs.pos())
    end method _parseNum;

    protected
    method _parseVar : str #:
      Parse a id.

      Note that pseudo vars like 'true', 'false', 'null' and native vars like
      'out', 'err', etc. are also parsed by this method

      Some variables accessible within a particular scope are not entirely
      local. For example, suppose class 'A' within namespace 'nm.sp' has a
      method 'f', a public raw class field 'M' and a public raw static variable
      'S'. From within method 'm', both 'M' and 'S' may (or may not) be 
      considered visible.  If they are visible, what syntax is used to access
      them?
       - for class fields, we have callsite notation for this:
           @nm.sp.A!M
         and if M wasn't raw, we could use accessor notation instead:
           @nm.sp.A.M
       - for static vars, there is a bit of an issue around the semantics of
         fields vs variables (it would be nice to reserve '!' for fields only),
         but it seems sensible, if static vars can have accessors, to extend
         '!' to apply to them too, in which case we can access 'S' similar
         to 'M':
           @nm.sp.A!S
         or, if S is not raw and has a getter:
           @nm.sp.A.S
       - alternatively, we could allow variables to contain '.', so that
           nm.sp.A.S
         is a reference to static variable S within class A of namespace
         'nm.sp'. But in Meta we really want to hide away fields (and vars) as
         much as possible by putting them behind accessors, and this notation
         does NOT hide them away as well as the callsite notation, so we are
         NOT supporting fully-qualified vars ... only callsites.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      line, i = self.current()
      /# Assumes line[i] is underscore or alpha without verifying
      /# No array bounds checking needed because all lines end in '\n'
      m = MetaExprParser.ID_PREFIX_RE.match(line[i:])
      if m:
        expr = m.group()
        self.colIs(i + m.end())
      else:
        self.error('Failed to parse an identifier at "%s"' % line[i:])
        expr = None
      return expr
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 'a val true meta!out a.bc.def.Hex\n'))
      eprs.set(row=0, col=0)

      self.iseq('a', eprs._parseVar())
      self.iseq(' ', eprs.getc())

      self.iseq('val', eprs._parseVar())
      self.iseq(' ', eprs.getc())

      self.iseq('true', eprs._parseVar())
      self.iseq(' ', eprs.getc())

      self.iseq('meta!out', eprs._parseVar())
      self.iseq(' ', eprs.getc())

      self.iseq('a', eprs._parseVar())
      self.iseq('.', eprs.getc())
      self.iseq('bc', eprs._parseVar())
      self.iseq('.', eprs.getc())
      self.iseq('def', eprs._parseVar())
      self.iseq('.', eprs.getc())
      self.iseq('Hex', eprs._parseVar())
      self.iseq('\n', eprs.getc())
    end method _parseVar;

    protected
    method _parseStr : str #:
      Parse a str.

      Current position must be a single or double quote.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      line, i = self.current()
      /# line[i] assumed to be either ' or "
      expr = None
      error = None
      start = i
      delim = line[i]
      try:
        while True:
          i += 1
          if line[i] == '\\':
            /# escapes next char.
            i += 1
          elif line[i] == delim:
            break
        i += 1
        expr = line[start:i]
        self.colIs(i)
      except IndexError:
        self.error('Failed to parse literal string')
        expr = None
      return expr
    test:
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(
          None, None, '  "this is a test"\n\'another test\'?  \n'))
      eprs.set(row=0, col=2)
      test.iseq('"this is a test"', eprs._parseStr())
      test.iseq((0, 18, '\n'), eprs.pos())
      eprs.set(row=1, col=0)
      test.iseq("'another test'", eprs._parseStr())
      test.iseq((1, 14, '?'), eprs.pos())
    end method _parseStr;

    protected
    method _parseGenericList : vec<map> #:
      Parse a list of expressions delimited by start and end
    params:
      var schr : char #:
        The start-of-expr character.
      var echr : char #:
        The end-of-expr character.
      var default : bool = false #:
        If true, support default expressions for elements of kind 'id'.
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      srow, scol, _ = self.pos()
      line, i = self.current()
      assert line[i] == schr
      /# NOTE: No array bounds checking is needed because all lines end in '\n'

      /# We record the end-of-terminator char with our list of such indicators
      /# to handle trailing commas.  If parse() encounters a character
      /# matching self.terms()[-1], it knows to return None immediately.
      self.terms().append(echr)

      /# expr is the list of parsed elements in the list. If an error occurs
      /# during parsing, expr is set to None (and errors added to field 'errors')
      expr = []

      /# Repeatedly consume expressions terminated by ',' or echr,
      /# accumulating into 'expr' until matching echr is reached.
      while True:
        /# line[i] is a schr or comma. Advance one char and parse an expr.
        self.colIs(i+1)

        /# Parse the current arg. Note that parse() skips past initial
        /# whitespace, so we don't have to do so here.
        arg = self.parse()

        if arg is None:
          /# This means one of two things:
          /#  1) an error was encountered (already written to field 'errors')
          /#  2) the matching end-of-expr character has been found after
          /#     whitespace (this happens if a trailing comma exists).
          /# In either case, the correct thing to do is end the loop.
          line, i = self.current()
          if line[i] == echr:
            /# We've reached the end of the plist ... set col to one past the
            /# closing parent and exit the loop.
            self.colIs(i+1)
            break
          elif self.errors():
            /# There was an error during parsing.
            expr = None
            break
          else:
            raise Error('Unknown situation')
        if expr is None:
          break

        /# We've successfully parsed the arg ... register it with the result.
        expr.append(arg)

        /# After the current arg, arbitrary spaces are allowed and skipped
        line, i = self.skipws()
        c = line[i]

        /# Support default values for identifiers.
        if default and arg.kind() == 'var' and c == '=':
          /# Advance past '=' and parse another expression
          self.colIs(i+1)
          defexpr = self.parse()
          arg.defaultIs(defexpr)
          line, i = self.skipws()
          c = line[i]

        /# Check for end-of-list.
        if c == echr:
          /# advance past closing paren
          i += 1
          self.colIs(i)
          break
        elif c == ',':
          /# There is (maybe) another arg. We do not need to increment i, as
          /# it is done as we start the next iteration of the loop.
          pass
        else:
          /# this is an error.
          self.error('Expecting "," or "%s" not "%s"' % (echr, c))
          expr = None

      if expr is None:
        /# We have an error ... reinstate the original position.
        self.set(row=srow, col=scol)
      else:
        /# We've successfully parsed the expression ... pop the echr off the
        /# 'terms' list.
        assert self.terms().pop() == echr

      return expr
    test<py>:
      /# noop ... tested in _parsePList() and _parseList()
      pass
    end method _parseGenericList;

    protected
    method _parseParen : any #:
      Parse an expression starting with '('. This is either a comma-separated
      list of expressions, or a bool expression. We use the attribute to
      determine which.

      The only use of 'list of comma-separated expresion' is the 'super'
      attribute of method constructs, whereas the boolean expression form is
      much more ubiquitous, especially in statement-level constructs.

      There are four different ways to resolve the ambiguity:
        1. Change super to use <a,b> instead of (a,b).
            - not preferred, as parathentical syntax matches method call syntax
        2. Assume it is a plist, and dynamically switch to parsing a boolexpr
           if syntax is encountered that indicates it.
            - problematic because some syntax can be interpreted as either
              plist or boolexpr (e.g. '(a)')
        3. Assume it is a boolexpr, and dynamically switch to parsing a plist
           if syntax is encountered that indicates it (e.g. a comma after an
           expr).
            - problematic because some syntax can be interpreted as either
              plist or boolexpr (e.g. '(a)')
        4. Use context (i.e. the attribute within which the Expr resides) to
           determine whether this is a plist or boolexpr
            - Since the only plist is 'super', this seems like a safe approach
              at least currently.

      Currently implementing #4 above, by requiring that an attribute always
      be provided when parsing an expression starting with '('
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      if not attribute:
        line, i = self.current()        
        raise Error('Missing attribute keyword for paren expr %s' % line[i:])
      if attribute.key() == 'super':
        result = self._parsePList(attribute=attribute)
      else:
        result = self._parseBool(attribute=attribute)
      return result
    test:
      attribute = metax.attr.ExprAttribute(None, 'super', None)
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '(1, "hello", apple)\n'))
      eprs.set(0, 0)
      test.iseq('plist', eprs.parse(attribute=attribute).kind())

      attribute2 = metax.attr.ExprAttribute(None, 'not_super', None)
      eprs2 = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '((a < 7) and (b > 10))\n'))
      eprs2.set(0, 0)
      test.iseq('bool', eprs2.parse(attribute=attribute2).kind())
    end;

    protected
    method _parseBool : map #:
      Parse a parenthesized list representing a boolean expression.

      Returns:
        List of maps describing the parsed boolean expression. Each element
        is a 
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      /# IMPORTTANT: To distinguish between _parseBool and _parsePList, this
      /# method must return something other than a list, and this is checked
      /# for in ExprParser.parse().
      data = []
      metafile = self.source()
      debug = False

      result = {
        'ops': [],
        'logic': 0,
        'data': data,
      }

      def AddOp(op):
        data.append(op)
        result['ops'].append(op)
        if op.isalpha() or op == '!':
          result['logic'] += 1

      /# Recognized syntax:
      /#   <boolexpr> ::- '(' <bexpr> [ <op> <bexpr> ] ')'
      /#   <bexpr>    ::- <expr> | <boolexpr>
      /#   <op>       ::- '<'  | '>'   | '<=' | '>=' | '==' |
      /#                  '&&' | 'and' | '||' | 'or'
      srow, scol, _ = self.pos()
      line, i = self.current()
      assert line[i] == '('
      /# NOTE: No array bounds checking is needed because all lines end in '\n'

      /# Big-picture goal: scan until we encounter matching ')'
      /#  - only the following is legal:
      /#      '('  ['!'] <expr> [ <op>  ['!'] <expr> ]... ')'
      /#  - with caveats:
      /#     - More than 1 <op> are allowed only for 'and' and 'or' ... if
      /#       the first op is not one of those, only one is allowed.
      /#     - mixing negation with comparison operators is not allowed.

      /# Advance past opening parent and whitespace.
      self.colIs(i+1)
      line, i = self.skipws()
      c = line[i]

      /# Parse an expression, optionally preceeded by negation.
      if c == '!':
        AddOp('!')
        self.colIs(i+1)
        if debug:
          print('Found negation before first expr')
      expr = self.parse(attribute=attribute)
      if not expr:
        /# Error will have been written to self.errors()
        return None
      if debug:
        print('Found first expr %s' % expr)
      data.append(expr)

      /# Skip whitespace
      line, i = self.skipws()
      c = line[i]

      /# Now parse zero or more <op> <expr> pairs.
      /#  - each time through the loop, c should be non-whitespace.
      while c != ')':
        assert not c.isspace()

        /# Parse an operator.
        opstr = line[i:]
        m = MetaExprParser.BOOL_OP_RE.match(opstr)
        if m:
          op = m.group('op')
          after = m.group('after')
          if not after.isalnum() and not after.isspace():
            /# after is another symbol, which means the operator isn't legal.
            self.error('Invalid operator "%s%s"' % (op, after))
            result = None
            break
          else:
            /# We have a valid operator.
            AddOp(op)
            i += len(op)
            self.colIs(i)
            if debug:
              print('Found operator "%s"' % op)
        else:
          self.error('Expecting operator', attribute=attribute)
          result = None
          break

        /# Now parse another expression, optionally preceeded by negation.
        line, i = self.skipws()
        c = line[i]
        if c == '!':
          AddOp('!')
          self.colIs(i+1)
          if debug:
            print('Found negation')
        rhs = self.parse(attribute=attribute)
        if not rhs:
          /# Error will have been written to self.errors()
          result = None
          break
        else:
          data.append(rhs)
          /# Skip whitespace.
          line, i = self.skipws()
          c = line[i]
          self.colIs(i+1)
          if debug:
            print('Found expr %s' % expr)

      /# We only get here if we find a matching ')'. Advance past it.
      if result:
        self.colIs(i+1)

      /# Consistency checks
      /#  - cannot mix logical and comparison operators.
      if result['logic'] and result['logic'] != len(result['ops']):
        self.error('Cannot mix logic and comparison operators')
        result = None

      /# Now parse zero or more <op> <expr> pairs (if <op> is
      return result
    test:
      attribute = metax.attr.ExprAttribute(None, 'someattr', None)

      /# A simple single-var bool expression
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, ' (var)\n'))
      eprs.set(0, 1)
      test.iseq(
        "{'logic': 0, 'data': [<kind=var str=var expr=var>], 'ops': []}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# A negated single-var bool expression with whitespace.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, ' ( ! var )\n'))
      eprs.set(0, 1)
      test.iseq(
        "{'logic': 1, 'data': ['!', <kind=var str=var expr=var>], 'ops': ['!']}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# A simple conjuncttion.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, ' ( v1 and v2 )\n'))
      eprs.set(0, 1)
      test.iseq(
        "{'logic': 1, 'data': [<kind=var str=v1 expr=v1>, 'and', <kind=var str=v2 expr=v2>], 'ops': ['and']}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# A conjuncttion of disjunctions.
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '((v1 or !v2 or v3) and (!v4 or v5 or v6))\n'))
      eprs.set(0, 0)
      test.iseq(
        "{'logic': 1, 'data': [<kind=bool str=(v1 or !v2 or v3) expr={'logic': 3, 'data': [<kind=var str=v1 expr=v1>, 'or', '!', <kind=var str=v2 expr=v2>, 'or', <kind=var str=v3 expr=v3>], 'ops': ['or', '!', 'or']}>, 'and', <kind=bool str=(!v4 or v5 or v6) expr={'logic': 3, 'data': ['!', <kind=var str=v4 expr=v4>, 'or', <kind=var str=v5 expr=v5>, 'or', <kind=var str=v6 expr=v6>], 'ops': ['!', 'or', 'or']}>], 'ops': ['and']}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# Some arthimetic expressions.
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '((v1<v2) and (v3 > v4) or (v5 ==v6))\n'))
      eprs.set(0, 0)
      test.iseq(
        "{'logic': 2, 'data': [<kind=bool str=(v1<v2) expr={'logic': 0, 'data': [<kind=var str=v1 expr=v1>, '<', <kind=var str=v2 expr=v2>], 'ops': ['<']}>, 'and', <kind=bool str=(v3 > v4) expr={'logic': 0, 'data': [<kind=var str=v3 expr=v3>, '>', <kind=var str=v4 expr=v4>], 'ops': ['>']}>, 'or', <kind=bool str=(v5 ==v6) expr={'logic': 0, 'data': [<kind=var str=v5 expr=v5>, '==', <kind=var str=v6 expr=v6>], 'ops': ['==']}>], 'ops': ['and', 'or']}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# Special modes.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '(3 < x < 7)\n'))
      eprs.set(0, 0)
      test.iseq(
        "{'logic': 0, 'data': [<kind=num str=3 expr=3>, '<', <kind=var str=x expr=x>, '<', <kind=num str=7 expr=7>], 'ops': ['<', '<']}",
        str(eprs._parseBool(attribute=attribute)))
      test.iseq([], eprs.errors())

      /# Error modes.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '(3 < x and 7)\n'))
      eprs.set(0, 0)
      test.isnull(eprs._parseBool(attribute=attribute))
      test.iseq(
        ['R0C13: Cannot mix logic and comparison operators'], eprs.errors())

    end method _parseBool;

    protected
    method _parsePList : vec<map> #:
      Parse a parenthesized list of comma-separated expressions OR a boolean
      expression.

      TODO(wmh): 
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      return self._parseGenericList('(', ')', default=True)
    test:
      hello = '"hello"'

      /# The empty plist.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '()\n'))
      test.iseq([], eprs._parsePList())

      /# A simple single-line plist expression
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, ' (1, "hello", apple)\n'))
      eprs.set(0, 1)
      test.iseq(
        '[<kind=num str=1 expr=1>, <kind=str str="hello" expr="hello">, <kind=var str=apple expr=apple>]',
        str(eprs._parsePList()))

      /# Now a multi-line plist expression
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 
          '  # python method call\n'
          '  self.f(1,\n'
          '         apple,\n'
          '         "hello",\n'
          '        )\n'))
      eprs.set(1, 8)
      test.iseq(
        '[<kind=num str=1 expr=1>, <kind=var str=apple expr=apple>, <kind=str str="hello" expr="hello">]',
        str(eprs._parsePList()))

      /# The same multi-line plist expression using parse() which invokes
      /# _parsePlist(). Note that this requires an attribute.
      attribute = metax.attr.ExprAttribute(None, 'super', None)
      eprs.set(1, 8)
      test.iseqtext(
        '<kind=plist str=(1,\n'
        '         apple,\n'
        '         "hello",\n'
        '        ) expr=[<kind=num str=1 expr=1>, <kind=var str=apple expr=apple>, <kind=str str="hello" expr="hello">]>',
        str(eprs.parse(attribute=attribute)))

      /# Test default values for id expressions.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, 'f(1, a, def=def)\n'))
      eprs.set(0, 1)
      test.iseq(
        '[<kind=num str=1 expr=1>, <kind=var str=a expr=a>, <kind=var str=def expr=def default=<kind=var str=def expr=def>>]',
        str(eprs._parsePList()))
    end method _parsePList;

    protected
    method _parseList : map #:
      Parse a square-bracket list of comma-separated expressions.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      return self._parseGenericList('[', ']', default=False)
    test:
      hello = '"hello"'

      /# The empty list.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '[]\n'))
      test.iseq([], eprs._parseList())

      /# A simple single-line plist expression
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, ' [1, "hello", apple]\n'))
      eprs.set(0, 1)
      test.iseq(
        '[<kind=num str=1 expr=1>, <kind=str str="hello" expr="hello">, <kind=var str=apple expr=apple>]',
        str(eprs._parseList()))

      /# Now a multi-line plist expression
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 
          '  # python method call\n'
          '  abc = [1,\n'
          '         apple,\n'
          '         "hello",\n'
          '        ]\n'))
      eprs.set(1, 8)
      test.iseq(
        '[<kind=num str=1 expr=1>, <kind=var str=apple expr=apple>, <kind=str str="hello" expr="hello">]',
        str(eprs._parseList()))

      /# The same multi-line plist expression using parse() which invokes
      /# _parselist().
      eprs.set(1, 8)
      test.iseqtext(
        '<kind=list str=[1,\n'
        '         apple,\n'
        '         "hello",\n'
        '        ] expr=[<kind=num str=1 expr=1>, <kind=var str=apple expr=apple>, <kind=str str="hello" expr="hello">]>',
        str(eprs.parse()))
    end method _parseList;

    protected
    method _parseUnit : metax.units.Quantity #:
      Parse a unit literal.

      Current position must be a '<'.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      line, i = self.current()
      n = len(line)
      j = i + 1
      end = None
      while j < n:
        if line[j] == '>':
          end = j
          break
        j += 1
      if end is None:
        self.error('Failed to parse literal unit')
        quantity = None
      else:
        qstr = line[i+1:end]
        tmp = metax.units.Quantity.New(qstr)
        /# We downcast if powers are known.
        units = tmp.units()
        quantity = tmp.subclone()
        if quantity is None:
          /# This means the quantity does not have a subclass ... do we use
          /# tmp, or report an error?
          quantity = tmp
        self.colIs(end+1)
      return quantity
    test:
      /# A simple single-line hash expression
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '<1.87m>\n'))
      res = eprs._parseUnit()
      test.iseq(' 1.87000 m', res.asStr())
      line, i = eprs.current()
      test.iseq('>', line[i-1])
    end method _parseUnit;

    protected
    method _parseHash : map #:
      Parse a collection of key : value pairs.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      schr = '{'
      echr = '}'
      srow, scol, _ = self.pos()
      line, i = self.current()
      assert line[i] == schr
      /# NOTE: No array bounds checking is needed because all lines end in '\n'

      /# We record the end-of-terminator char with 'terms', our list of such
      /# indicators to handle trailing commas. If parse() encounters a
      /# character matching self.terms()[-1], it knows to return None
      /# immediately.
      self.terms().append(echr)

      /# expr is the list of parsed key/value pairs in the hash (in the order
      /# they appeared lexical). Each element is a two-tuple of parsed expr
      /# dicts.
      expr = []

      /# Repeatedly consume key/value expressions terminated by ',' or '}',
      /# accumulating into 'expr' until matching '}' is reached.
      while True:
        /# line[i] is a schr or comma. Advance one char and parse an expr.
        self.colIs(i+1)

        /# Parse a key. Note that parse() skips past initial whitespace,
        /# so we don't have to do so here.
        key = self.parse(attribute=attribute)

        if key is None:
          /# This means one of two things:
          /#  1) an error was encountered (already written to field 'errors')
          /#  2) the matching end-of-expr character has been found after
          /#     whitespace (this happens if a trailing comma exists).
          /# In either case, the correct thing to do is end the loop.
          line, i = self.current()
          if line[i] == echr:
            /# We've reached the end of the hash ... set col to one past the
            /# closing parent and exit the loop.
            self.colIs(i+1)
            break
          elif self.errors():
            /# There was an error during parsing.
            expr = None
            break
          else:
            raise Error('Unknown situation')

        /# Now confirm the next non-ws char is a ':'
        line, i = self.skipws()
        c = line[i]
        if c != ':':
          self.error(
            'Line %d, column %d: Expecting a colon, encountered "%s"' %
            (self.row()+1, i+1, c))
          expr = None
          break

        /# Skip past the colon and whitespace
        self.colIs(i+1)
        line, i = self.skipws()

        /# Parse a value. Note that parse() skips past initial whitespace,
        /# so we don't have to do so here.
        value = self.parse(attribute=attribute)

        if value is None:
          /# This means one of two things:
          /#  1) an error was encountered (already written to field 'errors')
          /#  2) an expression-terminating character was encountered. This
          /#     means a value is missing ... an error.
          line, i = self.current()
          if line[i] == echr:
            self.error(
              'Expecting a value but encountered "%s"' % echr)
            expr = None
            break
          elif self.errors():
            expr = None
            break
          else:
            raise Error('Unknown situation')

        /# We've successfully parsed the key/value pair ... register it with
        /# the result.
        expr.append((key, value))

        /# After the current arg, arbitrary spaces are allowed and skipped
        line, i = self.skipws()
        c = line[i]

        /# Check for end-of-list.
        if c == echr:
          /# advance past closing paren
          i += 1
          self.colIs(i)
          break
        elif c == ',':
          /# There is (maybe) another key/value pair. We do not need to
          /# increment i, as it is done as we start the next iteration of the
          /# loop.
          pass
        else:
          /# this is an error.
          self.error('Expecting "," or "%s" not "%s"' % (echr, c))
          expr = None

      if expr is None:
        /# We have an error ... reinstate the original position.
        self.set(row=srow, col=scol)
      else:
        /# We've successfully parsed the expression ... pop the echr off the
        /# 'terms' list.
        assert self.terms().pop() == echr

      return expr

    test:
      /# An empty hash.
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '{}n'))
      test.iseq([], eprs._parseHash())

      /# A simple single-line hash expression
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, ' {"a": 1, \'b\': 2, 3 : apple, "a" : "hello" } \n'))
      eprs.set(0, 1)
      test.iseqtext(
        '[(<kind=str str="a" expr="a">, <kind=num str=1 expr=1>), (<kind=str str=\'b\' expr=\'b\'>, <kind=num str=2 expr=2>), (<kind=num str=3 expr=3>, <kind=var str=apple expr=apple>), (<kind=str str="a" expr="a">, <kind=str str="hello" expr="hello">)]',
        str(eprs._parseHash()))

      /# A multi-line hash expression
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 
          "data = {\n"
          "  'S': 1,\n"
          "  'H': 2,\n"
          "  'C': 3,\n"
          "  'D': 4,\n"
          "}\n"))
      eprs.set(row=0, col=7)
      test.iseqtext(
        "[(<kind=str str='S' expr='S'>, <kind=num str=1 expr=1>), (<kind=str str='H' expr='H'>, <kind=num str=2 expr=2>), (<kind=str str='C' expr='C'>, <kind=num str=3 expr=3>), (<kind=str str='D' expr='D'>, <kind=num str=4 expr=4>)]",
        str(eprs._parseHash()))
    end method _parseHash;

    protected
    method _parseCall : map #:
      Parse a callsite.

      A callsite consists of: '@' <rec> {<sep> <name> [<arglist>]}...

      Examples:
        @this!a(1);
        @this.f;
        @this.g(1);
        @this.g(@f.h(1,'a',z'));

      Note that the semicolon in the above is NOT part of the callsite (it is
      part of the callsite (it is part of the construct within which the expr
      resides). The semicolon is critically important though, as it is how
      we can determine when to end the callsite.  Other places where we end
      a callsite:
        @self.f(@a.b,@c!f)
      Note that the ',' ends '@a.b' and the ')' ends '@c!f'. Similarly for
        var a : map = { 'a': @a.b, 'b': @c!f }
      in which the comma ends '@a.b' and the '}' ends @c!f. In general,
      the chars in MetaExprParser.TERMCHARS represent when to end a call construct.

    params:
      var receiver : str = null #:
        If null (the normal case), we are parsing the complete callsite.
        If not null, it is a string, and representing the name of a variable
        that has previously been parsed. If provided, we are to skip the
        parsing of the receiver, because 'receiver' specifies the receiver.
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      line, i = self.current()
      /# No array bounds checking needed because all lines end with '\n'

      expr = None

      if not receiver:
        /# If an explicit receiver has not been provided for us, we parse it
        /# now.
        assert line[i] == '@'
        self.colIs(i+1)
        receiver = self._parseVar()

      if receiver is not None:
        subcalls = []
        expr = {'rec': receiver, 'subcalls': subcalls}

        /# Advance past whitespace
        line, i = self.skipws()

        while True:
          /# Parse <sep> <ws> <name> <ws> [<arglist>] <ws>
          /# Note that we cannot use a regexp (which would be faster) because we
          /# need to handle nested exprs within <arglist>.

          /# Establish <sep>
          sep = line[i]
          if sep != '!' and sep != '.':
            self.error('Expecting . or ! not "%s"' % sep)
            expr = None
            break

          /# Advance past the '.' or '!' and whitespace
          self.colIs(i+1)
          line, i = self.skipws()

          /# Obtain the <name>
          name = self._parseVar()
          if name is None:
            /# We encountered an error while parsing the name, so we exit.
            /# The error message has already been written to field 'errors'.
            expr = None
            break

          /# Skip past whitespace
          line, i = self.skipws()

          /# Obtain optional arglist
          arglist = None
          if line is not None:
            if line[i] == '(':
              arglist = self._parsePList()
              if arglist is None:
                break
          line, i = self.current()

          /# The var 'i' is now one char beyond <subcall>
          /#   <subcall> ::- <sep> <name> [<arglist>]
          subcall = {'name': name}
          if sep == '!': subcall['field'] = True
          if arglist: subcall['args'] = arglist
          subcalls.append(subcall)

          /# Advance past whitespace
          line, i = self.skipws()

          /# A call expr ends at any of the following:
          /#  - we've reached end of string at this point
          /#  - we are seeing a ')', which means we are at end of an arglist
          /#  - we are seeing a ',', which means we are at end of an arg inside an arglist
          /#  - we are seeing a ';', which means we are at end of expr construct.
          if line is None or line[i] in MetaExprParser.TERMCHARS:
            break

      return expr
    test:
      /# Simple method invocation with no args
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '@self.meth; \n'))
      test.iseq(
        {'rec': 'self', 'subcalls': [{'name': 'meth'}]},
        eprs._parseCall())

      /# Simple field get
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '@self!fld; \n'))
      test.iseq(
        {'rec': 'self', 'subcalls': [{'name': 'fld', 'field': True}]},
        eprs._parseCall())

      /# Simple method invocation with two args
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '@self.meth(a, 1); \n'))
      test.iseq(
        "{'rec': 'self', 'subcalls': ["
        "{'args': [<kind=var str=a expr=a>, <kind=num str=1 expr=1>], "
        "'name': 'meth'}]}",
        str(eprs._parseCall()))

      /# Simple field set
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '@self!fld(1); \n'))
      test.iseq(
        "{'rec': 'self', 'subcalls': [{'field': True, 'args': [<kind=num str=1 expr=1>], 'name': 'fld'}]}",
        str(eprs._parseCall()))

      /# Nested method invocation.
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '@self.meth1.meth2(a).meth3(b, 1); \n'))
      test.iseq(
        "{'rec': 'self', 'subcalls': [{'name': 'meth1'}, {'args': [<kind=var str=a expr=a>], 'name': 'meth2'}, {'args': [<kind=var str=b expr=b>, <kind=num str=1 expr=1>], 'name': 'meth3'}]}",
        str(eprs._parseCall()))

      /# Nested method invocation with nested calls.
      /# expr = metax.c.ExprParser(['@test.iseq(2, 1);\n'])
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, '@test.iseq(@test!hex.q, 1);\n'))
      test.iseq(
        "{'rec': 'test', 'subcalls': [{'args': [<kind=call str=@test!hex.q expr={'rec': 'test', 'subcalls': [{'field': True, 'name': 'hex'}, {'name': 'q'}]}>, <kind=num str=1 expr=1>], 'name': 'iseq'}]}",
        str(eprs._parseCall()))

      /# Nested method invocation with nested calls spanning multiple lines.
      eprs = metax.c.ExprParser(
        metax.c.MetaFile(None, None, 
          "        @test.iseq(\n"
          "          'Edge between <1,0,-1> (n) and <1,-1,0> (s) with center <0,-52>',\n"
          "          @edge.summary);\n"),
          col=8)
      test.iseqtext(
        "{'rec': 'test', 'subcalls': [{'args': [<kind=str str='Edge between <1,0,-1> (n) and <1,-1,0> (s) with center <0,-52>' expr='Edge between <1,0,-1> (n) and <1,-1,0> (s) with center <0,-52>'>, <kind=call str=@edge.summary expr={'rec': 'edge', 'subcalls': [{'name': 'summary'}]}>], 'name': 'iseq'}]}",
        str(eprs._parseCall()))

    end method _parseCall;

    method consumeOperator : map #:
      Consume an operator.
    params:
      var attribute : Attribute = null #:
        The attribute associated with this expression.
    scope:
      legal = MetaExprParser.LEGAL_OP_CHARS
      line, i = self.current()

      /# Obtain the operator
      start = i
      while line[i] in legal:
        i += 1
      op = line[start:i]

      /# When this method starts, i MUST be pointing to a legal op char. If
      /# it did not, the following will fail.
      assert len(op) > 0

      /# Parse an arbitrary expression.
      /#  - we do not need to skip whitespace here, as it is skipped in parse()
      self.colIs(i)
      rhs = self.parse(attribute=attribute)

      if rhs:
        result = {'op': op, 'rhs': rhs}
      else:
        /# There are two possible reasons for there to be no rhs:
        /#  - an error occurred during parsing
        /#  - self.terms()[-1] was seen after arbitrary whitespace was consumed,
        /#    which indicates end of construct.
        if self.errors():
          /# bad rhs ... error already written to errors().
          result = None
        else:
          /# We are at the end of the callsite. We return null and allow the
          /# caller to determine that this means stop-parsing-construct. Note
          /# that we do NOT pop terms[-1] ... that is for the code parsing
          /# the nested expr to do ... we are just using terms to determine
          /# that the callsite has ended.
          result = None

      return result

    test:
      eprs = metax.c.ExprParser(metax.c.MetaFile(None, None, '1 + 2\n'))
      eprs.parse()
      eprs.skipws()
      test.iseq(
        "{'rhs': <kind=num str=2 expr=2>, 'op': '+'}",
        str(eprs.consumeOperator()))
    end method consumeOperator;

    method isCallConstruct : bool #:
      Establish if the given text represents a complex call construct.

      TODO(wmh): Delete this in favor of some other mechanism? e.g.
      if data is parsed (which it always should be before invoking this method),
      check 'kind' == 'call' or define a kind() method so that callers can
      use it as they see fit.
    scope:
      return self.line().lstrip()[0] == '@';
    test:
      eprs1 = metax.c.ExprParser(metax.c.MetaFile(None, None, '@self.meth; \n'))
      eprs2 = metax.c.ExprParser(metax.c.MetaFile(None, None, '10 a\n'))
      test.istrue(eprs1.isCallConstruct())
      test.isfalse(eprs2.isCallConstruct())
    end;

  end class ExprParser;

  class Expr #:
    A parsed expression as returned by ExprParser.parse().
  scope:

    field kind : str #:
      One of 'num', 'str', 'id', 'list', 'hash', 'plist', 'call',...
    field text : str #:
      The (possibly multiline) string representation of the expression
    field value : any #:
      Type of this field depends on kind:
        num: int or float
        str: str
        id: str
        plist: list of dicts (each dict is same format as 'expr' above)
        call: dict
          rec: str (receiver)
          field: bool (true if field access)
          name: str (name of field or method being accessed)
          args: list of dicts (each format as returned by parse())
        op: dict
          op: str
          rhs: dict (same format as returned by parse())
            kind: str
            str: str
            expr:
    field default : str #:
      Used in, for example, plist expressions to represent default values
      for a variable.
      TODO(wmh): Make this an optional field?

    lifecycle params:
      var kind -> kind;
      var text -> text;
      var value -> value;
    scope:
    end;

    meta
    method FromStr : Expr #:
      Obtain an Expr from a string.
    params:
      var text : str #:
        The textual representation of the Expr.
      var attribute : metax.attr.Attribute = null #:
        The attribute the expr is part of. Used to distinguish between
        syntaxes like plist vs boolexpr.
    scope:
      /# ExprParser only relies on the source/lines of a MetaFile, not on the
      /# schema, so we can make a sparse instance.
      metafile = MetaFile(None, None, text + '\n')
      return ExprParser(metafile).parse(attribute=attribute)
    test:
      FS = metax.c.Expr.FromStr
      test.iseq('<kind=num str=1 expr=1>', repr(FS('1')))
      test.iseq('<kind=var str=true expr=true>', repr(FS('true')))
      test.iseq('<kind=var str=false expr=false>', repr(FS('false')))
      test.iseq('<kind=str str="" expr="">', repr(FS('""')))
      test.iseq("<kind=str str='' expr=''>", repr(FS("''")))
      test.iseq('<kind=var str=person expr=person>', repr(FS('person')))
    end method FromStr;

    method __repr__ : str #:
      The printable representation of this Expr
    scope:
      parts = ['kind=' + self._kind, 'str=' + self._text, 'expr=' + str(self._value)]
      if self._default:
        parts.append('default=' + str(self._default))
      return '<' + ' '.join(parts) + '>'
    test:
      expr = metax.c.Expr.FromStr(' 1   apple"hello"')
      test.iseq('<kind=num str=1 expr=1>', repr(expr))
    end method __repr__;

    method asStr : str #:
      The expr as a string. Most commonly invoked if kind is 'str', but also
      legal for any kind.
    params:
      var unquote : bool = false #:
        If true, and kind is 'str', remove quotes if they exist.
      var quote : bool = false #:
        If true, and kind is 'str', add quotes if they do not exist.
      var delim : str = null #:
        If non-null, and kind is 'str', use the specified quote delimiter.
        If null, uses the quoting provided in the str value itself.
    scope:
      kind = self.kind()
      if kind == 'str':
        result = self.value()
        if result:
          if unquote and (result[0] == "\"" or result[0] == "'"):
            result = result[1:-1]
          elif quote and (result[0] != "\"" and result[0] != "'"):
            if delim is None:
              delim = "'"
            result = delim + result + delim
        else:
          /# This is presumably very rare, since we must normally quote a string
          /# to recognize it as a string expression.
          if delim:
            result = delim + delim
      else:
        /# TODO(wmh): Do a better for the more complex types.
        result = str(self.value())
      return result
    test:
      return
      e1 = metax.c.Expr('str', '', '')
      e2 = metax.c.Expr('str', '""', '""')
      e3 = metax.c.Expr('str', "''", "''")

      print(e1.asStr())
      print(e1.asStr(unquote=True))
      print(e1.asStr(quote="\""))

      print(e2.asStr())
      print(e2.asStr(unquote=True))
      print(e2.asStr(quote="\""))

      print(e3.asStr())
      print(e3.asStr(unquote=True))
      print(e3.asStr(quote="\""))
    end method asStr;

  end class Expr;

  class VarSet comment:
    Maintain a collection of var/value/Attribute tuples.

    A VarSet is used to instantiate a baselang-specific template associated
    with some construct. The template contains special variable interpolation
    requests, and a Varset provides the variables, the associated value of the
    variable, and the source (an Attribute instance) of the var/value. The
    VarSet allows us to convert the template into a specific instantiation of
    some baselang-level syntactic construct.
  assocs:
    std assoc re;
  scope:

    field map : @map #:
      Maps variable names to lists containing [value, attribute, delim, width]
    end field map;

    lifecycle params:
      var items : vec<tuple> = null;
    scope:
      /# Populate map with any data from 'items'.
      /#  - each element of items is a tuple containing 2-5 elements
      /#     [0] var
      /#     [1] value
      /#     [2] attribute (optional)
      /#     [3] delim (optional)
      /#     [4] width (optional)
      if items:
        for item in items:
          n = len(item)
          var = item[0]
          value = item[1]
          attribute = item[2] if n > 2 else None
          delim = item[3] if n > 3 else None
          width = item[4] if n > 4 else -1
          self.addVar(var, value, attribute=attribute, delim=delim, width=width)
    setup:
      self.varset = metax.c.VarSet()
      self.varset.addVar('age', 25)
      self.varset.addVar('name', 'Bob', attribute=None)
      self.varset2 = metax.c.VarSet(items=(('age', 25), ('name', 'Bob', None)))
    end lifecycle;

    method clone : VarSet #:
      TODO(wmh): Move to lifecycle 'copy' when it is implemented.
    scope:
      result = self.__class__()
      for var, data in self._map.items():
        value, attribute, delim, width = data
        result.addVar(var, value, attribute=attribute, delim=delim, width=width)
      return result
    test:
      varset = test.varset
      varset2 = varset.clone()
      test.notsame(varset, varset2)
      s1 = varset.asStr()
      s2 = varset2.asStr()
      test.iseq(s1, s2)
    end method clone;

    method addVar #:
      Add a var/value/attribute triple.

      If 'var' already exists, it is replaced with the new data.
    params:
      var var : str #:
        The variable to add
      var value : any #:
        The value to associate with the var. This is either a str, a vec<str>,
        or a BaseSegment.  The 'str' can have newlines, but the elements
        of a vec<str> should not.
      var attribute : metax.attr.Attribute = null #:
        The meta-level attribute
      var delim : str = null #:
        Only meaningful if the value is a list, and indicates what
        str separates elements of the list.  If None, the list of values
        is assumed to represent lines (i.e. delim == '\n').  If it is, for
        example, ', ', then the values of the list are to be separated by
        comma-space.  The advantage of maintaining the value as a list with
        delimiter is that it allows us to perform line-wrapping at element
        boundaries.
      var width : int = -1 #:
        The width of lines generated by this var.  Currently only meaningful
        when value is a list and delim is not None or '\n'.
    scope:
      self._map[var] = [value, attribute, delim, width]
    test:
      test.iseq(['age', 'name'], sorted(test.varset._map))
    end method addVar;

    method appendVar #:
      Append a value to a var.

      If the current value of the variable is a string:
       - append the str-valued 'value' to it.
      If the current value of the variable is a list:
       - if value is a list, add all elements to the end of current
       - if value is a string, add one element to end of current
    params:
      var var : str #:
        The pre-existing variable to append to.
      var value : any #:
        What to add to the variable. Can be a str or vec<str>.
    scope:
      current = self._map[var][0]
      if isinstance(current, list):
        if isinstance(value, list):
          current.extend(value)
        else:
          current.append(value)
      else:
        if isinstance(value, list):
          raise Error(
            'Invalid (list) value "%s" for (string) current "%s"' %
            (value, current))
        else:
          self._map[var][0] += value
    test:
      varset = test.varset
      test.iseqtext(
        'age             = 25\nname            = Bob',
        varset.asStr())
      varset.appendVar('name', 'Smith')
      test.iseqtext(
        'age             = 25\nname            = BobSmith',
        varset.asStr())
    end method appendVar;

    method prependVar #:
      Prepend a value to an existing value.
    params:
      var var : str #:
        The variable to augment. This must exist or an error is raised.
      var value : str #:
        The value to prepend to an existing value.
      var default : str = null #:
        What to set the value to if it is currently empty.  If null, uses
        value.
    scope:
      current = self._map[var][0]
      if not current:
        if default is None:
          default = value
        self._map[var][0] = default
      else:
        self._map[var][0] = value + self._map[var][0]
    test:
      varset = test.varset
      test.iseqtext(
        'age             = 25\nname            = Bob',
        varset.asStr())
      varset.prependVar('name', 'Silly')
      test.iseqtext(
        'age             = 25\nname            = SillyBob',
        varset.asStr())
    end method prependVar;

    method __contains__ : bool #:
      Allow the 'in' operator to be applied to an instance of this class.

      TODO(wmh): This is a python-specific method ... need something more
      language-independent.
    params:
      var var;
    scope:
      return var in self._map
    test:
      test.iseq(True, 'age' in test.varset)
      test.iseq(False, 'height' in test.varset)
    end method __contains__;

    method get : tuple<str,metax.attr.Attribute,str,int> #:
      Obtain the value, Attribute, delim and width associated with a given
      variable name.
    params:
      var var : str #:
        The variable name to obtain info for.
    scope:
      return self._map.get(var, None) or [None, None, None, None]
    test:
      varset = test.varset
      test.iseq(['Bob', None, None, -1], varset.get('name'))
      test.iseq([None]*4, varset.get('height'))
      varset.addVar('empty', '')
      test.iseq(['', None, None, -1], varset.get('empty'))
    end method get;

    method getValue : str #:
      Obtain the value of a variable.
    params:
      var var : str #:
        The name of the variable to obtain the value of.
    scope:
      data = self._map.get(var, None)
      if data is None:
        raise Error('Failed to find varset var %s' % var)
      return data[0]
    test:
      varset = test.varset
      test.iseq(25, varset.getValue('age'))
      test.iseq('Bob', varset.getValue('name'))
    end method getValue;

    method setValue : str #:
      Set the value of a variable.
    params:
      var var : str #:
        The name of the variable to obtain the value of.
      var value : any #:
        The value of the variable.
    scope:
      data = self._map.get(var, None)
      if data is None:
        raise Error('Failed to find varset var %s' % var)
      data[0] = value
    test:
      varset = test.varset
      test.iseq(25, varset.getValue('age'))
      test.iseq('Bob', varset.getValue('name'))
    end method setValue;

    method asStr : str #:
      Format as string
    params:
      var name : str = '?' #:
        Name of construct
      var indent = '';
    scope:
      lines = []
      varmap = self._map
      for var in sorted(varmap):
        value, attribute, delim, width = varmap[var]
        if isinstance(value, str):
          value_str = value.replace('\n', '\\n')
        else:
          value_str = str(value)
        lines.append('%s%-15s = %s' % (indent, var, value_str))
        if attribute:
          lines[-1] += ' [%s.%s line %d]' % (
            name, attribute.key(), attribute.line())
      return u'\n'.join(lines)
    test:
      test.iseqtext(
        'age             = 25\n'
        'name            = Bob',
        test.varset.asStr(None))
    end method asStr;

    method show params:
      var fp : ostream = out #:
        Where to write this varset.
    scope:
      fp.write(self.asStr() + '\n')
    test:
      fp = test.fp()
      test.varset.show(fp=fp)
      test.iseqtext(
        'age             = 25\n'
        'name            = Bob\n',
        fp.getvalue())
    end method show;

  end class VarSet;

  class BaseStreams #:
    Provides support for writing output to multiple streams with aggregation.

    When compiling a Meta construct into base language constructs, the following
    functionality is useful:
      - ability to write to multiple conceptual streams incrementally, and to
        serialize various streams to files
      - ability to know what a line number in the meta source code corresponds
        to in a base language file.
      - ability to form base language output by instantiating a multi-line
        template string.
      - ability to enforce various constraints on the generated output (for
        example, no line longer than 80 characters, etc.)

    This class provides support for all of the above.
  scope:

    field streams : @map #:
      Maps conceptual stream names to lists of elements, each of which can
      be a str or BaseSegment.

    lifecycle scope:
    setup:
      self.bs = metax.c.BaseStreams()
      self.bs2 = metax.c.BaseStreams()
      self.bs2.initStreams('a', 'b', 'c')
      self.bs2.addLine('b', 'testing')
      self.bs2.addLine('b', 'testing')
      self.bs2.addLines('b', ['more', 'testing'])
      self.segment = metax.c.BaseSegment(
          None, chunks=['indented', 'lines'], indent='  ')
      self.bs2.addSegment('b', self.segment)
      self.bs2.addOpaque('c', {'a': 1, 'b': 2})
    end;

    method clear #:
      Remove all streams from this instance.
    scope:
      self._streams.clear()
    test:
      bs = test.bs2
      test.iseqvec(['a', 'b', 'c'], bs.streamNames())
      bs.clear()
      test.iseqvec([], bs.streamNames())
    end method clear;

    method streamNames : vec<str> #:
      Obtain all of the names of streams in this instance.
    scope:
      return sorted(self._streams)
    test:
      test.iseqvec([], test.bs.streamNames())
      test.iseqvec(['a', 'b', 'c'], test.bs2.streamNames())
    end method streamNames;

    method stream : vec #:
      Obtain the stream with the given name.

      Returns:
        A list of elements, each of which can be a str or BaseSegment.
    params:
      var name : str #:
        The conceptual stream name to return.
      var clear : bool = false #:
        If true, a new stream is created even if it already exists.
        Note that the stream is completed replaced, not just cleared.
      var create : bool = false #:
        If True, create if it does not exist.  By default, we want to
        report an error, because we usually want to explicilty create
        streams in parent compilation methods.
    scope:
      streams = self._streams
      result = streams.get(name, None)
      if clear:
        if name in streams:
          streams[name] = []
      if result is None:
        if create:
          result = []
          streams[name] = result
        else:
          raise metax.c.InternalError(
            'Failed to find stream named "%s" in %s' % (name, sorted(streams)))
      if False:
        /# Use this if you want to debug the actions taken on individual
        /# stream collections.  All the code is designed to handle lists
        /# or Stream wrappers around lists (albeit with some inefficiency
        /# builtin), so this can be turned on and off trivially.
        result = Stream(name, result)
      return result
    test:
      test.raises(metax.c.InternalError, test.bs.stream, 'a')
      test.iseq([], test.bs2.stream('a'))
      test.iseq([], test.bs.stream('a', create=True))
    end method stream;

    method initStreams #:
      Create streams for each name specified.
    params:
      multi var names : vec;
    scope:
      for name in names:
        self.stream(name, clear=True, create=True)
    test:
      /# setup has invoked initStreams() on test.bs2
      test.iseqvec(['a', 'b', 'c'], test.bs2.streamNames())
    end method initStreams;

    method newStream : tuple<vec,vec> #:
      Initialize a stream, returning new stream and previous one (may be null).
    params:
      var name : str #:
        Name of stream to query/initialize.
    scope:
      try:
        previous = self.stream(name)
      except metax.c.InternalError:
        previous = None
      current = self.stream(name, clear=True, create=True)
      return current, previous
    test:
      test.iseq(([], None), test.bs2.newStream('testing'))
    end method newStream;

    method addLine #:
      Add a single line to a named stream.
    params:
      var name : str #:
        The name of the stream.
      var line : str #:
        The line to add.
    scope:
      stream = self.stream(name)
      stream.append(line)
      /#if name.endswith('classes'):
      /#  print('Adding "%s" to %s: %s' % (line, name, stream))
    test:
      bs = test.bs2
      test.iseq([], bs.stream('a'))
      bs.addLine('a', 'this is a test')
      test.iseq(['this is a test'], bs.stream('a'))
    end method addLine;

    method addLines #:
      Add multiple lines, in order, to a named stream.
    params:
      var name : str #:
        The name of the stream
      var lines : vec<str> #:
        The lines to add.
    scope:
      stream = self.stream(name)
      stream.extend(lines)
      /#if name.endswith('classes'):
      /#  print('Adding "%s" to %s: %s' % (line, name, stream))
    test:
      bs = test.bs2
      test.iseq([], bs.stream('a'))
      bs.addLines('a', ['this is a test', 'and another'])
      test.iseq(['this is a test', 'and another'], bs.stream('a'))
    end method addLines;

    method addOpaque #:
      Add an arbitrary element to a named stream.
      TODO(wmh): Any code that uses this should be modified to instead
      write into construct-subclass-specific fields, leaving streams for
      strs and BaseSegments.
    params:
      var name : str #:
        The name of the stream to write to.
      var obj : any #:
        The object to write to the stream.
    scope:
      stream = self.stream(name)
      stream.append(obj)
      /#if name.endswith('classes'):
      /#  print('Adding "%s" to %s: %s' % (obj, name, stream))
    test:
      bs = test.bs2
      test.iseq([], bs.stream('a'))
      bs.addOpaque('a', {'a': 1})
      test.iseq([{'a': 1}], bs.stream('a'))
    end method addOpaque;

    method addSegment : any #:
      Add a segment to a stream.

      Returns:
        The stream that the segment was added to.
    params:
      var name : str #:
        The stream to add to.
      var segment : BaseSegment #:
        The segment to add.
      var create : bool = false #:
        Whether to create the named stream if it doesn't already exist.
        TODO(wmh): Is this param needed?
    scope:
      stream = self.stream(name, create=create)
      stream.append(segment)
      return stream
    test:
      bs = test.bs2
      test.iseq([], bs.stream('a'))
      segment = metax.c.BaseSegment(None)
      stream = bs.addSegment('seg', segment, create=True)
      test.iseq(1, len(stream))
    end method addSegment;

    method flatten : str #:
      Collapse a stream into a single multi-line text stream.
    params:
      var name : str #:
        Name of stream.
      var spaces : int = 0 #:
        How many blank lines to insert between segments.
      var indent : int = 0 #:
        How many spaces to insert at the beginning of each line.
    scope:
      lines, mapping = self.flattenWithMap(name, spaces=spaces, indent=indent)
      return '\n'.join([line.rstrip() for line in lines])
    test:
      test.iseq(
       >|"""  testing
       >|  testing
       >|  more
       >|  testing
       >|    indented
       >|    lines""",
       test.bs2.flatten('b', spaces=1, indent=2))
    end method flatten;

    method flattenWithMap : tuple<str,vec<tuple<int,int>>> #:
      Collapse a stream into a single multi-line text stream.

      Returns: two-tuple
        0) text : str
        1) mapping: vec<tuple>
           list of tuples (local file line numbers to meta file line numbers)
    params:
      var name : str #:
        Name of stream.
      var spaces : int = 0 #:
        How many blank lines to insert between segments.
      var indent : int = 0 #:
        How many spaces to insert at the beginning of each line.
    scope:
      dentstr = ' ' * indent
      lines = []
      stream = self.stream(name)

      segment = BaseSegment(None, chunks=list(stream))
      mapfile = MapFile(None, None)
      lines = []
      segment.flattenLines(lines, mapfile, indent=dentstr)
      return lines, mapfile.mapping()
    test:
      test.iseq(
        (['  testing',
          '  testing',
          '  more',
          '  testing',
          '    indented',
          '    lines'],
         []),
        test.bs2.flattenWithMap('b', spaces=1, indent=2))
    end method flattenWithMap;

    method flattenAll : str #:
      Flatten all streams.
    params:
      var spaces : int = 0 #:
        How many blank lines to insert between segments.
      var indent : int = 0 #:
        How many spaces to insert at the beginning of each line.
      var empty : bool = false #:
        If True, show empty streams too.
    scope:
      result = ''
      for stream in sorted(self._streams):
        text = self.flatten(stream, spaces=spaces, indent=indent + 2)
        if empty or text:
          result += '\n\n' + stream + '\n'
          result += text
      return result
    test:
      out = test.bs2.flattenAll()
      test.contains("  {'a': 1, 'b': 2}", out)
    end method flattenAll;

    method dump #:
      Show all streams.
    params:
      var title : str = null #:
        A title to show.
      var fp : ostream = out #:
        Where to write output.
    scope:
      indent = ''
      if title:
        fp.write('%s%s\n%s\n' % (indent, '#' * 80, title))
      fp.write(self.flattenAll())
      fp.write('\n')
    test:
      
    end method dump;

  end class BaseStreams;

  class Stream #:
    Wrapper around a list of lines/segments.

    Used for debugging purposes to give insight into usage. Not used normally
    in the interests of efficiency (but may be neglible in impact).
    TODO(wmh): Look into always storing Stream instances ... would provide
    for a cleaner interface upon which additional functionality could be built.
  scope:

    field name : str;
    field data : map;

    lifecycle params:
      var name -> name;
      var data -> data;
    scope:
    setup:
      test.stream = metax.c.Stream('decl', ['a', 'b'])
    end;

    method append params:
      var elem : any;
    scope:
      self._data.append(elem)
    test:
      stream = test.stream
      stream.append('c')
      test.iseqvec(['a', 'b', 'c'], stream.data())
    end method append;

    method extend params:
      var lst : vec;
    scope:
      self._data.extend(lst)
    test:
      stream = test.stream
      stream.extend(['c', 'd'])
      test.iseqvec(['a', 'b', 'c', 'd'], stream.data())
    end method extend;

    method insert params:
      var index : int;
      var elem : any;
    scope:
      self._data.insert(index, elem)
    test:
      stream = test.stream
      stream.insert(1, 'c')
      test.iseqvec(['a', 'c', 'b'], stream.data())
    end method insert;

    method __iter__ scope:
      /#return self._data
      for x in self._data:
        yield x
    test:
      test.iseqvec(['a', 'b'], list(test.stream))
    end method __iter__;

    method __len__ scope:
      return len(self._data)
    test:
      test.iseq(2, len(test.stream))
    end method __len__;

    method __add__ params:
      var other : any;
    scope:
      if isinstance(other, Stream):
        o = other._data
      elif isinstance(other, list):
        o = other
      else:
        raise ValueError('Stream does not know how to add to %s' % other.__class__)
      return self._data + o
    test:
      test.iseq(['a', 'b', 'a', 'b'], test.stream + test.stream)
      test.iseq(['a', 'b', 1, 2, 3], test.stream + [1,2,3])
    end method __add__;

  end class Stream;

  class BaseSegment #:
    A collection of contiguous lines of baselang text originating at a specific
    line in a .meta file.
  assocs:
    lib assoc metax.meta;
  scope:

    field chunks : vec<any> #:
      The collection of str and BaseSegment instances making up this
      BaseSegment.  The str values cannot contain any newlines (including
      at end of string), and each str value represents exactly one line
      of output. Each BaseSegment represents multiple lines of output (and
      has an associated position in the .meta source file).
      TODO(wmh): Add support to Meta for type specifications of the form:
        vec<line:str|segment:BaseSegment>

    field indent : @str #:
      How much indentation exists before each line in this BaseSegment.

    field attribute : metax.attr.Attribute #:
      The metalevel Attribute instance associated with this base-lang text.
      Identifies the meta-level line number.  If null, no meta-level
      attribute is associated with the text in question (e.g. implicit
      code, etc.)

    field metaline : int #:
      The meta-level line number corresponding to the first element of chunks().
      This is often 0, in which case the line is obtained from 'attribute'. It
      is necessary to specify explicitly in situations where implicit code is
      inserted before the user-level content (for example, in simple-blocks
      containing preamble.

    field attrs : @map<int,metax.attr.Attribute> #:
      Maps integer indices within self.chunks() to Attribute instances. The
      chunk at the index should be an string.

    lifecycle params:
      var attribute -> attribute;
      var metaline -> metaline = -1;
      var chunks : vec = null;
      var indent -> indent = '';
    scope:
      if chunks is None:
        chunks = []
      self.chunksIs(chunks)
    clinit:
      cls.TMPL_RE = re.compile(
        '((?:^|\n) *)?\$\{([a-zA-Z0-9_-]+)(?:\?([^\}]*))?\}')
    setup:
      context = metax.c.Context(None, None, None, None)
      fauxcons = metax.meta.FileConstruct('f', None, context)
      test.attr = metax.attr.ComplexBlock(fauxcons, 'comment:', [], line=77, col=69)
      test.segment = metax.c.BaseSegment(test.attr, chunks=['Hello'])
      test.segment2 = metax.c.BaseSegment(
        test.attr, chunks=['HPB', 'is a brat', '    '])
    end lifecycle;

    method show #:
      Print out details.
    params:
      var fp : ostream = out #:
        Where to write output.
      var indent : str = '' #:
        What to insert before each line.
      var nostr : bool = false #:
        If true, do not show string-valued chunks
    scope:
      for i, chunk in enumerate(self.chunks()):
        if isinstance(chunk, BaseSegment):
          attr = chunk.attribute()
          metaline = self.metaline()
          if metaline == -1 and attr:
            metaline = attr.line()
          fp.write(
            u'%s%2d: seg %s (%d)\n' %
            (indent, i, attr.key() if attr else None, metaline))
          chunk.show(fp=fp, indent=indent + '  ', nostr=nostr)
        else:
          if not nostr:
            fp.write(u'%s%2d: %s\n' % (indent, i, chunk))
    test:
      test.segment2.addChunk(test.segment)
      test.segment2.show(fp=test.fp())
      out = test.out()
      test.iseqtext(
       >|""" 0: HPB
       >| 1: is a brat
       >| 2:     
       >| 3: seg comment: (77)
       >|   0: Hello
       >|""",
       out)
    end method show;

    method updateIndent params:
      var indent : str;
    scope:
      self._indent += indent
    test:
      test.iseq('', test.segment.indent())
      test.segment.updateIndent('...')
      test.iseq('...', test.segment.indent())
    end method updateIndent;

    method numLines #:
      Obtain the number of lines this segment represents.
    scope:
      count = 0
      for chunk in self.chunks():
        if isinstance(chunk, BaseSegment):
          count += chunk.numLines()
        else:
          /# If this assert fails, something is broken in the code to allow
          /# a str-value with newlines to not get split.
          assert '\n' not in chunk
          count += 1
      return count
    test:
      test.iseq(1, test.segment.numLines())
      test.iseq(3, test.segment2.numLines())
    end method numLines;

    method flattenLines #:
      Obtain a sequence of lines from this segment and the meta/base mapping.

      This code produces a list of lines in baselanguage syntax, based on the
      compilation of meta-syntax constructs. We want to know the correspondence
      between base language line numbers and meta-level line numbers.

      SideEffect:
        The mapfile instance is populated with base/meta mappings.

      Returns:
        The lines making up the segment.
    params:
      var lines : vec<str> #:
        Where to write the flattened lines.
      var mapfile : MapFile #:
        Where to write line mapping info.
      var indent : str = '' #:
        The amount of indentation before each line.  This is in addition
        to any indentation specified in self._indent.
      var strip_special : bool = false #:
        If true, any line starting with spaces followed by '>|' is replaced
        with the text after >|.
      var debug : bool = false;
    scope:
      /# debug = True
      start_index = len(lines)

      indent = self._indent + indent
      mapping = mapfile.mapping()
      attrs = self.attrs()
      for chunk_index, chunk in enumerate(self.chunks()):
        /# The current baselang line number.
        /#  - increment by 1 to adjust from 0-based to 1-based.
        baseline = len(lines) + 1

        /# Now add the line (which may be an entire BaseSegment that needs to
        /# be expanded).
        if isinstance(chunk, BaseSegment):
          attribute = chunk.attribute()
          if attribute:
            /# print('ATTRIBUTE: %s (%d)' % (attribute.path(), attribute.line()))
            fqn = attribute.parent().fqn()
            fullid = fqn + ':' + attribute.key()
            metaline = chunk.metaline()
            if metaline == -1:
              metaline = attribute.line()
            if metaline < 0:
              /# No metaline info is known. This usually indicates that a
              /# dynamically created construct (in some expandMeta() methods)
              /# is not properly specifying attribute line numbers.
              pass
            else:
              /# The attribute line number is the position of the attribute
              /# key.  For list-valued attributes, the value starts on the
              /# next line. Note that if we start supporting text on same line
              /# as block key we'll need a different way of assessing when to
              /# increment.
              if attribute.isBlock():
                metaline += 1
              /# We increment metaline by one to adjust from 0-based to 1-based.
              metaline += 1

            /# Record the baseline/metaline/fullid triplet.
            mapping.append((baseline, metaline, fullid))
          else:
            /# print('ATTRIBUTE: None')
            pass
          chunk.flattenLines(lines, mapfile, indent=indent, debug=False)
        else:
          attribute = attrs.get(chunk_index, None)
          if attribute:
            fqn = attribute.parent().fqn()
            fullid = fqn + ':' + attribute.key()
            /# We increment metaline by one to adjust from 0-based to 1-based.
            metaline = attribute.line() + 1
            mapping.append((baseline, metaline, fullid))

          /# Handle both python2 and python3
          from past.builtins import basestring
          if not chunk:
            chunk = ''
          elif not isinstance(chunk, basestring):
            /# Handle opaque data
            chunk = str(chunk)
          try:
            lines.append(indent + chunk)
          except UnicodeDecodeError as e:
            /# TODO(wmh): Fix this! Must be able to handle unicode chars in
            /# meta source code!  This was working fine before I made all
            /# literal strings unicode (by prefacing them with 'u'), but now
            /# fails for symbols like ohm, etc.
            uchunk = chunk.decode('utf8', 'replace')
            try:
              lines.append(indent + uchunk)
            except Exception:
              print('ERROR: chunk = %s (%s)' % (chunk, type(chunk)))
              print('ERROR:       = %s (%s)' % (uchunk, type(uchunk)))
              print('ERROR: indent = "%s" (%s)' % (indent, type(indent)))
              raise

      if strip_special:
        dentre = metax.c.SPECIAL_PREFIX_RE
        for i in range(start_index, len(lines)):
          m = dentre.match(lines[i])
          if m:
            lines[i] = lines[i][m.end(0):]
    test:
      mapfile = metax.c.MapFile(None, None)
      test.segment2.addChunk(test.segment)
      test.iseq([], mapfile.mapping())

      lines = []
      test.segment2.flattenLines(lines, mapfile, indent='..')

      test.iseq(['..HPB', '..is a brat', '..    ', '..Hello'], lines)
      test.iseq([(4, 79, ':comment:')], mapfile.mapping())

      /# Verify that nested basesegments perform indentation as expected.
      s1 = metax.c.BaseSegment(None, indent='  ')
      s1.addChunk('if a:')
      s2 = metax.c.BaseSegment(None, indent='  ')
      s1.addChunk(s2)
      s2.addChunk('b = 1')
      s2.addChunk('if b:')
      s3 = metax.c.BaseSegment(None, indent='  ')
      s3.addChunk('c = 1')
      s2.addChunk(s3)
      lines = []
      s1.flattenLines(lines, mapfile)
      test.iseqtext(
        '  if a:\n    b = 1\n    if b:\n      c = 1',
        '\n'.join(lines))
    end method flattenLines;

    method flattenStr : str #:
      Obtain a multi-line string for this stream.

      Instantiates variables into a template, with special logic:
       - replace ${var} with the value of the variable
          - if the value is a list
             - if there is exactly one variable in the current line (with
               $prefix and $postfix text before and after the var), then
               each element in the value is rendered on a separate line,
               preceeded by $prefix and succeeded by $postfix.
             - if there is more than one variable on the current line,
                - if the value of the variable is list-valued, the elements
                  are to be joined together separated by a special string
                  indidcated in the variable (for example, ${var?, } means
                  elements should be joined together with ', ').
          - if the value if the variable is not list-valued, it is inserted
            as-is. If the variable is of the form ${var?, }, it means 'if the
            value is empty, print nothing. If it is not empty, print the value
            followed by ', '.
    params:
      var indent : str = '' #:
        What to insert at the beginning of each line.
      var linenum : int = 0 #:
        If zero, no line numbering is desired, otherwise produce line numbers
        starting at specified value.
    scope:
      mapfile = metax.c.MapFile(None, None)
      lines = []
      self.flattenLines(lines, mapfile, indent=indent)
      if linenum:
        result = '\n'.join(
          ['%4d: %s' % (i, line) for i, line in enumerate(lines, start=linenum)])
      else:
        result = '\n'.join(lines)
      return result + '\n'
    test:
      test.iseq(
        '  HPB\n  is a brat\n      \n',
        test.segment2.flattenStr(indent='  '))
    end method flattenStr;

    method instantiate #:
      Add text to self by instantiating a template into self via a varset.
    params:
      var template : str #:
        The template string
      var varset : VarSet #:
        The varset providing var/value/attr triples to instantiate into
        the template.
      var kind : str #:
        The construct kind for which we are instantiating.
      var fqn : str #:
        The fully qualified name of the construct producing this text.
      var joins : map = null #:
        Maps variable names to join strings, for use when a variable doesn't
        specify a join explicitly.
    scope:
      cls = self.__class__

      debug = False
      if template[-1] != '\n':
        raise InvariantViolated('Templates must end with newline')

      /# There are two kinds of variable substitutions to deal with:
      /#  1) A variable appearing on a line by itself, possibly indented.
      /#     These generate BaseSegment instances. Values of list type are
      /#     allowed and common, and indentation must be handled properly.
      /#  2) A variable with non-space text before it or any text after it.
      /#     These produce strings, and if values are lists the elements
      /#     are joined into a string via a template-provided separator.
      /#     Supports max-width logic and line wrapping.
      r = re.compile(r'\$\{(?P<var>[a-zA-Z0-9_-]+)(?:\?(?P<join>[^\}]*))?\}')
      lines = template.split('\n')
      while not lines[-1]: lines.pop()
      for line in lines:
        if debug: print('LINE: %s' % line)

        m = r.search(line)
        if not m:
          /# No variable ... add the line verbatim.
          self.addChunk(line)

        else:
          /# We have found a variable interpolation request.
          /#  - we repeat the following code over and over as long as we
          /#    continue to find a variable interpolation on the line.
          /#    (so the code MUST replace variable references with non-variable
          /#    references to avoid an infinite loop).
          /#  - the 'chunk' variable is accumulated as the line is processed,
          /#    and a single value is added after all variable interpalations
          /#    on the line have been processed.
          chunk = ''
          count = 0
          attributes = []
          while m:
            count += 1
            pre = line[:m.start(0)]
            post = line[m.end(0):]
            var = m.group('var')
            join = m.group('join')

            /# Obtain the information about the variable to be interpolated.
            value, attribute, elem_delim, line_width = varset.get(var)
            if value is None:
              raise Error(
                "Missing variable '%s' for %s template:\n%s\nvarset is:\n%s" %
                (var, kind, template, varset.asStr(indent='  ')))
            if attribute:
              if attribute not in attributes:
                attributes.append(attribute)

            if debug:
              print(str({
                'count': count, 'pre': pre, 'post': post, 'var': var,
                'join': join, 'value': value, 'attribute': attribute,
                'elem_delim': elem_delim, 'width': line_width}))

            if count == 1 and not post and not pre.strip():
              /# There is a single variable on the line (preceeded by indentation
              /# stored in 'pre').
              if isinstance(value, (list, tuple)):
                /# We have a variable that produces a BaseSegment.
                if debug: print('In multi with attribute=%s' % attribute)
                if value:
                  /# Non-empty value.
                  chunk = cls(attribute, chunks=value, indent=pre)
                else:
                  /# Empty value ... treat the variable as if it doesn't exist.
                  chunk = None
              else:
                /# The value is a string
                if not value:
                  /# Empty value, so the entire line is ignore.
                  chunk = None
                else:
                  chunk += pre + value
              /# There is only one variable on this line, so we can terminate
              /# the iterations.
              break
            else:
              /# We have a variable that produces a str
              /#  - if the value is a list, it is turned into a string by
              /#    joining with join (which must exist).
              if debug: print('In simple')
              chunk += pre
              if isinstance(value, (list, tuple)):
                if join is None:
                  if joins:
                    join = joins.get(var, None)
                  if join is None and len(value) < 2:
                    join = ' '
                if join is None:
                  raise Error('Found list-valued %s without join' % var)
                chunk += join.join(value)
              else:
                if value:
                  /# We replace the var with the value, and maybe with some
                  /# additional text.
                  chunk += value
                  if join:
                    chunk += join
                else:
                  /# If the value is empty, we do replace the var with nothing.
                  pass

            /# Prepare for next iteration
            line = post
            m = r.search(line)

          if chunk is None:
            /# An indication that we are to not add anything.
            pass
          elif isinstance(chunk, BaseSegment):
            self.addChunk(chunk)
          else:
            na = len(attributes)
            if na == 0:
              attribute = None
            elif na > 1:
              attribute = attributes[0]
              metafile = attribute.parent().metafile()
              metafile.warning(
                'Found multiple template variables with associated attributes. '
                'Dropping some.', attr=attribute)
            else:
              attribute = attributes[0]
            chunk += post
            self.addChunk(chunk, attribute=attribute)
    test:
      BaseSegment = metax.c.BaseSegment
      VarSet = metax.c.VarSet

      /# NOTE: The 'construct' instance is not part of a full stack, so
      /# fqn() will fail. Pass fqn into al calls to Instantiate to
      /# avoid it being called.
      construct = self.basics()

      class_scope = construct.rawattr('scope:')
      primattr = metax.attr.IdAttribute(
        test.construct, 'method', 'test', line=3, col=6)
      paramsattr = metax.attr.ComplexBlock(construct, 'params:', [], line=3, col=20)
      comattr = metax.attr.IdAttribute(
        test.construct, 'comment',
        ['This is a comment', 'with multiple lines', 'that should be indented'],
        line=7, col=23)

      /# First, a simple variable substitution
      segment = BaseSegment(class_scope)
      varset = VarSet()
      varset.addVar('method', primattr.value(), attribute=primattr)
      segment.instantiate(
        '@decorators\nmethod ${method}():\n', varset,
        'test', 'demo.cards1.Card.test')
      test.iseqtext(
        '@decorators\nmethod test():\n',
        segment.flattenStr())

      /# Now a list-valued variable with join suffix.
      segment = BaseSegment(class_scope)
      varset.addVar('params', ['a', 'b=1'], attribute=paramsattr)
      segment.instantiate(
        '@decorators\nmethod ${method}(${params?, }):\n', varset,
        'test', 'demo.cards1.Card.test')
      test.iseqtext(
        '@decorators\nmethod test(a, b=1):\n',
        segment.flattenStr())

      /# Now a multi-line value with indentation
      segment = BaseSegment(class_scope)
      varset = VarSet()
      varset.addVar('comment', comattr.value(), attribute=comattr)
      segment.instantiate(
        'Hello\n  ${comment}\nMore here\n', varset,
        'person', 'nm.sp.person')
      test.iseqtext(
        'Hello\n'
        '  This is a comment\n'
        '  with multiple lines\n'
        '  that should be indented\n'
        'More here\n',
        segment.flattenStr())

      /####
      /# Now we parse a real .meta file, obtain a method, and instantiate
      /# the method template to provide a more comprehensive test.

      /# Obtain the 'method' template for python.
      _, _, _, compiler = test.cachedInfo()
      metalang = compiler.metalang()
      context = metalang.context()
      template = context.consinfo('method').templateNamed('python')

      /# Parse the testdata/ex2.meta file
      ex2, scope, construct, path = test.getMetaFile(
        'oopl', 'ex2', debuglevel=0)
      method = ex2.find('/demo.cards0/Card/test')
      method_comment = method.rawattr('comment:')
      method_scope = method.rawattr('scope:')

      /# Obtain the lines in the metafile.
      fs = compiler.fs()
      with fs.open(path, 'r') as fp:
        metatext = fp.read()
      metalines = metatext.split('\n')

      /# Create and initialize a VarSet for use with the method template.
      varset = VarSet()
      comlines = method_comment.value()
      comlines[0] = '\"\"\"' + comlines[0]
      if len(comlines) == 1:
        comlines[0] += '\"\"\"'
      else:
        comlines.append('\"\"\"')
      varset.addVar('modifiers', '')
      varset.addVar('method', method.id())
      varset.addVar('params', '(%s)' % ', '.join(['a', 'b=1']))
      varset.addVar('comment', comlines, attribute=method_comment)
      varset.addVar('preamble', [])
      varset.addVar('scope', method_scope.value(), attribute=method_scope)
      varset.addVar('postamble', [])

      /# Instantiate the method template with the varset.
      segment = BaseSegment(method.primary())
      segment.instantiate(template, varset, method.kind(), method.fqn())
      mapfile = metax.c.MapFile(None, None)
      baselines = []
      segment.flattenLines(baselines, mapfile)
      mapping = mapfile.mapping()
      test.iseqvec(
        [
          '',
          'def test(a, b=1):',
          '  """Some method on a card."""',
          '  a = 1',
          '  return a',
        ],
        baselines)
      /# print(segment.flattenStr(linenum=1))

      /# Verify that the base/meta line mappings are correct.
      for bline, mline, fullid in mapping:
        baseline = baselines[bline-1]
        metaline = metalines[mline-1]
        if metaline.strip() not in baseline:
          test.fail(
            'baseline %d does not match metaline %d:\n  %s\n  %s' %
            (bline, mline, baseline, metaline))
    end method instantiate;

    method appendChunk #:
      Add a string or BaseSegment to the end of the last line in self.chunks(),
      handling multi-line strings and BaseSegment instances.
    params:
      var chunk : any #:
        str or BaseSegment
    scope:
      chunks = self._chunks

      /# We ensure there is always a last chunk in the initializer.
      last_chunk = chunks[-1]
      if isinstance(last_chunk, BaseSegment):
        raise Error(
          'Cannot append to the end of another BaseSegment: use add()')

      if isinstance(chunk, BaseSegment):
        /# Adding a BaseSegment to the end of chunks[-1] is only valid when
        /# chunks[-1] consists solely of whitespace. It establishes how much
        /# indentation to add to the BaseSegment.
        /#
        /# Adding the BaseSegment to the end of chunks[-1] involves adjusting
        /# the indent of the BaseSegment and replacing chunks[-1] with the
        /# BaseSegment.
        /#
        /# TODO(wmh): We should clone chunk before adding it to
        /# chunks, so that its state is maintained here but the original
        /# obj can be modified later without affecting the snapshot.
        indent = chunks[-1]
        if indent.strip():
          raise Error(
            'Cannot append BaseSegment to a line with non-whitespace text')
        chunk.updateIndent(indent)
        chunks[-1] = chunk

      else:
        /# Simple (possibly multi-line) string ... append first element to
        /# last line, add all others.
        if chunk:
          lines = self.__class__.StrChunkToList(chunk)
          chunks[-1] += lines[0]
          chunks.extend(lines[1:])
    test:
      segment = test.segment
      segment2 = test.segment2

      /# Add a simple line.
      test.iseq(['Hello'], segment.chunks())
      segment.appendChunk(' Goodbye')
      test.iseq(['Hello Goodbye'], segment.chunks())
      test.iseq('', segment.indent())

      /# Add a BaseSegment.
      segment2.appendChunk(segment)
      test.iseq('    ', segment.indent())
      test.iseq(['HPB', 'is a brat', segment], segment2.chunks())

      /# Add a multi-line string
      segment.appendChunk('. This is a\nmulti-line string\nwith ending newline\n')
      test.iseq(
        ['Hello Goodbye. This is a', 'multi-line string', 'with ending newline'],
        segment.chunks())
      segment.appendChunk('. And one\nwithout ending newline')
      test.iseq(
        ['Hello Goodbye. This is a', 'multi-line string',
         'with ending newline. And one', 'without ending newline'],
        segment.chunks())
    end method appendChunk;

    method addLine #:
      Add a single string line (no newline!) to myself.
    params:
      var line : str #:
        The line to add. Caller responsibility to ensure no newline in it.
    scope:
      self._chunks.append(line)
    test:
      segment = test.segment
      test.iseq(['Hello'], segment.chunks())
      segment.addLine('World!')
      test.iseq(['Hello', 'World!'], segment.chunks())
    end method addLine;

    method addLines #:
      Add multiple string lines (each with no newline!) to myself.
    params:
      var lines : vec<str> #:
        The lines to add. Caller responsibility to ensure no newline in them.
    scope:
      assert isinstance(lines, list)
      self._chunks.extend(lines)
    test:
      segment = test.segment
      test.iseq(['Hello'], segment.chunks())
      segment.addLines(['how are you', 'doing today?'])
      test.iseq(['Hello', 'how are you', 'doing today?'], segment.chunks())
    end method addLines;

    method addChunk #:
      Add a new str or BaseSegment to my list of items.
    params:
      var chunk : any #:
        The str or BaseSegment to add to self.chunks(). If null, nothing is
        done (but if empty, an empty line is produced).
      var indent : str = '' #:
        The indentation of the new chunk (in addition to any indentation
        it may already have).
      var attribute : metax.attr.Attribute = null #:
        Only needed for str-valued chunks ... allows one to associate an
        attribute with the string.
    scope:
      chunks = self._chunks

      if isinstance(chunk, BaseSegment):
        segment = chunk
        segment.updateIndent(indent)
        /# TODO(wmh): Verify that updating segment indent will properly convey
        /# the indentation to all sub-segments of that segment as well!
        chunks.append(segment)
        if attribute:
          raise Error('Do not provide attribute to addChunk for BaseSegments')
      else:
        if chunk is not None:
          /# TODO(wmh): If chunk is a string without newlines, the following
          /# somewhat more expensive than it needs to be. But performing a check
          /# for newlines is redundant too. Should we disallow newlines are
          /# support them?
          lines = self.__class__.StrChunkToList(chunk)
          if attribute:
            self.attrs()[len(chunks)] = attribute
          chunks.extend([indent + line for line in lines])
    test:
      attr = metax.attr.ComplexBlock(None, 'comment:', [], line=77, col=69)
      segment = metax.c.BaseSegment(attr, chunks=['Hello'])
      test.iseq(['Hello'], segment.chunks())
      segment.addChunk('fun', indent='  ')
      test.iseq(['Hello', '  fun'], segment.chunks())
      segment2 = metax.c.BaseSegment(attr, chunks=['World'])
      test.iseq('', segment2.indent())
      segment.addChunk(segment2, indent='    ')
      test.iseq(['Hello', '  fun', segment2], segment.chunks())
      test.iseq('    ', segment2.indent())
    end method addChunk;

    method appendAddChunks #:
      Given multiple chunks, append the first and add the rest.

      If new_chunks[0] is a BaseSegment instance, chunks[-1] must consist solely
      of whitespace, and it indicates how much the indentation of new_chunks[0]
      should be increased as it is added. Note that subsequent elements of
      new_chunks are not currently indented, so this is really only meaningful
      for a single element lines. TODO(wmh): do we want to indent all values in
      new_chunks by chunks[-1]?

      This was extendFromInterpolationData() in old code.
    params:
      var new_chunks : vec<any> #:
        list of str|BaseSegment
        The chunks to add to self.chunks().'
      var indent : str = '' #:
        How much indentation to add before each chunk in new_chunks when
        adding to self.chunks().
    scope:
      chunks = self.chunks()
      last_chunk = chunks[-1]
      k = len(new_chunks)
      if k and (k > 1 or (k == 1 and new_chunks[0])):
        /# We need to add the first chunk of new_chunks to the end of
        /# chunks[-1].
        assert not isinstance(last_chunk, BaseSegment) and indent == last_chunk, 'indent="%s" last_chunk="%s"' % (indent, last_chunk)
        self.appendChunk(new_chunks[0])
        /# Append all subsequent chunks.
        for item in new_chunks[1:]:
          self.addChunk(item, indent)
      else:
        raise Error('What should we do here?')
    test:
      attr = metax.attr.ComplexBlock(None, 'comment:', [], line=77, col=69)
      segment = metax.c.BaseSegment(attr, chunks=['Hello', '  '])
      test.iseq(['Hello', '  '], segment.chunks())

      segment.appendAddChunks(['fun', 'crazy', ''], indent='  ')
      test.iseq(['Hello', '  fun', '  crazy', '  '], segment.chunks())

      segment2 = metax.c.BaseSegment(attr, chunks=['World'])
      test.iseq('', segment2.indent())
      segment.appendAddChunks([segment2, 'testing'], indent='  ')
      test.iseqvec(
        ['Hello', '  fun', '  crazy', segment2, '  testing'],
        segment.chunks())
      test.iseq('  ', segment2.indent())
    end method appendAddChunks;

    meta
    method StrChunkToList : vec<str> #:
      Convert a potentially multi-line string into a list of strings.

      If the string ends with a newline, it is treated the same as if the
      newline did not exist (the value 'hello\n' is the same as 'hello').
      However, if multiple newlines exist, they represent empty lines (the
      value 'hello\n\n' yields ['hello', '']).
    params:
      var chunk : str #:
        The str-valued chunk to turn into a list.
    scope:
      if chunk and chunk[-1] == '\n':
        chunk = chunk[:-1]
      result = chunk.split('\n')
      return result
    test:
      test.iseqvec(['hello'], metax.c.BaseSegment.StrChunkToList('hello'))
      test.iseqvec(['hello'], metax.c.BaseSegment.StrChunkToList('hello\n'))
      test.iseqvec(['hello', ''], metax.c.BaseSegment.StrChunkToList('hello\n\n'))
    end method StrChunkToList;

  end class BaseSegment;

  class MapFile #:
    Associated with a BaseFile. Contains file lines number mappings from base to
    MetaFile.
  scope:

    field path : str #:
      The path of the mapfile.

    field metapath : str #:
      The absolute real path of the meta file that produced the basefile
      associated with this map.

    field mapping : vec<tuple<int,int,str>> #:
      Each element contains <baseline,metaline,fullid>.
      The fullid is some meta-level attribute (comment, primary, scope, etc.),
      the metaline is the line number in the metafile of that attribute,
      and baselin is the line number in the baselang file generated by
      compiling the metafile.

    lifecycle params:
      var path -> path;
      var metapath -> metapath;
      var mapping : vec = null;
    scope:
      if mapping is None:
        mapping = []
      self.mappingIs(mapping)
    setup:
      _, _, _, metac = test.cachedInfo()      
      path = metac.fs().join(
        metac.workspaceDirectory(), 'demo', 'cards0', '.__init__.py.map')
      test.mapfile = metac.loadMapFile(path)
    end lifecycle;

    method addSubFile #:
      Add additional entries by adjusting a given sub-mapfile.
    params:
      var mapfile : MapFile #:
        The mapfile to add.
      var offset : int #:
        The offset to apply to baseline numbers in the subfile.
    scope:
      data = self.mapping()
      for baseline, metaline, fullid in mapfile.mapping():
        data.append((baseline + offset, metaline, fullid))
    test:
      submapfile = metax.c.MapFile(
        'a', 'b', mapping=[
          (200, 10, 'a:scope'),
          (217, 20, 'b:scope'),
          (251, 30, 'c:scope'),
      ])
      test.mapfile.addSubFile(submapfile, 10)
      /# Need to perform better tests here.
    end method addSubFile;

    method serialize #:
      Write a mapfile to disk.

      This method is paired with Compiler.loadMapFile().

      Returns:
        The path written to.
    params:
      var fp : ostream = out #:
        Where to write the map.
      var indent : str = '' #:
        What to insert before each line.
    scope:
      close = False
      fp.write(u'%s%s\n' % (indent, self.metapath()))
      mapping = self.mapping()
      for bline, mline, fullid in mapping:
        fp.write(u'%s  %8d %8d %s\n' % (indent, bline, mline, fullid))
      if close: fs.close(fp)
    test:
      mapfile = metax.c.MapFile(
        '/some/path/to/mapfile', '/some/path/to/file.meta',
        [(1, 1, 'note1'), (2, 3, 'note2'), (6, 17, 'note3')])
      fp = test.fp()
      mapfile.serialize(fp, indent='  ')
      test.iseqtext(
        '  /some/path/to/file.meta\n'
        '           1        1 note1\n'
        '           2        3 note2\n'
        '           6       17 note3\n',
        fp.getvalue())
    end method serialize;

    method baseToMeta : tuple<str,int> #:
      Convert a line number in a given base file to a metafile/line pair.

      Returns: two-tuple
       0) the metafile path
       1) the line number within the metafile identified by (0).
    params:
      var basenum : int #:
        A line number within self._mapfile.
    scope:
      metapath = self.metapath()
      mapping = self.mapping()

      j = None
      for i, info in enumerate(mapping):
        if basenum < info[0]:
          j = i - 1
          break
      if j is None:
        meta_line = None
      else:
        smap = mapping[j]
        if len(smap) < 1:
          import pprint
          print('Here with %s, %s and j=%d' % (self.path(), self.metapath(), j))
          pprint.pprint(smap)

        base_start = smap[0]
        meta_start = smap[1]
        if meta_start == -1:
          meta_line = None
        else:
          diff = basenum - base_start
          /# print('diff=%d (%d - %d for meta_start %d)' % (diff, basenum, base_start, meta_start))
          if diff < 0:
            /#print(metapath)
            /#print(self.path())
            /#pprint.pprint(mapping)
            /#raise InternalError('Should not be possible for diff to be %d' % diff)
            print('ERROR: Should not be possible for diff to be %d' % diff)
          meta_line = meta_start + diff

      return metapath, meta_line
    test:
      test.iseq(26, test.mapfile.baseToMeta(82)[1])
      test.iseq(27, test.mapfile.baseToMeta(83)[1])
    end method baseToMeta;

  end class MapFile;

  class ConsInfo #:
    An optimized representation of a construct. Maintains:
     - for every feature attribute
       - feature key
       - aliases of feature key
       - all feature values and their aliases
       - default feature value
       - whether multiple values are allowed
     - for primary attribute
       - aliases of the primary attribute
     - for secondary attributes
       - aliases of the secondary attributes
       - type of the attribute value
       - default value
       - whether the attribute key is optional
       - whether the attribute value is optional
     - for each template
       - mapping from template name to template body.
  assocs:
    usertest std assoc copy;
  scope:
    field name : str #:
      Name of the construct.
    field aliases : *vec<str> #:
      A collection of abbreviations of the construct kind.  For example,
      the 'associations' construct has a 'assocs' abbrev.
    field featvals : @map #:
      Maps legal feature values to canonical feature key.
      Each feature value and all of its aliases map to associated feature key.
    field features : @map #:
      Maps legal feature keys and aliases to maps containing:
        cankey: str
        type: str
          Always 'feature'
        attribute: metax.attr.Attribute (or null)
          The attribute instance to use in attrpair() when the specified
          attribute was looked up and not found.
        default: str (optional)
          Default value of this feature
        delim: str (optional)
          Usually not present. If it is present, values are split on this
          value into a list of strings, instead of a single string.
    field secondaries : @map #:
      Maps legal secondary keys and aliases to maps containing:
        cankey: str
        type: str
        keyopt: bool
        valopt: bool
        attribute: metax.attr.Attribute (or null)
          The attribute instance to use in attrpair() when the specified
          attribute was looked up and not found.
        children: vec<str>
          Only present if type is 'complex' or (optionally) 'simple'.
    field primary : @map #:
      Maps legal primary keys and aliases to maps containing:
        cankey: str
        type: str
        keyopt: bool
        valopt: bool
        replacer: str (optional)
    field autokeys : @map #:
      Maps single-char to secondary key, for those secondary attributes that
      are uniquely identified by the first character in the value (and thus
      do not need to specify a key)
    field templates : @map<str,str> #:
      Maps template names to multi-line template bodies.
    field construct_class : class #:
      The class implementing the construct.
    field order : @vec<str> #:
      The order in which attributes for the construct appear in the schema.
      Used in Construct.write().

    lifecycle params:
      var name -> name;
      var type : str #:
        The type of the primary attribute value.
      var construct_class -> construct_class;
      var aliases : vec<str> = null #:
        Abbrevs/aliases for the primary key.
      var valopt : bool = false #:
        If true, the primary attribute does not require an explicit value
        (a value is auto-generated if not provided).
    scope:
      primary_data = {
        'cankey': name, 'type': type, 'keyopt': False, 'valopt': valopt}
      prims = [name]
      if aliases: prims.extend(aliases)
      primary = self.primary()
      for prim in prims:
        primary[prim] = primary_data
    setup:
      self.cons = metax.c.ConsInfo('person', 'id', None)
    end lifecycle;

    method setReplacer #:
      Set a replacer for the primary key.
    params:
      var replacer : str #:
        The name of a secondary attribute to assign the id value to.
    scope:
      data = self.primary()[self.name()]
      data['replacer'] = replacer
    test:
      cons = test.cons
      test.isnull(cons.primary()['person'].get('replacer', None))
      cons.setReplacer('on')
      test.iseq('on', cons.primary()['person'].get('replacer', None))
    end method setReplacer;

    method clone : ConsInfo #:
      Create a copy of myself.
    scope:
      result = self.__class__(self.name(), 'id', self._construct_class)
      result._aliases = copy.copy(self.aliases())
      result._featvals = copy.copy(self.featvals())
      result._features = copy.copy(self.features())
      result._secondaries = copy.copy(self.secondaries())
      result._primary = copy.copy(self.primary())
      result._autokeys = copy.copy(self.autokeys())
      result._templates = copy.copy(self.templates())
      result._order = self.order()[:]
      return result
    test:
      _, context = test.schemaParser('\n')

      for consinfo in context.consmap().values():
        /# Make a copy of each consinfo and verify that its show() output
        /# is exactly the same as the original's show() output.
        conscopy = consinfo.clone()
        fp = self.fp()
        consinfo.show(fp=fp)
        s1 = fp.getvalue()
        fp = self.fp()
        conscopy.show(fp=fp)
        s2 = fp.getvalue()
        test.iseq(s1, s2)
    end method clone;

    method show #:
      Print out this class.
    params:
      var fp : ostream = out #:
        Where to write output.
      var indent : str = '' #:
        What to insert before each line of output.
    scope:
      klass = self._construct_class
      fp.write(
        u'%s%s: %s\n' %
        (indent, self.name(), klass.__name__ if klass else 'No class (generic)'))
      fp.write(u'%s  featvals:\n' % (indent))
      featvals = self.featvals()
      for featval in sorted(featvals):
        fp.write(u'%s    %-20s = %s\n' % (indent, featval, featvals[featval]))
      fp.write(u'%s  features:\n' % (indent))
      features = self.features()
      for featkey in sorted(features):
        feature = features[featkey]
        fp.write(
          u'%s    %-20s = %-20s %s\n' %
          (indent, featkey, feature['cankey'], feature['default']))
      primary = self.primary()
      fp.write(u'%s  primary:\n' % indent)
      for pkey in sorted(primary):
        data = primary[pkey]
        fp.write(
          u'%s    %-20s = %-20s %-20s %-20s %-1s %-1s\n' %
          (indent, pkey,
           data['cankey'], '<required>', data['type'],
           str(data['keyopt'])[0], str(data['valopt'])[0]))
      secondaries = self.secondaries()
      fp.write(u'%s  secondaries:\n' % indent)
      for secondary in sorted(secondaries):
        data = secondaries[secondary]
        type = data['type']
        typestr = type if len(type) <= 20 else type[:19] + '$'
        if 'children' in data:
          children = '  <%s>' % '|'.join(data['children'])
        else:
          children = ''
        fp.write(
          u'%s    %-20s = %-20s %-20s %-20s %-1s %-1s%s\n' %
          (indent, secondary,
           data['cankey'], data['default'], typestr,
           str(data['keyopt'])[0], str(data['valopt'])[0], children))
    test:
      cons = test.cons
      cons.registerSecondary('birthday', 'str', '<empty>', aliases=['dob'])
      cons.registerFeature(
        'gender',
        values={'female': ['f'], 'male': ['m'], 'trans': ['t']},
        default='female',
        aliases=['sex'])
      cons.registerFeature(
        'day',
        values={d: None for d in ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']},
        default='mon')
      cons.registerSecondary(
        'test:', 'complex', '<empty>', children=['birthday'])
      fp = self.fp()
      cons.show(fp=fp)
      test.iseqtext(
        >|"""person: No class (generic)
        >|  featvals:
        >|    f                    = gender
        >|    female               = gender
        >|    fri                  = day
        >|    m                    = gender
        >|    male                 = gender
        >|    mon                  = day
        >|    sat                  = day
        >|    sun                  = day
        >|    t                    = gender
        >|    thu                  = day
        >|    trans                = gender
        >|    tue                  = day
        >|    wed                  = day
        >|  features:
        >|    day                  = day                  mon
        >|    gender               = gender               female
        >|    sex                  = gender               female
        >|  primary:
        >|    person               = person               <required>           id                   F F
        >|  secondaries:
        >|    birthday             = birthday             <empty>              str                  F F
        >|    birthday<*>          = birthday             <empty>              str                  F F
        >|    dob                  = birthday             <empty>              str                  F F
        >|    dob<*>               = birthday             <empty>              str                  F F
        >|    test:                = test:                <empty>              complex              F F  <birthday>
        >|    test<*>:             = test:                <empty>              complex              F F  <birthday>
        >|""",
        fp.getvalue())
    end method show;

    method registerFeature : ConsInfo #:
      Add a feature to this construct.
       - feature keys and aliases must be unique
       - feature values/aliases do NOT need to be unique
    params:
      var key : str #:
        The canonical name of the feature key
      var values : map = null #:
        Maps legal feature values to list of value aliases or None if there are
        no aliases.  If null, no values added ... useful when creating
        a ConsInfo that will be used to extend a pre-existing ConsInfo.
      var default : str = null #:
        The default value of this feature if not provided explicitly. Can
        be null if extending pre-existing ConsInfo without changing the
        default (although this is the most common thing to change when
        extending).
      var aliases : vec<str> = null #:
        Any aliases for the feature key
      var delim : str = null #:
        If null, only one value is supported.
        If non-null, it is a string by which multiple values can be joined
        together.
    scope:
      /# Register the key and its aliases in featkeys()
      self.order().append(key)

      features = self.features()
      fkeys = [key]
      if aliases:
        fkeys.extend(aliases)
      feature = {'cankey': key, 'type': 'feature'}
      if delim is not None:
        feature['delim'] = delim
        fcls = metax.attr.MultiFeatureAttribute
      else:
        fcls = metax.attr.FeatureAttribute
      if default is not None:
        feature['default'] = default
        /# TODO(wmh): Create an Attribute instance for use when LOOKUP is
        /# requested in calls to Construct.attr() and Construct.attrpair() ...
        /# obtain feature['attribute'] and clone it each time.
        feature['attribute'] = fcls(None, key, default)

      for fkey in fkeys:
        if fkey in features:
          raise Error(
            'Attempt to register feature key %s->%s when already maps to %s' %
            (fkey, key, features[fkey]))
        features[fkey] = feature

      /# Register the values and all their aliases in featvals()
      if values:
        featvals = self.featvals()
        for featval in values:
          fvals = [featval] + (values[featval] or [])
          for fval in fvals:
            if fval in featvals:
              raise ConflictingFeatureValues(
                'Attempt to register feature value %s (canonical %s) when already maps to canonical %s' %
                (fval, featval, featvals[fval]))
            featvals[fval] = key

      return self
    test:
      cons = test.cons
      cons.registerFeature(
        'gender',
        values={'female': ['f'], 'male': ['m'], 'trans': ['t']},
        default='female',
        aliases=['sex'])
      cons.registerFeature(
        'day',
        values={d: None for d in ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']},
        default='mon')
      /#cons.show()

      features = {}
      attrs = []
      for key in ('gender', 'day', 'sex'):
        feature = copy.copy(cons._features[key])
        attrs.append(feature.pop('attribute'))
        features[key] = feature
      test.iseq(
        {'gender': {'cankey': 'gender', 'default': 'female', 'type': 'feature'},
         'day': {'cankey': 'day', 'default': 'mon', 'type': 'feature'},
         'sex': {'cankey': 'gender', 'default': 'female', 'type': 'feature'},
        },
        features)
      test.iseqvec(
        ['gender female', 'day mon', 'gender female'],
        [attr.asStr() for attr in attrs])

      test.iseqmap(
        {
          'male': 'gender',
          'm': 'gender',
          'female': 'gender',
          'f': 'gender',
          'trans': 'gender',
          't': 'gender',
          'mon': 'day',
          'tue': 'day',
          'wed': 'day',
          'thu': 'day',
          'fri': 'day',
          'sat': 'day',
          'sun': 'day',
        },
        cons._featvals)

      /# Verify that we cannot register two different features that use the
      /# same feature value.
      cons = metax.c.ConsInfo('person', 'id', None)
      cons.registerFeature(
        'location', default='user',
        values={'user': None, 'test': None, 'meta': None})
      test.raises(
        metax.c.ConflictingFeatureValues,
        cons.registerFeature, 'kind', default='instance',
        values={'instance': None, 'static': None, 'meta': None})
      /# cons.show()
    end method registerFeature;

    method registerSecondary : ConsInfo #:
      Add a secondary to this construct.
    params:
      var key : str #:
        The canonical name of the secondary key. If type is 'simple' or 'complex'
        this key must end with ':'.
      var type : str = null #:
        The type of the attribute value. May be null when extending
        a pre-existing ConsInfo.
      var default : str = null #:
        The default value of this attribute when attribute not specified.
        May be null when extending a pre-existing ConsInfo.
      var aliases : vec<str> = null #:
        Aliases for this secondary key.
      var keyopt : bool = false #:
        If True, the key is optional
      var valopt : bool = false #:
        if True, the value is optional
      var autokey : str = null #:
        A single character which, if present as the current character when
        expecting a secondary key, implicitly identifies this secondary. Useful
        when the first character in a value uniquely identifies a secondary
        attribute so that we don't need to specify the secondary key.
      var children : vec<str> = null #:
        Only present if type is 'complex' or (optionally) 'simple'. The
        list of construct kinds that are legal to appear within the block
        (if simple, those construct kinds legal if the block is upgraded to
        complex via a <*> selector).
    scope:
      self.order().append(key)
      isblock =  type in ('simple', 'complex')
      if isblock:
        if key[-1] != ':':
          raise Error(
            'Construct %s attribute "%s" must end with ":" (%s)' %
            (self.name(), key, type))
      data = {
        'cankey': key,
        'type': type,
        'default': default,
        'keyopt': keyopt,
        'valopt': valopt,
        'autokey': autokey,
      }

      if autokey:
        autokeys = self.autokeys()
        if autokey in autokeys:
          raise Error(
            'Attempt to register autokey "%s" for %s and %s' %
            (autokey, key, autokeys[autokey]))
        autokeys[autokey] = key
      if children:
        data['children'] = children

      /# 
      /# TODO(wmh): We need a better way to handle the following situation:
      /#   panel :<*l>:
      /#     ...
      /# The panel construct has auto-assigned id *if* the token after the
      /# 'panel' token is recognized as a secondary attribute key. That is
      /# what 'secondaries' is for, and we of course add the newly added
      /# secondary key and its aliases. We *could* also add the baselang
      /# variants of key and its aliases, but this would be needed for ALL
      /# baselangs, which hugely inflates the size of secondaries. Can we 
      /# do better?  See CODETANGLE(baselang_keys) in MetaFile.parseConstruct().
      keys = [key, metax.attr.Attribute.BasedAttr(key, '*')]
      if aliases:
        for alias in aliases:
          if isblock:
            if alias[-1] != ':':
              raise Error(
                'Construct %s attribute %s alias "%s" must end with ":" (%s)' %
                (self.name(), key, alias, type))
          keys.append(alias)
          keys.append(metax.attr.Attribute.BasedAttr(alias, '*'))
          /# TODO(wmh): Add every baselang version of alias too? That is excessive.

      secondaries = self.secondaries()
      for k in keys:
        secondaries[k] = data

      /# The following code must occur after the code above.
      /#  - the code below invokes methods that eventually invoke this method
      /#    again, and the state in self.secondaries() must already be
      /#    populated to a catch-22.

      /# We create an Attribute instance that will be used when an EMPTY version
      /# of this attribute is requested (explicitly or via lookup)
      empty_func = MetaFile.AttrValueEmpty[data['type']]
      try:
        empty_value = empty_func()
        empty = MetaFile.CreateNewAttribute(
          None, self, key,
          key=key, value=empty_value, typecheck=False, secondary=True)
      except InvalidAttributeType:
        empty = None
      data['empty'] = empty

      /# Now we create an Attribute instance that will be returned if this
      /# attribute key is requested from a construct with LOOKUP semantics
      /# and the key (or an alias) is not specified explicitly in the construct.
      attribute = None
      done = False
      if default == '<required>':
        /# No need to create an default Attribute because one is always required.
        done = True
      elif default == '<empty>':
        /# We are to return an empty attribute ... we already have such an
        /# attribute, so we use it.
        attribute = empty
        done = True
      elif type == 'expr' and default == '<special>':
        /# TODO(wmh): Can we avoid making this check here? Very specialized,
        /# and every additional check slows down the compiler, as this method
        /# is called very often.
        default = None
      elif type == 'type':
        /# We need to upgrade the string-valued default to a Type instance.
        default = Type.Instance(default)
      /# TODO(wmh): We may need to add additional elif clauses above to handle
      /# other attribute types.
      if not done:
        attribute = MetaFile.CreateNewAttribute(
          None, self, key,
          key=key, value=default, typecheck=False, secondary=True)
      data['attribute'] = attribute

      return self
    test:
      cons = test.cons
      cons.registerSecondary('birthday', 'str', '<empty>', aliases=['dob'])
      cons.registerSecondary(
        'test:', 'complex', '<empty>', children=['birthday'])

      secondaries = cons._secondaries
      attrs = []
      empties = []

      copysecs = {}
      for key in ('dob', 'birthday', 'test:'):
        secondary = copy.copy(secondaries[key])
        if 'attribute' in secondary:
          attrs.append(secondary.pop('attribute'))
        if 'empty' in secondary:
          empties.append(secondary.pop('empty'))
        copysecs[key] = secondary
      test.iseq(
        {
          'dob': {
            'default': '<empty>',
            'valopt': False,
            'keyopt': False,
            'type': 'str',
            'cankey': 'birthday',
            'autokey': None,
          },
          'birthday': {
            'default': '<empty>',
            'valopt': False,
            'keyopt': False,
            'type': 'str',
            'cankey': 'birthday',
            'autokey': None,
          },
          'test:': {
            'valopt': False,
            'cankey': 'test:',
            'default': '<empty>',
            'children': ['birthday'],
            'keyopt': False,
            'type': 'complex',
            'autokey': None,
          },
        },
        copysecs)
      test.iseqvec(
        [attr.key() for attr in attrs], ['birthday', 'birthday', 'test:'])
      test.iseqvec(
        [attr.key() for attr in empties], ['birthday', 'birthday', 'test:'])
    end method registerSecondary;

    method registerTemplate #:
      Add a named template.
    params:
      var name : str #:
        The name of the template.
      var text : str #:
        The text of the template, with variable interpolation requests.
    scope:
      self._templates[name] = text
    test:
      test.iseq({}, test.cons._templates)
      test.cons.registerTemplate('ex', 'misc text')
      test.iseq({'ex': 'misc text'}, test.cons._templates)
    end method registerTemplate;

    method templateNamed : str #:
      Obtain the template with given name.
    params:
      var name : str;
    scope:
      result = self._templates.get(name, None)
      /#if result is not None:
      /#  result += '\n'

      if result is None:
        raise Error(
          'Failed to find template named %s in %s' % (name, self.name()))
      return result
    test:
      test.raises(metax.c.Error, test.cons.templateNamed, 'ex')
      test.cons.registerTemplate('ex', 'misc text')
      test.iseq('misc text', test.cons.templateNamed('ex'))
    end method templateNamed;

    method findTemplate : str #:
      Find a template.
    params:
      var names : vec<str> #:
        The names of possible templates. First one found is returned.
    scope:
      result = None
      for name in names:
        result = self._templates.get(name, None)
        if result:
          break
      if result is None:
        raise Error(
          'Failed to find template named %s in %s' % (name, self.name()))
      return result
    test:
      test.raises(metax.c.Error, test.cons.templateNamed, 'ex')
      test.cons.registerTemplate('ex1', 'misc text')
      test.cons.registerTemplate('ex2', 'misc text2')
      test.cons.registerTemplate('ex3', 'misc text3')
      test.iseq('misc text2', test.cons.findTemplate(['missing', 'ex2', 'ex3']))
    end method findTemplate;

  end class ConsInfo;

  class ConsGroup #:
    Maintains a collection of ConsInfo instances.
     - keeps the list of all tokens that can appear before a construct kind
     - keeps the regexp identifiying a construct kind
     - ensures that constraints related to feature keys, feature values,
       primary keys and secondary keys are abided by.
  scope:

    field kinds : vec<str> #:
      A list of kinds.

    field primaries : map<str,ConsInfo> #:
      Maps all tokens representing primary keys (including aliases) to
      ConsInfo instances.

    field features : map<str,tuple<str,str,vec<str>>> #:
      Maps all feature keys/aliases and feature values/aliases to tuples:
       0) fkind : str
         One of 'key' or 'value'
       1) fkey : str
         A canonical feature key
       2) kinds : vec<str>
         A list of construct kinds (aka primary key) that have this
         feature key or value.

    lifecycle params:
      var kinds -> kinds;
      var primaries -> primaries;
      var features -> features;
    scope:
    end;

    method show #:
      Print out this instance in humand-readable format.
    params:
      var fp : ostream = out #:
        Where to write to.
    scope:
      fp.write(u'ConsGroup: %s\n' % ','.join(self.kinds()))

      primaries = self.primaries()
      fp.write(u'  Primaries:\n')
      for token in sorted(primaries):
        fp.write(u'    %-20s = %s\n' % (token, primaries[token].name()))

      fp.write(u'  Features:\n')
      features = self.features()
      for token in sorted(features):
        info = features[token]
        fp.write(
          u'    %-20s = %-20s %-20s %s\n' %
          (token, info[0], info[1], ','.join(sorted(info[2]))))
    test:
      _, _, _, compiler = test.cachedInfo(metal='meta')
      context = compiler.bootstrapContext()
      /# TODO(wmh): The following is not a sensible collection of constructs to
      /# pass to legalInfo. When the new schema for Meta(Oopl) is defined, use
      /# ['method', 'field'] for a more realistic example.
      consgroup = context.legalInfo(
        ['MetaLanguage', 'Construct', 'Attribute', 'FeatureValue'])
      fp = test.fp()
      consgroup.show(fp=fp)
      /# print(fp.getvalue())
    end method show;

  end class ConsGroup;

  class Context #:
    A Context maintains the set of (modified) ConsInfo instances that apply when
    parsing a Construct (based on the set of constructs legal in the Meta
    language and any 'config' blocks in the lexical chain above the current
    construct).

    We do NOT create a Context for every Construct or even every ComplexBlock.
    Only if a Construct has a 'config' attribute do we need to introduce a
    new Context.
  scope:

    field parent : Context #:
      The parent context.  Only null when parsing a schema file. When
      parsing a metafile, the Context associated with the MetaLanguage
      is used to start the parsing process.

    field consmap : map<str,ConsInfo> #:
      Maps construct primary keys to ConsInfo instances. Represents all
      constructs defined in the MetaLanguage, along with any changes made to
      constructs/attributes by 'config' blocks in the lexical chain above the
      construct this context belongs to.

      A MetaLanguageConstruct exists for each MetaLanguage, and its 'config'
      block contains a collection of Construct constructs whose 'config' block
      contains a collection of Attribute constructs whose 'config' block
      contains a collection of FeatureValue constructs. The information within a
      Construct relevant to parsing the construct is summarized in a ConsInfo
      instance.

      Most constructs in most Meta Languages define a 'config' secondary
      attribute that allows one to change aspects of constructs that will
      apply to all (recursive) complex blocks within the construct. The
      Construct instances within the 'config' block imply the creation of a
      new ConsInfo (inheriting from the parent ConsInfo with new values
      for the modified items).
    end field consmap;

    field compiler : Compiler #:
      Since every construct maintains a Context, by storing a compiler instance
      in Context every construct has access to everything (metafile, baselang,
      metalang, compiler, etc.).  Not needed for proper functioning of the
      class itself, just cached here as a convenient means of providing the
      compiler to constructs without requiring that each construct store
      the compiler explicitly (same rationale applies to 'metafile' below).

    field autocount : int = 0 #:
      Used to generate auto-assigned ids.

    field legals : @map #:
      Maps strings of comma-separated (alphabetically sorted) construct kinds
      to maps of all kinds/aliases to ConsInfo instances. This is used by
      legalInfo() to cache computed results.

    field metafile : MetaFile #:
      The MetaFile that this Context resides within. Since every Construct
      maintains a Context, by storing a MetaFile in the Context each Construct
      has access to its MetaFile without having to traverse its parent chain.

      Note that this does mean that we must create a new Context for every
      MetaFile, even if no explicit config block exists at top-level within the
      MetaFile.
    end field metafile;

    static
    field Tokens : map<@str,@str> #:
      A collection of constants. Code should use self.token('<key>')
      instead of hard-coding any of these.  For now they are stored here
      in a class var, but we may want to allow customization within
      config blocks, in which case they will become instance fields.

    lifecycle params:
      var parent -> parent;
      var consmap -> consmap;
      var compiler -> compiler;
      var metafile -> metafile;
    scope:
    clinit:
      cls.TokensIs({
        /# What character starts a new scope. Block-valued attributes must
        /# end with this.
        'scope': ':',

        /# What separates identifiers in a fully qualified scope. For
        /# example, nm.sp.Class.meth is separated by '.'.
        'scope_sep': '.',

        /# What terminates a construct.
        'term': ';',

        /# The secondary terminator text.
        'end': 'end',

        /# Meta-level one-line comment
        'remark': '/#',

        /# How many characters is each scope indented relative to parent.
        'blockdent': 2,

        /# What is inserted before field names to produce raw field name
        /#  - CODETANGLE(fieldinit): See FieldConstruct.expandMeta() and
        /#    BaseLanguageOopl.initCode()
        'field_prefix': '_',

        /# What is inserted after field names to produce raw field name
        /#  - CODETANGLE(fieldinit): See FieldConstruct.expandMeta() and
        /#    BaseLanguageOopl.initCode()
        'field_suffix': '',

        /# The character used to indicate that the class in a type is
        /# to be treated "as is".
        'explicit_class_indicator': '^',
      })
    setup:
      _, _, _, compiler = test.cachedInfo(metal='meta')
      self.compiler = compiler
      self.context = compiler.bootstrapContext()
    end lifecycle;

    method subclone : Context #:
      Make a copy of myself and set the copy's parent to self.
    params:
      var metafile : MetaFile = null;
    scope:
      if metafile is None:
        metafile = self.metafile()
        if metafile is None:
          raise Error('Must provide metafile when self has no metafile')
      compiler = self.compiler()

      /# Group all tokens sharing same ConsInfo together
      tmp = {}
      for key, consinfo in self.consmap().items():
        tmp.setdefault(consinfo, []).append(key)

      /# Create a copy of consmap
      consmap = {}
      for consinfo, keys in tmp.items():
        /# TODO(wmh): It is not technically necessary to create clones of
        /# every ConsInfo ... it is only those constructs that have 'config'
        /# blocks that need to be cloned.  How can we detect this
        /# efficiently?
        conscopy = consinfo.clone()
        for key in keys:
          consmap[key] = conscopy
      return self.__class__(self, consmap, compiler, metafile)
    test:
      metafile, parent = test.schemaParser('\n')
      parent.metafileIs(None)
      test.raises(metax.c.Error, parent.subclone)
      context = parent.subclone(metafile=metafile)
      test.issame(metafile, context.metafile())
      /# TODO(wmh): Add some tests to verify that parent and context are
      /# now truly independent from one another (changes to one do not
      /# result in changes in the other).
    end method subclone;

    method autoId : str #:
      Obtain a new id.
    scope:
      self.autocountIs(self.autocount() + 1)
      return 'Meta__%d__' % self.autocount()
    test:
      test.iseq('Meta__1__', test.context.autoId())
      test.iseq('Meta__2__', test.context.autoId())
    end method autoId;

    meta
    method IsAutoId : bool #:
      True if the id is auto-assigned.
    params:
      var id : str;
    scope:
      return bool(re.match('^Meta__(\d+)__$', id))
    test:
      test.istrue(metax.c.Context.IsAutoId('Meta__39__'))
      test.isfalse(metax.c.Context.IsAutoId('foo'))
    end method IsAutoId;

    method consinfo : ConsInfo #:
      Obtain the consinfo for a given construct kind.
    params:
      var kind : str #:
        The construct kind (aka primary key).
    scope:
      return self.consmap().get(kind, None)
    test:
      test.iseq('Construct', test.context.consinfo('Construct').name())
      _, _, context, compiler = test.cachedInfo()
      consinfo = context.consinfo('lifecycle')
      test.iseq(
        {'lifecycle': {
          'valopt': True, 'keyopt': False, 'type': 'id', 'cankey': 'lifecycle'}},
        consinfo.primary())
      /# consinfo.show()
    end method consinfo;

    method attrinfo : any #:
      docstr
    params:
      var kind : str #:
        The construct kind (or alias) that attr info is desired for.
      var key : str #:
        The attribute key (or alias) that info is desired for
    scope:
      consinfo = self.consinfo(kind)
      if consinfo is None:
        /# context.show()
        raise Error('Failed to find consinfo for "%s"' % kind)
      info = (
        consinfo.features().get(key) or consinfo.secondaries().get(key))
      return info, consinfo
    test:
      _, metalang, context, _ = test.cachedInfo()
      info, consinfo = context.attrinfo('method', 'location')
      info = copy.copy(info)
      attribute = info.pop('attribute')
      test.iseqmap(
        {'default': 'user', 'type': 'feature', 'cankey': 'location'},
        info)
    end method attrinfo;

    method register #:
      Register a ConsInfo instance with this Context.  This method is invoked
      in two related situations:
       - when parsing a MetaLanguage schema, a Context is created, and
         Context.register() is invoked on the ConsInfo instance associated with
         the Construct.
       - when parsing an arbitrary construct, if a 'config' secondary attribute
         is encountered, the Context associated with the construct is changed
         (a copy of the parent Context is created and modified by calling
         Context.register() for the ConsInfo version of each Construct found
         within the 'config' block).
    params:
      var consinfo : ConsInfo #:
        The 'compiled' version of a Construct to be registered into this
        Context.
    scope:
      consmap = self.consmap()
      primary = consinfo.name()
      if primary in consmap:
        /# We are probably in a 'config' block modifying a construct relative to
        /# what exists in the parent context. One should make a copy of the
        /# pre-existing ConsInfo and invoke registerFeature() or
        /# registerSecondary on that copy, rather than re-registering a
        /# ConsInfo.
        raise Error('Attempt to re-register ' + primary)
      else:
        /# We are registering this construct for the first time.
        consmap[primary] = consinfo
    test:
      /# Note that bootstrapContext() invokes register() once for each
      /# construct it emulates (5 times).
      context = self.context
      test.iseqvec(
        ['Attribute', 'BaseLanguage', 'Construct', 'FeatureValue', 'File',
         'MetaLanguage', 'Template'],
        sorted(context.consmap()))

      /# Now we verify that invoking register on a pre-existing construct
      /# raises an exception.
      consinfo = metax.c.ConsInfo('Attribute', 'id', metax.meta.AttributeConstruct)
      test.raises(metax.c.Error, context.register, consinfo)
    end method register;

    method token : any #:
      Obtain the value of a named token. Raises KeyError if not recognized.
    params:
      var name : str;
    scope:
      return Context.Tokens()[name]
    test:
      context = test.context
      test.iseq(';', context.token('term'))
    end method token;

    method show #:
      Print out this class.
    params:
      var fp : ostream = out #:
        Where to write output.
      var indent : str = '' #:
        What to insert before each line of output.
    scope:
      metafile = self.metafile()
      fp.write(u'Context: %s\n' % (metafile.path() if metafile else 'null'))
      indent = indent.decode('utf8')
      subindent = indent + '  '
      consmap = self.consmap()
      for key in sorted(consmap):
        consinfo = consmap[key]
        consinfo.show(fp=fp, indent=subindent)
    test:
      fp = test.fp()
      test.context.show(fp=fp)
      out = fp.getvalue()
      test.contains(
        '      Attribute            = Attribute            <required>           word                 F F\n',
        out)
    end method show;

    method legalInfo : ConsGroup #:
      Obtain all legal tokens that can appear at/before any of a given set
      of construct kinds.
    params:
      var kinds : vec<str> #:
        The constructs legal in a particular complex block.  May be null,
        in which case all constructs provided by the meta language are
        legal.
    scope:
      consmap = self.consmap()
      if kinds is None:
        kinds = sorted(consmap.keys())
      else:
        kinds = sorted(kinds)
      kindskey = ','.join(kinds)

      legals = self.legals()
      result = legals.get(kindskey, None)
      if result is None:
        primaries = {}
        features = {}
        for kind in kinds:
          consinfo = consmap.get(kind, None)
          if consinfo is None:
            /# No information has been found in consmap for this kind. This can
            /# happen, for example, when parsing a schema file for a sublang of
            /# Meta(Meta) ... the legal kinds include construct from the sublang
            /# but consmap may only support Meta(Meta).
            continue
          assert consinfo.name() == kind
          for key in consinfo.primary().keys():
            if key in primaries:
              raise Error('Attempt to add %s twice' % key)
            primaries[key] = consinfo

          /# consinfo.features() maps feature keys/aliases to maps containing
          /# cankey, etc.
          for token, fkeyinfo in consinfo.features().items():
            fkey = fkeyinfo['cankey']
            info = features.get(token, None)
            if info:
              if info[0] != 'key':
                raise Error(
                  'Token "%s" is a feature key for %s and a feature value for %s' %
                  (token, kind, info[2]))
              elif info[1] != fkey:
                raise Error(
                  'Token "%s" is a feature key for both %s and %s' %
                  (token, kind, info[2]))
              else:
                info[2].append(kind)
            else:
              features[token] = ('key', fkey, [kind])

          /# consinfo.featvals() maps legal feature values to canonical feature
          /# keys.
          for token, fkey in consinfo.featvals().items():
            info = features.get(token, None)
            if info:
              if info[0] != 'value':
                raise Error(
                  'Token "%s" is a feature value for %s and a feature key for %s' %
                  (token, kind, info[2]))
              /#elif info[1] != fkey:
              /#  raise Error(
              /#    'Token "%s" is a feature value for both %s and %s' %
              /#    (token, kind, info[2]))
              else:
                info[2].append(kind)
            else:
              features[token] = ('value', fkey, [kind])
        result = ConsGroup(kinds, primaries, features)
        legals[kindskey] = result
      return result
    test:
      context = self.context
      test.iseqmap({}, context.legals())
      res1 = context.legalInfo(['Construct'])
      test.iseqvec(['Construct'], sorted(res1.primaries()))
      res2 = context.legalInfo(['Construct'])
      test.issame(res1, res2)
      res3 = context.legalInfo(['Construct', 'Attribute'])
      test.iseqvec(['Attribute', 'Construct'], sorted(res3.primaries()))
    end method legalInfo;

  end class Context;

  class Type #:
    An abstraction of a Meta type.

    Primitive Types
     - bool
     - char (nightmare of unicode)
     - int<1> to int<128>, with what 'int' refers to be customizable.
        - implemented with masking, shifting, etc.
     - real<32>, real<64>, real<128> with 'real' being customizable.
     - complex

    Interned String Type
     - See discussion in <<src_root>/README.md

    Native Types
    - These are types that are mapped to baselanguage-level types where
      possible.
    - A meta class exists to define the interface, but the same interface
      is mapped onto base language functionality.
    - All primitive types provide a similar 'virtual' interface, so methods
      can be sent to numbers: 5.2.round, 7.floor, etc.
    - Native types are those that:
       - exist in Type.Natives(), or
       - start with 'meta!' or '!'

    To be supported:
     - unique, shared, weak pointers
        - http://www.codeproject.com/Articles/570638/Ten-Cplusplus-Features-Every-Cplusplus-Developer
     - http://clang.llvm.org/docs/ThreadSafetyAnalysis.html
     - literals for units of measurement
        - Ex: 95kg, 1.2m, 37oC, etc.
        - https://en.wikipedia.org/wiki/Units_of_measurement
        - kinds of units
           - length (metre, foot, yard, etc)
           - mass (kilogram, pound, stone, etc.)
           - time (second, minute, hour, day, week)
           - electric current (ampere, ???)
           - temperature (kelvin, celsius, fahrenheit)
           - luminous intensity (candela, ...)
           - amount of substance (mole, ...)
           - ... how to deal with derived units?

    Notes on combining the pass-by indicator ('@', '*' and '&') with
    constness indicator ('#'):
      pass-by-pointer
         *T   -> pointer to T
         *#T  -> pointer to const T (cannot modify what var points to)
         #*T  -> const pointer to T (can change var to a different value)
         #*#T -> const pointer to const T (cannot modify var or what points to)

         &T   -> reference to T
         &#T  -> reference to constant T (cannot modify T, cannot modify ref)
     no! #&T  -> const reference to T, but references are always const so
                 this is the same as &T (and is disallowed to avoid clutter).

         @T   -> by-value T (copy if arg, guartanteed to be non-null if field)
         @#T  -> copy of const T (no different than just @T in most cases, 
                 but may be useful for local vars where one wants to remind
                 oneself not to modify something ... const int val)
     no! #@T  -> const copy of T (same as @#T which is more canonical so this
                 is disallowed)

    Notes about unique_ptr, shared_ptr and weak_ptr.
          u*T -> std::unique_ptr<T>
         u*#T -> std::unique_ptr<const T>
         #u*T -> const std::unique_ptr<T>
        #u*#T -> const std::unique_ptr<const T>

          s*T -> std::shared_ptr<T>
         s*#T -> std::shared_ptr<const T>
         #s*T -> const std::shared_ptr<T>
        #s*#T -> const std::shared_ptr<const T>

          w*T -> std::weak_ptr<T>
         w*#T -> std::weak_ptr<const T>
         #w*T -> const std::weak_ptr<T>
        #w*#T -> const std::weak_ptr<const T>

    Other rules about types:
     no! &&T  -> cannot take reference to a reference
         &*T  -> a reference to a pointer (so the pointer itself can be
                 modified)
     no! *&T  -> a pointer to a reference is not allowed
     no! #&   -> use &#
     no! #@   -> use @#
     no! ##   -> redundant
     no! @*   -> use *
     no! @&   -> use &
     no! u#*T -> use #u*T
     no! s#*T -> use #s*T
     no! w#*T -> use #w*T

    Legal type prefixes are:
      @#?
      &?(#?[usw]?\*)*#?

    How to type a variable V.
     - Establish the base type T
     - Is T modifiable?
         If not, prefix with '#'
     - Can the variable be null?
        - if not
          - for a field or local var, prefix with '@'
          - for an arg, prefix with '&' (pass-by-ref) or '@' (pass-by-value)
     - Is T a class type and can variable can be null?
        - prefix with '*' or leave off (default is to prefix with '*')
     - If the variable is a primitive type and one wants pass-by-refence
       semantics,
        - prefix with '&' or '*' (boxed class will be used if lang does not
          support)
     - Any '*' in the prefix can be prefixed with 'u' (unique ptr), 's'
       (shared ptr) or 'w' (weak ptr) to obtain implicit memory management,
       and can be further prefixed by '#' to indicate the pointer itself is
       const (cannot be changed).  Note that in languages that provide
       garbage collection [usw] is ignored, but '#' can still be semantically
       useful.

    Does it make sense to claim that Meta has any primitive types?  Maybe
    these are just numeric examples of native types supported by Meta?

    On the other hand, it is useful to be able to ask if the type is primitve
    in situations where none of @, * or & are specified ... primitive types
    default to @, others to * (see details in Type.Instance())

    ----------------------------------------------------------------------
    Type Analysis and Inference In Meta

    Meta has the following data-structures useful for type analysis and
    inference
     - ClassConstruct maintains
        - the collection of all 'field' instances
        - the collection of all 'method' instances
       and they are initialized in ...?

     - ExecutableConstruct maintains:
        - the collection of all ...?

  scope:

    meta
    method Instance #:
      Return the interned instance of a Type given a representation.
    params:
      var raw : str #:
        The raw type
      var allow_invalid : bool = false #:
        If True, invalid types do not raise an Error.
      var cons : str = null #:
        The construct kind.  Used to determine what the default prefix
        should be when one is not specified.
      var default_prefix : str = null #:
        This is almost never given, but can be provided for special snowflake
        types whose default prefix differs from the normal rules ('@' for
        primitives, '*' for anything else). See the Type clinit: block for an
        example.
      var namespace_function : function = null #:
        A function accepting no args that returns the namespace within which
        the Type appears.  Used to resolve relative class types.  If resolution
        is needed, it is an error not to provide such a function
    scope:
      wrapper = None
      result = cls.Repository.get(raw, None)
      if not result:
        match = cls.LEGAL_METATYPE_RE.match(raw)
        if match:
          prefix, base, params_str = match.groups()
          params = cls.ParseTypes(
            params_str, allow_invalid=allow_invalid,
            namespace_function=namespace_function)
          native = (
            (base in cls.Natives())
            or base.startswith('meta!')
            or base[0] == '!')
          primitive = base in cls.Primitives()
          if not prefix or prefix == '#':
            /# The rationale for what prefix to use when one is not explicit
            /# provided is discussed in detail in <<src_root>>/README.md. The
            /# summary is:
            /#   - Use '@' for primitive types
            /#   - Use '&' for 'str' (because &str is interpreted specially)
            /#   - Use '*' for all other types.
            if base == 'void' or primitive:
              prefix = prefix + '@'
            elif default_prefix is not None:
              prefix = default_prefix
            else:
              prefix = '*' + prefix

          tokens = Context.Tokens()
          use_native = native or primitive
          if (
            not use_native
            and tokens['scope_sep'] not in base
            and base[0] != tokens['explicit_class_indicator']
          ):
            /# This type refers to a relative class name (as opposed to a fully
            /# qualified one).  We need to establish both a Type instance that
            /# uses the fully qualified class name, and a TypeWrapper instance
            /# that captures this particular relative type.
            if namespace_function is None:
              raise Error('Must provide a namespace')
            namespace = namespace_function()
            if not isinstance(namespace, metax.oopl.NamespaceConstruct):
              print('ERROR: %s() = %s (%s) when resolving type "%s"' % (
                namespace_function,
                namespace, namespace.kindid() if namespace else None, base))
              
              raise Error(
                'Failed to establish namespace ... cannot qualify %s' % raw)

            wrapper = namespace.getType(raw)
            if wrapper:
              /# We have previously seen the same relative type, and can use it.
              result = wrapper.type()
            else:
              /# We need to create Type and TypeWrapper instances.
              nmsp = namespace.id()
              fqcn = nmsp + '.' + base
              fqraw = prefix + fqcn + (params_str or '')
              result = cls(
                fqraw, prefix, fqcn, params=params, native=False)
              wrapper = TypeWrapper(result, raw)
              namespace.registerType(wrapper)
          else:
            result = cls(raw, prefix, base, params=params, native=use_native)
        else:
          if allow_invalid:
            /# We are to return a Type instance even though it is invalid.
            result = cls(raw, prefix=None, base=None, native=False)
          else:
            result = None
        if result:
          cls.Repository[result.raw()] = result
      if not allow_invalid:
        if not result or not result.isValid():
          raise metax.root.Error('Invalid type %s (%s)' % (raw, result))
      return wrapper or result
    test:
      /# Create a namespace for use when a type needs to resolve a relative
      /# class.
      _, _, context, _ = self.cachedInfo()
      namespace = metax.oopl.NamespaceConstruct.NewFromData('nm.sp', context)
      nmspfunc = lambda: namespace

      /# The following types should all be valid and verbatim
      for mtstr in (
        '*str',
        '@void',
        '*map<*str,@int>',
        '*tuple<&#int,*#int,#*int,@#int>',
        '*nm.sp.Person',
      ):
        typ = metax.c.Type.Instance(mtstr, namespace_function=nmspfunc)
        self.assertTrue(typ.isValid())
        test.iseq(mtstr, typ.asStr(mode=1))

      /# The following types are valid but involve a rewrite.
      for mtstr, canonical in (
        ('int', '@int'),
        ('void', '@void'),
        /# TODO(wmh): Should '*^Object' be cleaned up or left as is?
        /# Note that '^' is not legal in types, only in 'parent', 'metaparent',
        /# and 'testparent' attributes of 'class' constructs, which have type
        /# 'word', not 'type'.  So having '^Object' in this list is kinda
        /# wrong to begin with.
        ('^Object', '*^Object'),
        ('str', '*str'),
        ('a.b.Person', '*a.b.Person'),
        ('map<int,*str,*a.b.Person>', '*map<@int,*str,*a.b.Person>'),
        ('A', '*nm.sp.A'),
        ('*A', '*nm.sp.A'),
        ('u*A', 'u*nm.sp.A'),
        ('s*A', 's*nm.sp.A'),
        ('w*A', 'w*nm.sp.A'),
        ('#u*A', '#u*nm.sp.A'),
        ('#s*A', '#s*nm.sp.A'),
        ('#w*A', '#w*nm.sp.A'),
        /# TODO(wmh): support this!
        /#('map<int,str,Person>', '&map<@int,*str,*Person>')
      ):
        typ = metax.c.Type.Instance(mtstr, namespace_function=nmspfunc)
        self.assertTrue(typ.isValid())
        test.iseq(canonical, typ.asStr(mode=1))

      /# The following types are invalid
      for mtstr in (
        'int@',
        'u#*A',
        's#*A',
        'w#*A',
      ):
        typ = metax.c.Type.Instance(
          mtstr, allow_invalid=True, namespace_function=nmspfunc)
        test.iseq(False, typ.isValid())
    end method Instance;

    meta
    method ParseTypes : vec<Type> #:
      Parse a comma-separated list of types into a list of Types.

      This parses the parameterized types associated with container classes.
      For example, a Map is of the form '*map<str,@int>', and a
      vector of vector of maps is: vec<vec<map<str,*int>>>'.  This
      method does not parse the entire type, just the portion inside the <...>,
      so for our two examples, params_str would be 'str,@int' and
      'vec<map<str,*int>>' respectively.
    params:
      var params_str : str #:
        The comma-separated list of within-parameter types to parse.
      var allow_invalid : bool = false #:
        If True, allow invalid types, otherwise raise Error.
      var namespace_function : function = null #:
        A function accepting no args that returns the namespace within which
        the Type appears.  Used to resolve relative class types.  If resolution
        is needed, it is an error not to provide such a function
    scope:
      if not params_str:
        return None
      result = []
      angles = 0
      start = 0
      i = 0
      N = len(params_str)
      sep = ','
      while True:
        if i > N:
          break
        if i == N or (params_str[i] == sep and angles == 0):
          raw = params_str[start:i]
          try:
            /# We first check if 'raw' is an integer.
            type_ = int(raw)
          except ValueError:
            type_ = cls.Instance(
              raw, allow_invalid=allow_invalid,
              namespace_function=namespace_function)
          result.append(type_)
          i += 1
          start = i
        else:
          c = params_str[i]
          if c == '<':
            angles += 1
          elif c == '>':
            angles -= 1
            if angles < 0:
              /# TODO(wmh): What to do when allow_invalid is true?
              raise metax.root.Error(
                'Invalid params (too many <): %s' % params_str)
          i += 1
      return result
    test:
      metax.c.Type.Repository = None
      metax.c.Type.Meta__Initialize()
      res = metax.c.Type.ParseTypes('*str,@int')
      test.iseq(['*str', '@int'], [t.raw() for t in res])
      test.iseq(
        ['&str', '*str', '@int', 'str'], sorted(metax.c.Type.Repository.keys()))
      res2 = metax.c.Type.ParseTypes('*map<*str,@int>')
      test.iseq(1, len(res2))
      params = res2[0].params()
      test.iseq(['*str', '@int'], [t.raw() for t in params])
      self.assertTrue(params[0] is metax.c.Type.Repository['*str'])
      self.assertTrue(params[1] is metax.c.Type.Repository['@int'])
      res3 = metax.c.Type.ParseTypes('3')
      test.iseq([3], res3)
    end method ParseTypes;

    meta
    method ShowRepository #:
      Print out the repository (useful during debugging).
    params:
      var fp : ostream = out;
    scope:
      rep = cls.Repository
      for tstr in sorted(rep):
        metatype = rep[tstr]
        fp.write(u'%-30s : %s\n' % (tstr, metatype))
    test:
      metax.c.Type.Repository = None
      metax.c.Type.Meta__Initialize()
      fp = test.fp()
      metax.c.Type.ShowRepository(fp=fp)
      test.iseqtext(
        '&str                           : &str\n'
        '*str                           : *str\n'
        'str                            : str\n',
        fp.getvalue())
    end method ShowRepository;

    field prefix : str #:
      The pass-by and const semantics indicators.
    field base : str #:
      The base type
    field native : bool #:
      True if we are to use the base-language native type associated with
      this type when generating base-language code.  This is true
      for both native types and primitive types.
    field params : vec<any> #:
      The parameters of this type. Each element can be either a Type or an int.
    field raw : str #:
      The raw representation of the type.

    static
    field Primitives : map<str,map> #:
      A mapping from Meta primitive type name to map containing:
        args: tuple
      Note that aliases for Meta primitive types must also be specified
      explicitly (e.g. 'float' and 'double', etc.

    static
    field Natives : map<str,map> #:
      Keys are Meta native types, values are maps containing:
        defparam: str
        args: tuple

    lifecycle params:
      var raw -> raw;
      var prefix -> prefix;
      var base -> base;
      var params -> params = null;
      var native -> native = false;
    scope:
    metainit:
      cls.EXTERNAL_CLASS_INDICATOR = '^';
      /# TODO(wmh): Added the $? on 2016-06-30 to support "generic types" ala
      /# templates and generics (hash<$K,$V>, etc.).  Need to add support for
      /# this throughout the codebase.
      cls.LEGAL_METATYPE_RE = re.compile(
        r'^(?P<prefix>&?(?:#?[usw]?\*)*#?|@#?|&#?|\$)?'
        r'(?P<base>\%s?[a-zA-Z0-9_.!:]+)'
        r'(?:<(?P<params>\S+)>)?$'
        % cls.EXTERNAL_CLASS_INDICATOR)
    clinit:
      cls.RE = None
      cls.METATYPE_SPLIT = re.compile(r'([#])?([usw])?\*')

      cls.PrimitivesIs({
        /# bool, boolean
        'bool': {},
        /# char
        'char': {},  # <1>, <2>, <4> ???
        /# byte, short, int, long, longlong
        'int': {'args': ('int',)},   # <1> ... <128>
        /# unsigned byte, short, int, long, longlong
        'uint': {'args': ('int',)},   # <1> ... <128>
        /# float, double
        'real': {'args': ('int',)},  # <32> or <64> or <128>
        'float': {},
        'double': {},
        /# complex
        /# TODO(wmh): This should probably be moved to 'native' ... we cannot
        /# actually provide a primitive implementation of complex numbers in
        /# all baselangs.
        'complex': {},
      })

      cls.NativesIs({
        'any': {},
        'void': {'defparam': ''},
        /# interned (const) string
        'str': {},
        /# mutable string
        'string': {},
        /# map, dict, hashtable, associative array
        'map': {'args': ('*', '*')},
        /# pair of types.
        'pair': {'args': ('*', '*')},
        /# immutable ordered container: tuple
        /#  - a k-tuple can be specified with either no parameters or with k
        /#    params.
        /#     - tuple
        /#     - tuple<int,str,Person>
        'tuple': {
          /# 'args' being an empty tuple means can have any number of args.
          'args': tuple(),
        },
        /# mutable ordered container: vector, list, growable array
        'vec': {'args': ('*',)},
        /# mutable unordered container: set, frozenset
        'set': {'args': ('*',)},

        'ostream': {},
        'istream': {},
        'strstream': {},

        /# TODO(wmh): Establish what the names for time-related native types
        /# will be:
        /#  - to represent a date and time
        /#    - if year, month, day, hour, minute, second explicitly
        /#      - datetime
        /#      - time
        /#      - ymdhms
        /#    - if only store number of seconds relative to start
        /#      - timestamp
        /#    - if we want support for relative dates
        /#      - ??
        /#  - to represent a date (year, month, day)
        /#    - if year, month, day explicitly
        /#      - date
        /#      - ymd
        /#    - if only store number of days relative to start
        /#      - ??
        /#  - to represent a time within a day without the date
        /#    - if hour, minute, second stored explicitly
        /#      - hms
        /#    - if only store number of seconds relative to 00:00:00
        /#      - should this be related to the concept of Duration?
        /#
        /# Would be preferable to find high-level names that don't assume a
        /# particular implementation (and provide implementation-specific
        /# variants similar to how we'll do for map and vec).
        /#
        /# Desired features
        /#  - very space efficient
        /#  - very time efficient
        /#  - can perform relative date manipulation
        'ymd': {},   # date without time of day
        'hms': {},   # time of day without date
        'date': {},  # this is a date plus time of day

        /# TODO(wmh): Add support for random variables
        /#  - when used as type of var, if default is a number, we can
        /#    implicitly initialize to scipy.stats.uniform(<number>, 0)
        /#  - could support rv.norm(), rv.norm(5,1), rv.uniform(5,8), etc.
        'rv': {},    # random variable

        'regexp': {},

        'nulltype': {},
        'class': {},
        'method': {},
        'function': {},

        'void': {},
      })

      /# We create Type instances for various ubiquitous types and aliases
      /# of those types.
      /#
      /# See ../../README.md section 'Implementing interned string support'
      /# for details on *str, &str, @str, #str and str. Below, we are
      /# implementing 'str' = '*str'.
      cls.Repository = {}
      strreftype = cls.Instance('&str')
      strptrtype = cls.Instance('*str')
      /# Because 'str' means '*str' it really isn't necessary to pass in
      /# default_prefix, but it is left in case we decide to swtich back to
      /# 'str' meaning '&'.
      strtype = cls.Instance('str', default_prefix='*')
      assert sorted(cls.Repository.keys()) == ['&str', '*str', 'str']
      /# TODO(wmh): Are there other types we should intern?
    setup:
      metax.c.Type.Repository = None
      metax.c.Type.Meta__Initialize()
      self.type = metax.c.Type('@int<32>', '@', 'int', ['32'])
    test:
      test.iseq('@int<32>', test.type.raw())
    end lifecycle;

    method clone : Type #:
      Make a copy of myself.
      TODO(wmh): Move to 'copy' attribute of 'lifecycle' when support available.
    scope:
      cls = self.__class__
      if self._params is None:
        params = None
      else:
        params = []
        for param in self._params:
          if isinstance(param, Type):
            params.append(param.clone())
          else:
            params.append(param)
      return cls(
        self._raw, self._prefix, self._base, params=params, native=self._native)
    test:
      type = test.type
      type2 = type.clone()
      test.notsame(type, type2)
      test.iseq(type.asStr(), type2.asStr())
    end method clone;

    method dump : void #:
      Print out details about this Type instance.

      TODO(wmh): This should be an automatically generated method.
    params:
      var fp : ostream = out;
    scope:
      fp.write(u'Type: %s\n' % self._raw)
      fp.write(u'  prefix = %s\n' % self._prefix)
      fp.write(u'  base   = %s\n' % self._base)
      fp.write(u'  native = %s\n' % self._native)
      fp.write(u'  params = %s\n' % self._params)
    test:
      fp = test.fp()
      test.type.dump(fp=fp)
      test.iseqtext(
        u'Type: @int<32>\n'
        u'  prefix = @\n'
        u'  base   = int\n'
        u'  native = False\n'
        u"  params = ['32']\n",
        fp.getvalue())
    end method dump;

    method numericParam : int #:
      Returns an integer if the params has size 1 and is an int, else 0.
    scope:
      params = self._params
      if params and len(params) == 1 and isinstance(params[0], int):
        result = params[0]
      elif self._raw == 'bool':
        result = 1
      else:
        result = 0
      return result
    test:
      test.iseq(0, test.type.numericParam())
      typ = metax.c.Type.Instance('uint<14>')
      test.iseq(14, typ.numericParam())
      typ2 = metax.c.Type.Instance('map<14,str>')
      test.iseq(0, typ2.numericParam())
      typ3 = metax.c.Type.Instance('bool')
      test.iseq(1, typ3.numericParam())
    end method numericParam;

    method fqcn : str #:
      Obtain the fully qualified class name.

      Returns:
        Returns None if the type is primitive or native.
    scope:
      if self.isPrimitive() or self.isNative():
        result = None
      else:
        result = self.base()
      return result
    test:
      types = metax.c.Type.ParseTypes('int,str,nmsp.sub.A,&a.b.C')
      test.iseq(
        [None, None, 'nmsp.sub.A', 'a.b.C'],
        [t.fqcn() for t in types])
    end method fqcn;

    method paramStr : str #:
      The parameters of the type as a string.
    scope:
      raw = self.raw()
      index = raw.find('<')
      if index == -1:
        result = ''
      else:
        result = raw[index:]
      return result
    test:
      test.iseq('', metax.c.Type.Instance('int').paramStr())
      test.iseq('<17>', metax.c.Type.Instance('int<17>').paramStr())
      test.iseq('<str,a.A>', metax.c.Type.Instance('map<str,a.A>').paramStr())
    end method paramStr;

    method isIntegral : bool #:
      Determine if the type is int or uint. A pointer to an int is not
      considered integral.
    scope:
      return self.base() in ('int', 'uint') and self.prefix() == '@'
    test:
      test.istrue(metax.c.Type.Instance('int').isIntegral())
      test.istrue(metax.c.Type.Instance('uint<17>').isIntegral())
      test.isfalse(metax.c.Type.Instance('*int').isIntegral())
      test.isfalse(metax.c.Type.Instance('float').isIntegral())
      test.isfalse(metax.c.Type.Instance('nm.sp.A').isIntegral())
    end method isIntegral;

    method isPrimitive : bool #:
      Determine if the base type is primitive.  Note that a pointer to a pointer
      to a primitive is considered primitive.
    scope:
      return Type.Primitives().get(self.base(), None) is not None
    test:
      typ1 = metax.c.Type.Instance('uint<8>')
      test.iseq(True, typ1.isPrimitive())
      typ2 = metax.c.Type.Instance('*a.b.Person')
      test.iseq(False, typ2.isPrimitive())
    end method isPrimitive;

    method isNative : bool #:
      Determine if the base type is a native type.
    scope:
      return Type.Natives().get(self.base(), None) is not None
    test:
      test.isfalse(test.type.isNative())
    end method isNative;

    method isValid : bool #:
      Determine if this is a valid (legal) type.
    scope:
      base = self.base()
      return self._native or bool(self.prefix() and base)
    test:
      t1 = metax.c.Type.Instance('*str')
      test.iseq(True, t1.isValid())
      t2 = metax.c.Type.Instance('@@blah', allow_invalid=True)
      test.iseq(False, t2.isValid())
    end method isValid;

    method isBaseConst : bool #:
      Determine if the base type is const or not.
      TODO(wmh): isPrimitive and isNative are about base types too, but
      are not named isBasePrimitive or isBaseNative. Why is this not named
      isConst() instead?
    scope:
      /# TODO(wmh): Conceptually, 'str' (and '@str' and '&str' and '*str')
      /# should return true for isBaseConst. But currently isBaseConst() is
      /# used in FieldConstruct.translateMeta() to determine whether to
      /# generate setters/reffers (no for const types) ... but we DO want
      /# to generate setters for fields of type 'str' (distinction between
      /# changing the string and changing the variable storing the string).
      prefix = self.prefix()
      return prefix and (prefix[-1] == '#' or prefix.endswith('#@'))
    test:
      test.iseqvec(
        [False, False, True, True, False],
        [t.isBaseConst() for t in
         metax.c.Type.ParseTypes(
           'str,int,#a.Person,#int,#*a.Person')])
    end method isBaseConst;

    method isTemplate : bool #:
      Determine if this is a template type or not.
    scope:
      prefix = self.prefix()
      return prefix and prefix == '$'
    test:
      test.isfalse(test.type.isTemplate())
    end method isTemplate;

    method isPtr : bool #:
      Determine if this is a pointer type or not.
    scope:
      prefix = self.prefix()
      if not prefix:
        raise metax.root.Error('All types should have a prefix: %s' % self.raw())
      /# If there is a '*' anywhere in prefix, this is a pointer type.
      return '*' in prefix
    test:
      test.iseq(
        [True, False, True, True, True, False, True, True, False],
        [t.isPtr() for t in
         metax.c.Type.ParseTypes(
           'str,int,*a.Person,*int,a.Person,&a.Person,*#a.A,**a.A,&#a.A')])
    end method isPtr;

    method isRef : bool #:
      Determine if this is a reference type or not.
    scope:
      prefix = self.prefix()
      if not prefix:
        raise metax.root.Error('All types should have a prefix: %s' % self.raw())
      return prefix[0] == '&' and '*' not in prefix
    test:
      test.iseq(
        [False, False, False, False, False, True, False],
        [t.isRef() for t in
         metax.c.Type.ParseTypes(
           'str,int,*a.Person,*int,a.Person,&a.Person,&*a.A')])
    end method isRef;

    method isRefPtr : bool #:
      Determine if this is areference to a pointer.
    scope:
      prefix = self.prefix()
      if not prefix:
        raise metax.root.Error('All types should have a prefix: %s' % self.raw())
      return prefix[0] == '&' and '*' in prefix
    test:
      test.iseq(
        [False, False, False, False, False, False, False, False, False, True],
        [t.isRefPtr() for t in
         metax.c.Type.ParseTypes(
           'str,int,*a.Person,*int,a.Person,&a.Person,*#a.A,**a.A,&#a.A,&*a.A')])
    end method isRefPtr;

    method isValue : bool #:
      Determine if this is a value type or not.
    scope:
      prefix = self.prefix()
      if not prefix:
        raise metax.root.Error('All types should have a prefix: %s' % self.raw())
      return prefix[0] == '@'
    test:
      test.istrue(test.type.isValue())
    end method isValue;

    method isStr : bool #:
      True if the type is 'str' (or '@str' or '&str' or '*str')
    scope:
      return self.base() == 'str'
    test:
      test.isfalse(test.type.isStr())
      test.istrue(metax.c.Type.Instance('str').isStr())
    end method isStr;

    method isVoid : bool #:
      Determine if this is the void type or not.
      TODO(wmh): We will almost certainly need to make a distinction between
      '*void' and 'void'. Currently this method returns True for both, but
      we should maybe have isVoid() and isBaseVoid() to distinguish.
    scope:
      return self.base() == 'void'
    test:
      test.isfalse(test.type.isVoid())
      test.istrue(metax.c.Type.Instance('void').isVoid())
    end method isVoid;

    method isAny : bool #:
      Determine if this is the 'any' type or not.
      TODO(wmh): We will almost certainly need to make a distinction between
      '*any' and 'any'. Currently this method returns True for both, but
      we should maybe have isAny() and isBaseAny() to distinguish.
    scope:
      return self.base() == 'any'
    test:
      test.isfalse(test.type.isVoid())
    end method isAny;

    method asStr : str #:
      Convert to a string according to mode.
    params:
      var mode : int = 0 #:
        If 0, print the verbatim type seen.
        Otherwise print the type formed by composing parsed data.
    scope:
      raw = self.raw()
      if mode == 0 or raw.startswith('{#') and raw.endswith('#}'):
        result = raw
      else:
        params_str = ''
        params = self.params()
        if params:
          params_list = []
          for type_ in params:
            params_list.append(type_.asStr(mode=mode))
          params_str = '<' + ','.join(params_list) + '>'
        result = '%s%s%s' % (
          self.prefix(), self.base(), params_str)
        /#if result != self.raw():
        /#  result += ' [%s]' % self.raw()
      return result
    test:
      test.iseq('@int<32>', test.type.asStr())
    end method asStr;

    method __str__ : str #:
      TODO(wmh): Meta should auto-generate baselang-specific to-string
      methods based on asStr() or some more formal method.
    scope:
      return self.asStr()
    test:
      t1 = metax.c.Type.Instance('*str')
      test.iseq('*str', str(t1))
    end method __str__;

    test
    method testx_verifyInitiale scope:
      metax.c.Type.Repository = None
      metax.c.Type.Meta__Initialize()
      test.iseqvec(
        ['&str', '*str', 'str'],
        sorted(metax.c.Type.Repository.keys()))

  end class Type;

  class TypeWrapper #:
    A wrapper for the Type class.

    The Type class has interned instances for each type in the system.
    Internment provides efficiency but is at odds with wanting a distinction
    between the canonical type and display type (where display type can differ
    depending on context).

    In particular, suppose we have
       namespace ex.code ::
         class A ::
           method meth : B ...
    The return type of 'meth' is not fully qualified, but under the hood Meta
    needs to know the fully qualified type in order to be able to find the
    associated class during type analysis. But if we create an interned Type
    instance with value ex.code.B, then when we canonicalize the code, the type
    will no longer be local, it will appear as 'ex.code.B', when the local
    version is arguably more readable (less clutter).

    To address this issue, the following strategy is used:
     - All interned Type instances specify fully qualified class names
       (for non-native, non-primitive types)
     - In the code, a type specification that is not fully qualified is
       made an instance of TypeWrapper, which contains the interned Type
       instance and a display representation.  This class otherwise responds
       to exactly the same interface as Type, with the sole difference being
       how the type responds to __str__; Type instances print the fully
       qualified class name, TypeWrapper instances print their cached display
       string instead.  There can be many TypeWrapper instances for the
       same local type, but only a single Type instance.

  scope:

    field type : metax.c.Type #:
      The type being wrapped.

    field display : str #:
      The local type name found in the source code, and to be displayed during
      (some) canonicalizations.

    lifecycle params:
      var type -> type;
      var display -> display;
    scope:
    setup:
      metax.c.Type.Repository = None
      metax.c.Type.Meta__Initialize()
      self.type = metax.c.Type.Instance('a.b.Person')
      self.wrap = metax.c.TypeWrapper(self.type, 'Person')
    end;

    method wrappedRaw : str #:
      The local type name found in the source code.
    scope:
      return self._display
    test:
      test.iseq('Person', test.wrap.wrappedRaw())
    end method wrappedRaw;

    method __str__ : str #:
      The printable representation of this WrappedType instance.
    scope:
      return self._display
    test:
      test.iseq('a.b.Person', str(test.type))
      test.iseq('Person', str(test.wrap))
    end method __str__;

    method __getattr__ : any #:
      This method delegates all non-locally defined methods to the contained
      self.type().
      TODO(wmh): This is a python-specific method, and a more general mechanism
      for delegating all non-local methods to a contained object is needed.
    params:
      var name;
    scope:
      return getattr(self._type, name)
    test:
      /# noop. See test_isPtr, test_isRef, test_fqcn below.
      pass
    end method __getattr__;

    test
    method test_isPtr scope:
      test.iseq(True, test.type.isPtr())
      test.iseq(True, test.wrap.isPtr())
    end method test_isPtr;

    test
    method test_isRef scope:
      test.iseq(False, test.type.isRef())
      test.iseq(False, test.wrap.isRef())
    end method test_isRef;

    test
    method test_fqcn scope:
      test.iseq('a.b.Person', test.type.fqcn())
      test.iseq('a.b.Person', test.wrap.fqcn())
    end method test_fqcn;

  end class TypeWrapper;

  class MetaFile #:
    A metafile (with functionality for parsing, as well as final state).
  assocs:
    std assoc math;
    usertest std assoc pprint;
    std assoc time;
  scope:

    field path : str #:
      The path to the .meta file being parsed.

    field abbrev : str #:
      A temporary abbrev set by the Compiler to concisely but uniquely
      identify the metafile amongst all metafiles currently parsed in memory.

    field construct : metax.meta.FileConstruct #:
      The FileConstruct instance storing the parsed representation of the
      MetaFile.  Initialized by parseMeta()

    field compiler : Compiler #:
      The compiler instance specifying which metalang and baselang are active,
      as well as various other user-level config options.

    field debuglevel : int #:
      Controls how much debugging diagnostic output is produced.

    field debuglast : int #:
      The line number during the most recent call to self.debug()

    field lnum : int #:
      The current line within the file (0 is first line).

    field index : int #:
      The current position within self.text().

    field logmap : map #:
      Provides level-specific lists of logging lines.

    field text : str #:
      The contents of the .meta file being parsed, as a multi-line string
      ending with a newline.

    field lines : vec<Line> #:
      The .meta file as a collection of Line instances.

    field files : @set<str> #:
      The set of files written as part of compiling this metafile.
      TODO(wmh): Remove in favor of basefiles.

    field basefiles : @set<str> #:
      The set of BaseFile instances associated with compiling this metafile.
      TODO(wmh): This should be able to subsume files() above.

    field context : Context #:
      The context within which the current construct is being parsed.
      When parsing a construct, a next Context is created if a 'config'
      secondary block is encountered.

    field constructs : @map<str,set<Construct>> #:
      Every construct that is created during parsing is added to this
      dict.  Keys are construct kinds, values are lists of Construct.

    field userconstructs : @map<str,set<Construct>> #:
      Every user-defined construct that is created during parsing is added to this
      dict.  Keys are construct kinds, values are lists of Construct.

    field streams : BaseStreams #:
      The collection of streams one can write to when compiling this metafile.

    field classdeps : set<str> #:
      The fully-qualified names of classes depended on within this metafile.
      Used to determine which .meta files need to be imported during importMeta.

    field stats : @map #:
      Maintains status on various things:
        parse: float
          seconds taken to parse
        expand: float
          seconds taken to expand
        translate: float
          seconds taken to translate
        compile: float
          seconds taken to compile

    field state : str #:
      Indicates the current state of the metafile. One of:
        parsing: currentingly being parsed
        parsed: finished parsing, have not yet expanded
        expanding: currently expanding
        expanded: finished expanding, have not yet imported
        importing: currently importing
        imported: finished importing, have not yet translated
        translating: currently translating
        translated: finished translating, have not yet compiled
        compiling: currently compiling
        compiled: finished compiling
        complete: all actions have been accomplished.

    field phases : @vec<str> #:
      The phases that have been completed. Legal values are:
        parse
        expand
        import
        translate
        compile
      Although 'state' almost uniquely establishes which phases have
      been completed, 'import' is a special case (sometimes a metafile
      is imported, sometimes not, but translate and compile can still
      occur either way).

    lifecycle params:
      var path -> path;
      var compiler -> compiler;
      var text : str #:
        If present, path is not read (and thus does not need to exist).
        Instead, the contents of the metafile are assumed to be fully
        specified by this param.  Useful in unittests.
      var debuglevel -> debuglevel = 0;
    scope:
      self.logmapIs({'order': []})
      assert text is not None
      if not text or text[-1] != '\n':
        text += '\n'
      lines = Line.FromText(text)
      streams = BaseStreams()

      /# TODO(wmh): field files of type @set is not properly initializing a set.
      self.filesIs(set())
      self.basefilesIs(set())
      self.classdepsIs(set())

      self.linesIs(lines)
      self.textIs(text)
      self.streamsIs(streams)
    clinit:
      /# AttrTypeMap maps conceptual attribute value type strings to
      /# three-tuples containing
      /#    <subclass, exception_class, function>
      /# The value establishes the subclass of Attribute to use for representing
      /# attribute values of the key type. If the value is a tuple, the second
      /# element is the exception raised if a particular value is invalid,
      /# and the third element is a function accepting an input value that
      /# returns a canonicalized value.
      import metax.attr
      cls.AttrTypeMap = {
        'feature': (metax.attr.FeatureAttribute, None, None),

        /# Word-based
        'id': (metax.attr.IdAttribute, None, None),
        'xid': (metax.attr.IdAttribute, None, None),
        'word': (metax.attr.WordAttribute, None, None),
        'num': (metax.attr.NumAttribute, ValueError, None),
        'enum': (metax.attr.EnumAttribute, TypeError, None),

        /# Specialty
        'str': (metax.attr.ExprAttribute, None, None),
        'expr': (metax.attr.ExprAttribute, None, None),
        'type': (metax.attr.TypeAttribute, InvalidType, None),

        /# Block-valued
        'simple': (metax.attr.SimpleBlock, None, None),
        'complex': (metax.attr.ComplexBlock, None, None),
        'simplex': (metax.attr.SimpleBlock, None, None),

        /# List-valued
        /#'word-list': (metax.attr.WordListAttribute, None, None),
        /#'id-list': (metax.attr.IdListAttribute, None, None),
      }

      /# Maps attrtype strings to functions accepting attribute key, type and
      /# value. Returns true if the value type checks relative to the type, and
      /# False if not.
      cls.AttrTypeCheck = {
        'id': lambda akey, atype, aval: ExprParser.ID_RE.match(aval),
        'xid': lambda akey, atype, aval: ExprParser.XID_RE.match(aval),
        'num': lambda akey, atype, aval: ExprParser.NUM_RE.match(aval),
        'enum': lambda akey, atype, aval: ExprParser.ENUM_RE.match(aval),
      }

      def Err():
        raise InvalidAttributeType(
          'No sensible default exists for this value type')

      cls.AttrValueEmpty = {
        /# should never see 'feature', since feature Attribute instances should
        /# never have default <empty>
        'feature': Err,

        'id': lambda: '',  # not legal, must disable typechecking in createNewAttribute
        'xid': lambda: '', # not legal, must disable typechecking in createNewAttribute
        'word': lambda: '',
        'num': lambda: 0,
        'enum': lambda: tuple(),

        'str': lambda: Expr('str', '""', '""'),
        'expr': Err,       # is there a meaningful empty expr?
        'type': Err,       # is there a meaningful empty type?

        'complex': lambda: tuple(),
        'simplex': lambda: tuple(),
        'simple': lambda: tuple(),

        'word-list': lambda: tuple(),
        'id-list': lambda: tuple(),
      }

      cls.TERM_RE = re.compile(
        r'((?P<end>end)(?:\s+(?P<kind>\S+)(?:\s+(?P<id>\S+))?)?)?;')
    setup:
      test.text = (
        'MetaLanguage Test config:\n'
        'end MetaLanguage;\n'
      )
      test.metafile, test.context = test.schemaParser(test.text)
    end lifecycle;

    method set #:
      Set current index and line.
    params:
      var index : int = -1 #:
        If negative, it is a request to compute the index based on line number.
      var lnum : int = -1 #:
        If negative, it is a request to compute line number based on index. This
        is expensive and should not be used in production paths.
      var adj : int = 0 #:
        An adjustment to add to the index. Useful when index is -1 and lnum is
        not (which sets index to first live char of the line, and adj allows
        one to advance within the line).
    scope:
      lines = self._lines
      if index < 0:
        if lnum < 0:
          raise Error('Must provide one of index or lnum')
        line = lines[lnum]
        index = line.start() + line.indent()
      elif lnum < 0:
        self.warning(
          'WARNING: MetaFile.set() is expensive when index given without lnum.\n'
          'Consider explicitly providing lnum')
        /# TODO(wmh): We could use binary search, but frankly we should never
        /# use this code ... we should always have the lnum available to pass
        /# in explicitly.
        lnum = 0
        try:
          while lines[lnum].end() < index:
            lnum += 1
        except IndexError:
          /# EOF.
          lnum = -1
      index += adj
      /#if index > lines[lnum].end():
      /#  raise Error('Cannot adj past end of line %d (%d)' % (lnum, adj))
      self.indexIs(index)
      self.lnumIs(lnum)
    test:
      mf = test.metafile
      test.iseq((0, 0, 0), (mf.index(), mf.lnum(), mf.column()))
      mf.set(index=5, lnum=0)
      test.iseq((5, 0, 5), (mf.index(), mf.lnum(), mf.column()))
      mf.set(index=30, lnum=1)
      test.iseq((30, 1, 4), (mf.index(), mf.lnum(), mf.column()))
    end method set;

    method current : tuple<str,int,int,Line> #:
      Obtain the text and current index, lineno, column and Line.
    scope:
      line = self.line()
      index = self._index
      col = index - line.start()
      return (self._text, index, self._lnum, col, line)
    test:
      test.iseq(
        ('MetaLanguage Test config:\nend MetaLanguage;\n', 0, 0, 0, test.metafile.line()),
        test.metafile.current())
    end method current;

    method line : Line #:
      The specified Line.
    params:
      var lnum : int = -1 #:
        If negative, use self._lnum instead.
    scope:
      lines = self._lines
      if lnum < 0:
        lnum = self._lnum
      return lines[lnum] if lnum < len(lines) else None
    test:
      test.iseq('MetaLanguage Test config:', test.metafile.line().line())
    end method line;

    method column : int #:
      Obtain the current column
    params:
      var line : Line = null #:
        The current Line. Not necessary, as it can be obtained from
        self._lines[self._lnum], but provided as an optimization for
        situations where the caller has the line. It is important the
        correct Line is passed in, or the result will be incorrect.
    scope:
      try:
        if line is None:
          line = self._lines[self._lnum]
        result = self._index - line.start()
      except IndexError:
        /# EOF
        result = -1
      return result
    test:
      metafile, context = test.schemaParser(
        'MetaLanguage Test config:\nend MetaLanguage;\n')
      test.iseq(0, metafile.column())
      metafile.indexIs(7)
      test.iseq(7, metafile.column())
      metafile.set(30, 1)
      test.iseq(4, metafile.column())
    end method column;

    method log #:
      Log a message
    params:
      var message : str;
      var kind : str = 'I';
      var line : int = -1;
      var col : int = -1;
      var attr : metax.attr.Attribute = null;
    scope:
      if attr:
        line = attr.line()
        col = attr.col()
      elif line < 0:
        line = self._lnum
        col = self.column()
      elif col < 0:
        col = self.column()
      entry = {'message': message, 'line': line, 'col': col, 'kind': kind}
      /# TODO(wmh): We really don't need to store the entry in both a
      /# kind-specific list and in the 'order' list ... we could just
      /# increment a counter instead.
      kind_log = self._logmap.setdefault(kind, [])
      kind_log.append(entry)
      order = self._logmap['order']
      order.append(entry)
      return entry
    test:
      mf = test.metafile
      mf.log('Testing')
      test.iseq(
        {'I': [{'message': 'Testing', 'line': 0, 'kind': 'I', 'col': 0}],
         'order': [{'message': 'Testing', 'line': 0, 'kind': 'I', 'col': 0}]},
        mf._logmap)
      mf.log('An error', kind='E', line=30, col=16)
      test.iseq(
        {'I': [{'message': 'Testing', 'line': 0, 'kind': 'I', 'col': 0}],
         'E': [{'message': 'An error', 'line': 30, 'kind': 'E', 'col': 16}],
        'order': [
          {'message': 'Testing', 'line': 0, 'kind': 'I', 'col': 0},
          {'message': 'An error', 'line': 30, 'kind': 'E', 'col': 16}]
        },
        mf._logmap)
    end method log;

    method debug #:
      Write a debug message.
    params:
      var message : str;
      var line : int = -1;
      var col : int = -1;
      var width : int = 60;
    scope:
      if self._debuglevel:
        entry = self.log(message, kind='D', line=line, col=col)
        num = entry['line']
        lastnum = self._debuglast
        self._debuglast = num
        lines = self._lines
        if self._debuglevel > 1:
          lineobj = lines[num] if num < len(lines) else None
          msg = message[:width-1] + '$' if len(message) > width else message
          linetext = (
            (lineobj.line() if lineobj else '<eof>') if num != lastnum
            else '        \"')
          sys.stdout.write('%4d:%3d: %s |%s\n' % (
            entry['line'] + 1, entry['col'], msg.ljust(width), linetext))
        else:
          sys.stdout.write('%4d: %s\n' % (
            entry['line'], message))
    test:
      mf = test.metafile
      test.iseq(0, mf._debuglevel)
      mf.debug('a problem', line=14, col=30, width=30)
      test.iseq({'order': []}, mf._logmap)

      test.captureStdout()

      mf._debuglevel = 1
      mf.debug('another problem', line=14, col=30, width=30)
      test.iseq(
        {'order': [
           {'message': 'another problem', 'line': 14, 'kind': 'D', 'col': 30}],
         'D': [{'message': 'another problem', 'line': 14, 'kind': 'D', 'col': 30}],
        },
        mf._logmap)

      mf._debuglevel = 2
      mf.debug('a third problem', line=50, col=2, width=30)
      test.iseq(
        {'order': [
          {'message': 'another problem', 'line': 14, 'kind': 'D', 'col': 30},
          {'message': 'a third problem', 'line': 50, 'kind': 'D', 'col': 2}],
         'D': [
           {'message': 'another problem', 'line': 14, 'kind': 'D', 'col': 30},
           {'message': 'a third problem', 'line': 50, 'kind': 'D', 'col': 2}],
        },
        mf._logmap)

      out = test.getStdout()
      test.iseqtext(
        '  14: another problem\n'
        '  51:  2: a third problem                |<eof>\n',
        out)
    end method debug;

    method info params:
      var message : str;
      var line : int = -1;
      var col : int = -1;
      var attr : metax.attr.Attribute = null;
    scope:
      return self.log(message, kind='I', line=line, col=col, attr=attr)
    test:
      mf = test.metafile
      mf.info('hello')
      mf.info('goodbye', line=15, col=30)
      construct = test.basics()
      attr = metax.attr.FeatureAttribute(
        construct, 'kind', 'instance', line=50, col=10)
      mf.info('done', attr=attr)
      test.iseq(
        {'I': [
          {'message': 'hello', 'line': 0, 'kind': 'I', 'col': 0},
          {'message': 'goodbye', 'line': 15, 'kind': 'I', 'col': 30},
          {'message': 'done', 'line': 50, 'kind': 'I', 'col': 10}],
         'order': [
           {'message': 'hello', 'line': 0, 'kind': 'I', 'col': 0},
           {'message': 'goodbye', 'line': 15, 'kind': 'I', 'col': 30},
           {'message': 'done', 'line': 50, 'kind': 'I', 'col': 10}],
       },
       mf._logmap)
    end method;

    method warning params:
      var message : str;
      var line : int = -1;
      var col : int = -1;
      var attr : metax.attr.Attribute = null;
    scope:
      return self.log(message, kind='W', line=line, col=col, attr=attr)
    test:
      test.basics()
      mf = test.metafile
      mf.warning('hello')
      mf.warning('goodbye', line=15, col=30)
      attr = metax.attr.FeatureAttribute(
        test.construct, 'kind', 'instance', line=50, col=10)
      mf.warning('done', attr=attr)
      test.iseq(
        {'W': [
          {'message': 'hello', 'line': 0, 'kind': 'W', 'col': 0},
          {'message': 'goodbye', 'line': 15, 'kind': 'W', 'col': 30},
          {'message': 'done', 'line': 50, 'kind': 'W', 'col': 10}],
         'order': [
           {'message': 'hello', 'line': 0, 'kind': 'W', 'col': 0},
           {'message': 'goodbye', 'line': 15, 'kind': 'W', 'col': 30},
           {'message': 'done', 'line': 50, 'kind': 'W', 'col': 10}],
       },
       mf._logmap)
    end method warning;

    method error params:
      var message : str;
      var line : int = -1;
      var col : int = -1;
      var attr : metax.attr.Attribute = null;
    scope:
      return self.log(message, kind='E', line=line, col=col, attr=attr)
    test:
      mf = test.metafile
      mf.error('hello')
      mf.error('goodbye', line=15, col=30)
      construct = test.basics()
      attr = metax.attr.FeatureAttribute(
        construct, 'kind', 'instance', line=50, col=10)
      mf.error('done', attr=attr)
      test.iseq(
        {'E': [
          {'message': 'hello', 'line': 0, 'kind': 'E', 'col': 0},
          {'message': 'goodbye', 'line': 15, 'kind': 'E', 'col': 30},
          {'message': 'done', 'line': 50, 'kind': 'E', 'col': 10}],
         'order': [
           {'message': 'hello', 'line': 0, 'kind': 'E', 'col': 0},
           {'message': 'goodbye', 'line': 15, 'kind': 'E', 'col': 30},
           {'message': 'done', 'line': 50, 'kind': 'E', 'col': 10}],
       },
       mf._logmap)
    end method error;

    method fatal params:
      var message : str;
      var line : int = -1;
      var col : int = -1;
      var attr : metax.attr.Attribute = null;
    scope:
      self.log(message, kind='F', line=line, col=col)
      self.die(log=True)
    test:
      mf = test.metafile
      construct = test.basics()
      attr = metax.attr.FeatureAttribute(
        construct, 'kind', 'instance', line=50, col=10)

      test.captureStdout()

      test.raises(metax.root.Error, mf.fatal, 'hello')
      test.iseq(
        {'order': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}], 'F': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}]},
        mf._logmap)

      test.raises(metax.root.Error, mf.fatal, 'goodbye', line=15, col=30)
      test.iseq(
        {'order': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}, {'message': 'goodbye', 'line': 15, 'kind': 'F', 'col': 30}], 'F': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}, {'message': 'goodbye', 'line': 15, 'kind': 'F', 'col': 30}]},
        mf._logmap)

      test.raises(metax.root.Error, mf.fatal, 'done', attr=attr)
      test.iseq(
        {'order': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}, {'message': 'goodbye', 'line': 15, 'kind': 'F', 'col': 30}, {'message': 'done', 'line': 0, 'kind': 'F', 'col': 0}], 'F': [{'message': 'hello', 'line': 0, 'kind': 'F', 'col': 0}, {'message': 'goodbye', 'line': 15, 'kind': 'F', 'col': 30}, {'message': 'done', 'line': 0, 'kind': 'F', 'col': 0}]},
        mf._logmap)

      out = test.getStdout()
      test.iseqtext(
        '\n'
        'fauxpath:\n'
        'F1: hello\n'
        '\n'
        'fauxpath:\n'
        'F1: hello\n'
        'F16: goodbye\n'
        '\n'
        'fauxpath:\n'
        'F1: hello\n'
        'F16: goodbye\n'
        'F1: done\n',
        out)
    end method fatal;

    method die params:
      var log : bool = true;
    scope:
      if log:
        self.printLog()
      raise metax.root.Error('Dying')
    test:
      mf = test.metafile
      test.raises(metax.root.Error, mf.die, log=False)
    end method die;

    method warnings : vec<str> scope:
      return self._logmap.get('W', [])
    test:
      test.iseq([], test.metafile.warnings())
    end method warnings;

    method errors : vec<str> scope:
      return self._logmap.get('E', [])
    test:
      test.iseq([], test.metafile.errors())
    end method errors;

    method hasErrors : bool #:
      Determine if the parse has encountered errors.

      Returns:
        True if any errors exist, False if no errors exist.
    params:
      var show : bool = false #:
        If True (default), print out all log entries if errors exist.
      var category : str = 'E';
    scope:
      if self._logmap.get(category):
        result = True
        if show:
          self.printLog(exclude_kinds=['I'])
      else:
        result = False
      return result
    test:
      mf = test.metafile
      test.isfalse(mf.hasErrors())
      mf.error('testing')
      test.istrue(mf.hasErrors())

      test.captureStdout()
      mf.hasErrors(show=True)
      out = test.getStdout()
      test.iseqtext(
        '\n'
        'fauxpath:\n'
        'E1: testing\n',
        out)
    end method hasErrors;

    method numErrors : int scope:
      return len(self.errors())
    test:
      mf = test.metafile
      test.iseq(0, mf.numErrors())
      mf.error('testing')
      test.iseq(1, mf.numErrors())
    end method numErrors;

    method clearLog scope:
      self._logmap = {'order': []}
    test:
      test.metafile.clearLog()
    end method clearLog;

    method printLog params:
      var indent : str = '';
      var exclude_kinds : vec<str> = null #:
        If present, the kinds to exclude from printing.
    scope:
      fs = self.compiler().fs()
      basefile = fs.basename(self._path)
      numwidth = int(math.ceil(math.log(len(self._lines), 10)))
      print
      print('%s%s:' % (indent, self._path))
      for entry in self._logmap['order']:
        lnum = entry['line']
        kind = entry['kind']
        if exclude_kinds and kind in exclude_kinds: continue
        linestr = '' if lnum < 0 else str(lnum+1)
        print('%s%s%s: %s' % (
          indent, kind, linestr.rjust(numwidth), entry['message']))
    test:
      mf = test.metafile

      test.captureStdout()
      mf.printLog()
      out = test.getStdout()
      test.iseqtext('\nfauxpath:\n', out)

      mf.info('info')
      mf.warning('warning')
      mf.error('error')
      test.captureStdout()
      mf.printLog()
      out = test.getStdout()
      test.iseqtext(
        '\n'
        'fauxpath:\n'
        'I1: info\n'
        'W1: warning\n'
        'E1: error\n',
        out)
    end method printLog;

    method find : any #:
      Obtain a Construct or Attribute descendent node.

      Example:
        method = metac.find('nm.sp.Person.bmi')
    params:
      var spec : str #:
        Format is:
          <term> ::- <id> ['@' <attr> ]
          <spec> ::- <term> | <spec> '/' <term>
      var fp : ostream = null #:
        If non-null, where to write failure information.
    scope:
      if spec[0] in ('/', '.'):
        spec = spec[1:]
      file_construct = self.construct()
      result = file_construct.child(spec)
      return result
    test:
      cards1, scope, namespace, path = test.getMetaFile(
        'oopl', 'cards1', debuglevel=0)
      test.iseq('namespace demo.cards1', cards1.find('demo.cards1').kindid())
      test.iseq('class Card', cards1.find('demo.cards1/Card').kindid())
    end method find;

    method registerDependentClass #:
      Record the fact that this metafile depends on a given class.
    params:
      var fqcn : str #:
        The fully qualified name of the class depended upon.
    scope:
      self.classdeps().add(fqcn)
      /#print('Now have %d deps in %s' % (len(self.classdeps()), id(self)))
    test:
      test.metafile.registerDependentClass('a.b.c')
      test.iseq(set(['a.b.c']), test.metafile.classdeps())
    end method registerDependentClass;

    method registerConstructInMetaFile #:
      Add this construct to a global list.

      Certain constructs need to be globally accessible, not just discoverable
      within a particular namespace:
       - we need to maintain a mapping from fully qualified class name to
         ClassConstruct instance, so that we can do type inference.
       - we need to maintain a mapping from namespace to Namespace to
         implement node traversal.
          - this is necessitated by the fact that ides of namespaces are xids
            (meaning they can have dots).  If they were only ids, and we
            created sub namespace instances for each part of 'nm.sp.sub',
            we could traverse the path hierarchy by splitting a fully
            qualified construct id on dots.
          - more concretely, suppose we have
              wmh.game.catan.Hex.edge
            to find this construct from a FileConstruct instance, we would
            like to split on dots and traverse the child hierarchy. But
            that currently won't work ... we need to know to split it into
              ['wmh.game.catan', 'Hex', 'edge']
          - By providing a mapping from namespace id to NamespaceConstruct,
            we can implement traversal below that level.
            TODO(wmh): Clean this all up!!!
    params:
      var construct : Construct;
    scope:
      /#if construct.kind() in ('namespace', 'class', 'method', 'field'):
      /#  print('Registering %s in context %s path %s' % (
      /#    construct.path(), id(self.context()), self.filename()))
      kind = construct.kind()
      conset = self.constructs().setdefault(kind, set())
      if construct in conset:
        if FLAGS.lintfull:
          print('WARNING: Re-registering %s in MetaFile %s' % (
            construct.path(), self.filename()))
      else:
        conset.add(construct)
        if self.state() == 'parsing':
          userconset = self.userconstructs().setdefault(kind, set())
          userconset.add(construct)
        if construct.kind() == 'namespace' and construct.isUser():
          self.current_namespaceIs(construct)

    test:
      metafile = test.metafile
      construct = metax.meta.FileConstruct('dummy', None, test.context)
      test.iseq({}, metafile.constructs())
      metafile.registerConstructInMetaFile(construct)
      test.iseq(construct, list(metafile.constructs()['File'])[0])
    end method registerConstructInMetaFile;

    method unregisterConstructInMetaFile #:
      Remove a construct from a metafile.
    params:
      var construct : Construct;
    scope:
      conset = self.constructs().setdefault(construct.kind(), set())
      if construct not in conset:
        print('WARNING: Request to unregister non-registered construct %s within %s' % (
          construct.path(), self.path()))
      else:
        conset.remove(construct)
    test:
      metafile = test.metafile
      construct = metax.meta.FileConstruct('dummy', None, test.context)
      test.iseq({}, metafile.constructs())
      metafile.registerConstructInMetaFile(construct)
      test.iseq(construct, list(metafile.constructs()['File'])[0])
      metafile.unregisterConstructInMetaFile(construct)
      test.iseq({'File': set([])}, metafile.constructs())
    end method unregisterConstructInMetaFile;

    meta
    method CreateNewAttribute : metax.attr.Attribute #:
      Create an instance of some subclass of Attribute based on info.
    params:
      var parent : Construct #:
        The construct within which this attribute is being created.
        This is null if a primary attribute is being created, and non-null
        if a secondary attribute is being created.
      var consinfo : ConsInfo #:
        The construct info describing all attributes in a construct.
      var litkey : str #:
        The literal key appearing in the source.
      var key : str = null #:
        The canonical key. This is usually not needed, as it can be established
        from litkey. However, litkey is the empty string in situations where
        the attribute key is not explicitly specified.
      var value : any = null #:
        The value of the attribute. This is often null when initially
        creating Attribute instances.
      var line : int = -1 #:
        The line in which the attribute appears (indexed from 0).
      var col : int = -1 #:
        The column within the line at which the attribute starts (indexed from 0).
      var typecheck : bool = true #:
        Perform typechecking if true.
      var metafile : MetaFile = null #:
        Where to write errors.  If not provided, an Error is raised instead.
      var secondary : boolean = false #:
        Only relevant if parent is null ... if true, treat as secondary even
        when parent is null.
      var type : str = null #:
        One of 'simple' or 'complex'. Should never be 'simplex' (caller shouuld
        convert to simple or complex based on basel before calling this method.
    scope:
      /# TODO(wmh): This check can be removed when the code has been updated to
      /# always having a parent.
      assert parent is None or isinstance(parent, metax.meta.Construct)

      result = None
      error = None
      thekey = key or litkey
      if thekey is None:
        raise Error('Must provide one of "litkey" or "key"')

      /# Establish the attribute info.
      if parent or secondary:
        /# Secondary attribute
        info = consinfo.secondaries().get(thekey, None)
      else:
        /# Primary attribute
        info = consinfo.primary().get(thekey, None)
      if not info:
        consinfo.show()
        print('KEY: %s' % str(thekey))
        raise Error(
          'Invalid attribute key %s for construct %s' %
          (thekey, consinfo.name()))

      /# Establish canonical key and type
      if key is None:
        key = info['cankey']
      else:
        if key != info['cankey']:
          print('****** HERE with key=%s cankey=%s' % (key, info['cankey']))
        assert key == info['cankey']
      type2 = info['type']
      if type is None:
        type = type2

      /# Perform type checking.
      if typecheck:
        type_checker = cls.AttrTypeCheck.get(type, None)
        if type_checker and value is not None:
          if not type_checker(key, type, value):
            err = (
              'The attribute key "%s" of type "%s" cannot have value "%s"' %
              (key, type, value))
            if metafile:
              metafile.error(err)
            else:
              raise Error(err)

      /# Create the Attribute
      typeinfo = cls.AttrTypeMap.get(type, None)
      if typeinfo:
        attr_class, exc_class, value_converter = typeinfo
        if exc_class is None: exc_class = UnusedException
        if value_converter and value is not None:
          value = value_converter(value)
        try:
          result = attr_class(
            parent, key, value, litkey=litkey, line=line, col=col)
        except exc_class as e:
          err = 'Invalid value "%s" for %s' % (value, key)
          if parent:
            err += ' in ' + parent.kindid()
          if metafile:
            metafile.error(err)
          else:
            raise Error(err)
          result = None
      else:
        error = (
          "Unknown attribute type '%s' for key '%s' of construct '%s'" %
          (type, key, consinfo.name()))
        /# TODO(wmh): Define a special Exception subclass that can contain as
        /# one of its fields any other exception, so that we can store the
        /# offending issue.
        raise Error(error)

      return result
    test:
      mf, context = test.schemaParser('\n')
      attr = metax.c.MetaFile.CreateNewAttribute(
        self.construct, context.consinfo('Attribute'), '=',
        value='blah', line=10, col=20, metafile=mf)
      test.iseq('= blah', attr.asStr())
    end method CreateNewAttribute;

    method show #:
      Print out the content of this metafile.
    params:
      var fp : ostream = out #:
        Where to write to.
    scope:
      sep = u'#' * 80 + '\n'
      fp.write(sep)
      lines = self.lines()
      rawlines = self.text().rstrip().split('\n')
      assert len(lines) == len(rawlines), '%d lines vs %d rawlines' % (len(lines), len(rawlines))
      n = len(lines)
      rawstart = 0
      fp.write(u'lnum:index:in:line\n')
      for i in range(0, n):
        rawline = rawlines[i]
        rawlen = len(rawline) + 1
        line = lines[i]
        start = line.start()
        assert start == rawstart
        fp.write(
          u'%4d:%5d:%2d:%s\n' % (i, line.start(), line.indent(), line.line()))
        rawstart += rawlen
      fp.write(sep)
    test:
      fp = test.fp()
      test.metafile.show(fp=fp)
      test.iseqtext(
        '################################################################################\n'
        'lnum:index:in:line\n'
        '   0:    0: 0:MetaLanguage Test config:\n'
        '   1:   26: 0:end MetaLanguage;\n'
        '################################################################################\n',
        fp.getvalue())
    end method show;

    method parseSimpleBlock #:
      Given a parser at start-of-block, parse to end of block adding to self.
    params:
      var block : metax.attr.SimpleBlock #:
        The block to parse into.
      var indent : int #:
        The minimum indent of lines in the block.
    scope:
      context = self.context()
      value = block.value()

      /# Parse lines until we encounter one whose indent is less than indent.
      lines = self._lines
      lnum = self._lnum
      n = len(lines)
      line = lines[lnum]
      index = line.start()
      try:
        while line.empty() or line.indent() >= indent:
          /# We strip the indent off the line added to value, and do NOT add
          /# a newline at the end of the line added. If per-char parsing of
          /# these lines becomes necessary, it can be useful to add a newline
          /# so that we can check for newline instead of having to guard for
          /# end-of-line, in which case we will add a newline (which will
          /# necessitate a few changes in the code, in particular in
          /# SimpleBlock.writeValueLines()).
          value.append(line.line(index + indent))
          lnum += 1
          line = lines[lnum]
          index = line.start()
      except IndexError:
        /# We've encountered eof.
        pass
      /# Update line and index
      /#  - the line is one more than the last line in the simple block.
      /#  - the index is positioned at the first non-space character on the
      /#    new line.
      self.lnumIs(lnum)
      self.indexIs(line.start() + line.indent())
    test:
      text = (
        'MetaLanguage Test comment:\n'
        '  This is a test\n'
        '\n'
        '  to verify simple block parsing.\n'
        'end MetaLanguage;\n'
      )
      metafile, context = test.schemaParser(text)
      block = metax.attr.SimpleBlock(self.construct, 'comment:', [], None)
      metafile.set(21, 1)
      metafile.parseSimpleBlock(block, 2)
      test.iseqvec(
        ['This is a test', '', 'to verify simple block parsing.'],
        block.value())
    end method parseSimpleBlock;

    method parseComplexBlock #:
      Given a parser at start-of-block, parse to end of block adding to self.
    params:
      var block : metax.attr.ComplexBlock #:
        The block to parse into.
      var indent : int #:
        The indentation at which the construct must occur.
      var legals : vec<str> = null #:
        The kinds of constructs that can legally appear in this block. If null,
        no constraints placed on constructs.
    scope:
      context = self.context()
      blockdent = context.token('blockdent')
      value = block.value()

      /# Establish the ConsGroup associated with the legal constructs that can
      /# appear within this block.
      consgroup = context.legalInfo(legals)

      /# Parse constructs until we reach the end of the block.
      while True:
        construct = self.parseConstruct(block, indent, consgroup)
        if not construct:
          /# No more constructs in this block.
          break
        
        termcode = construct.termcode()
        if termcode == TERM_UNINIT:
          /# We have encountered an error during parsing.
          /#  - skip forward to end of current block.
          self.skipToIndent(indent - blockdent)
          break

        block.registerConstruct(construct)
    test:
      text = (
        'MetaLanguage Test config:\n'
        '  Construct A;\n'
        '  Construct B;\n'
        '  Construct C;\n'
        'end MetaLanguage;\n'
      )
      schema, context, metafile = test.newTestSchema(text)
      block = metax.attr.ComplexBlock(schema, 'config:', [], schema)
      metafile.set(22, 1)
      metafile.parseComplexBlock(block, 2)
      fp = test.fp()
      block.writeValueLines(fp=fp)
      test.iseqtext(
        '\n'
        '  Construct A;\n'
        '  Construct B;\n'
        '  Construct C;\n',
        fp.getvalue())
    end method parseComplexBlock;

    method parseConstruct : Construct #:
      Parse a Construct at the current parser position.

      SideEffects:
       - advances the parser position to the line that terminates the parsed
         construct (this is either a line containing an explicit construct
         terminator, or a line
         parsed construct, at the first non-space character.

      Returns:
        The parsed construct, or null if EOF has been reached or an
        error occurred during parsing.
    params:
      var parent : ComplexBlock #:
        The parent of the to-be-parsed construct.
      var indent : int #:
        The indentation at which the construct must occur.
      var consgroup : ConsGroup #:
        The list of legal construct kinds in the current block.
    scope:
      result = None
      context = self.context()
      /#consgroup = context.legalInfo(legals)
      primaries = consgroup.primaries()

      /# Skip past empty lines
      line, index, matches, precount = self.skipEmptyLines(indent=indent)
      if not matches:
        /# The first token is NOT found at column 'indent', which means either
        /# we've encountered an implicit construct termination or an error.
        if line.indent() < indent:
          /# Implicit termination.
          parent.postcountIs(precount)
        else:
          /# Probably an error. We advance past all lines at indent 'indent'
          self.skipToIndent(indent-1)

        return None

      /# Check for eof
      if not line: return None

      /# If we are at the end of the complex block, then precount refers to
      /# the number of lines after the last construct.  We update the parent
      /# postcount each time this method is invoked.
      parent.postcountIs(precount)

      /# Consume feature attribute keys and values until we reach a token
      /# that is in 'consgroup' (a token identifying a construct kind that is
      /# legal in this context).
      text = self.text()
      feature_tuples = []
      consinfo = None
      /# the position within text of the start of the primary key
      lnum = self.lnum()
      start = index
      while True:
        atuple = self.peekFeatureOrPrimaryToken(start, consgroup)
        token_data = atuple[3]
        if token_data == 'primary_key':
          break
        elif token_data == 'error':
          /# We have encountered an error ... we were unable to find
          /# a feature value or primary token.  For now, we skip forward
          /# to the end of the block containing the construct being parsed.
          self.error(
            'Unrecognized feature/primary token %s' % str(atuple),
            line=line.num()-1)
          self.skipToIndent(indent-1)
          return None
        else:
          word, attrkey, attrsel, form, index, _, fnum, fcol = atuple
          self.debug('%s "%s"' % (form, word), line=fnum, col=fcol)
          feature_tuples.append(atuple)
          index = atuple[4]
          if text[index] == '\n':
            line, index, matches = self.nextLine(indent=indent)
            if not matches:
              self.skipToIndent(indent-1)
              return None
          start = index

      /# The only way we reach this point is by finding a construct primary
      /# key.
      word, pkey, psel, _, index, consinfo, primary_lnum, primary_col = atuple
      self.debug(
        'kind "%s"' % consinfo.name(),
        line=primary_lnum, col=primary_col)

      /# We have identified a primary.
      /#  - It is useful to have the construct registered in the parent as
      /#    soon as possible (e.g. not waiting until all attributes have
      /#    been parsed).
      /#  - Since a construct is registered with its parent block by id
      /#    (aka primary attribute value), it is important that we obtain the
      /#    id before creating the construct.
      /#  - Note that some primary attributes have optional (auto-assigned)
      /#    values, and in some situations it can appear that a primary
      /#    has an explicit value when in fact that value should be given
      /#    to a replacer attribute).
      primary_litkey = word
      /# Data about the primary key.
      primary_data = consinfo.primary()[primary_litkey]
      valopt = primary_data['valopt']
      replacer = primary_data.get('replacer', None)
      replacer_attribute = None
      /# Keys represent all legal secondary key tokens
      secondaries = consinfo.secondaries()
      /# The value of an implicit-key secondary

      /#print('HERE with litkey %s valopt %s' % (primary_litkey, valopt))

      /# When this block is finished, we will have:
      /#  - identified the primary_value
      /#  - identified the index within text of one char past the end of the
      /#    primary value.
      /#  - detected need for autoassigned id.
      /#  - handled replacer semantics
      /#  - returned from method on error
      primary_value_start = index
      if text[index] == '\n':
        /# We have a situation where the value associated with the primary
        /# key is not on the same line as the key. For now at least, we
        /# require values to start on same line as key, so either this value
        /# is optional or we have an error.
        if valopt:
          primary_value = context.autoId()
        else:
          col = index - line.start()
          self.error('Missing primary id', line=self.lnum(), col=col)
          /# TODO(wmh): We are skipping the entire collection of lines with
          /# indent >= indent, which is maybe more aggresive than we need.
          self.skipToIndent(indent-1)
          return None
      else:
        word, _, next_index = self.peekWord(index)
        if valopt:
          if word in secondaries:
            /# CODETANGLE(baselang_keys)
            /# word is a secondary key, so we autoassign a primary value
            /#  - we avoid updating index, so that the secondary attribute
            /#    code below will properly handle the secondary key we've
            /#    found.  We could do a bit of optimization on this...
            /#
            /# Note that normally we allow attribute values that contain the
            /# same text as a key (e.g. Construct Construct, var var, etc.)
            /# but NOT when the value is optional.
            primary_value = context.autoId()

          elif replacer:
            /# There are two possibilities here: the attribute key specified
            /# in 'replacer' is either explicitly specified within this
            /# construct or not. In the former case, 'word' is the identifier
            /# as normal. However, in the latter case, 'word' is the value
            /# (or start of the value) to be assigned with the attribute
            /# identified in replacer, and we are to:
            /#  - autoassign an id.
            /#  - implicitly create a secondary attribute for the implicit
            /#    replacer.
            /#
            /# Since constructs are registered by id, it is important for us
            /# to know *now* (not later) what the correct id is, so rather than
            /# parsing all secondaries to verify that the replacer attribute
            /# isn't explicitly specified, we require that if an explicit
            /# id is needed for a construct with a replacer, the replacer
            /# attribute *must* be explicitly specified immediately after
            /# the primary value. Thus, we can simple peek at the second
            /# word (the one starting at next_index). If it matches replacer,
            /# word is an explicit id, else it is part of the replacer value.
            text = self._text
            if text[next_index] == '\n':
              /# When an explicit identifier is needed for a construct with
              /# replacer semantics, the replacer attribute must not only appear
              /# after the id, but must (for now at least) also appear on the
              /# same line. So, a newline means no explicit replacer.
              found_replacer = False
            else:
              /# We peek forward.
              word2, _, next_index2 = self.peekWord(next_index)
              if word2 == replacer:
                /# There *is* an explicit replacer attribute, so 'word' is
                /# the identifier and we don't need to do anything special.
                found_replacer = True
              else:
                /# There is no explicit replacer, so 'word' is part of the
                /# implicit replacer value and we auto-assign the id.
                found_replacer = False

            /# print('Here with word="%s" word2="%s" found=%s' % (word, word2, found_replacer))

            if found_replacer:
              /# There is an explicit replacer attribute after 'word', so
              /# 'word' is an explicit primary id.
              primary_value = word
              index = next_index

            else:
              /# We are to auto-assign the primary id and create an implicit
              /# attribute for the replacer attribute.
              primary_value = context.autoId()
      
              /# Parse the value of the implicit replacer attribute. It starts
              /# at index 'index'.
              /#  - we create a faux construct instance, which is needed in
              /#    parseSecondaryAttribute to:
              /#     - set termcode of context (irrelevant)
              /#     - obtain context when parsing blocks (irrelevant)
              /#     - register attribute (intentionally disabled when an
              /#       explicit_key is provided)
              /#  - must remember to change the parent!
              construct_class = consinfo._construct_class
              dummy_construct = construct_class(primary_value, None, context)

              /# Import to set index before (so that parsing starts at proper
              /# place), and obtain index after (so that later code sets index
              /# properly).
              self.indexIs(index)
              replacer_attribute, errtok = self.parseSecondaryAttribute(
                dummy_construct, consinfo, indent, explicit_key=replacer)
              index = self.index()

          else:
            /# word is the primary_value
            primary_value = word
            index = next_index
        else:
          /# word must be the primary value.
          primary_value = word
          index = next_index
          if replacer:
            /# A replacer attribute should not exist if the primary
            /# attribute isn't optional.
            /# TODO(wmh): This check should happen during parsing of the
            /# metaschema, not here.
            metafile.error(
              '%s %s is not optional but has replacer %s' %
              (primary_litkey, word, replacer))

      self.debug(
        '  id "%s"' % primary_value,
        line=self.lnum(), col=primary_value_start - line.start())

      /# Update position ... past primary value and whitespace, all on same line
      /# as started this method (so we don't need to update the line).
      self.indexIs(index)

      /# Create the primary construct
      primary = self.__class__.CreateNewAttribute(
        None, consinfo, primary_litkey,
        value=primary_value, line=primary_lnum, col=primary_col, metafile=self)

      /# Establish the class to use to implement this construct instance.
      /#  - The ConsInfo instances properly identify the class of all
      /#    constructs except BaseLanguage, which are treated specially
      /#    (for metalang <X> and baselang <Y>, the class is <X><Y>).
      /#  - TODO(wmh): It is unfortunate that we need to test if the current
      /#    construct is BaseLanguage in this (very frequently invoked) method.
      /#    Can we find a way to avoid having ot make that check?  Maybe we
      /#    parse all of them into BaseLanguageConstruct instances initially,
      /#    and then patch up with downcasts later?
      /#  - TODO(wmh): Merge BaseLanguageConstruct and BaseLanguage into
      /#    a single class.
      construct_class = consinfo._construct_class
      if consinfo.name() == 'BaseLanguage':
        /# BaseLanguage constructs are special
        /#  - all other constructs of a given kind are implemented by a class
        /#    identified solely by the kind.
        /#  - for baselang constructs, each instance is implemented by its
        /#    own class, based on both kind and id.
        /#  - for metalang <Y> and baselang <X>, the class is <Y><X>.
        /#  - if we do not find the more refined class, we use BaseLanguageConstruct,
        /#    but this should only happen if we are in code like command schema,
        /#    where we don't expect the classes to be defined yet.
        parent_construct = parent.parent()
        metal = parent_construct.id().capitalize()
        basel = primary.value().capitalize()
        class_name = metal + basel
        metax_module = sys.modules['metax']
        /# TODO(mwh): Generalize this (need to know which metalang the baselang
        /# is in!!)
        metax_c_module = metax_module.oopl
        better_construct_class = getattr(metax_c_module, class_name, None)
        if better_construct_class:
          construct_class = better_construct_class
        /# print('MetaFile.parseSecondaryAttribute: metalang %s baselang %s = %s [%s]' % (
        /#   metal, basel, class_name, construct_class))

      /# Create the construct
      if construct_class:
        /# All kind-specific construct_classes use the same signature as
        /# Construct.
        construct = construct_class(primary.value(), parent, context)
      else:
        /# There is no kind-specific construct class registered for this
        /# construct, so we use a GenericConstruct, which passes in the
        /# kind explicitly.
        construct = metax.meta.GenericConstruct(
          primary.value(), parent, context, primary.key())

      /# We update the construct
      construct.precountIs(precount)
      primary.parentIs(construct)

      /# Parse all of the feature keys/values into FeatureAttributes.
      /#  - the list of feature keys and feature values in feature_tuples are
      /#    valid for *some* construct in the meta language, but it is
      /#    entirely possible they will not be valid for the construct that
      /#    has been identified ... any unrecognized keys/values are reported
      /#    as errors.
      featvals = consinfo.featvals()
      featkeys = consinfo.features()
      i = 0
      n = len(feature_tuples)
      while i < n:
        token, featkv, fsel, form, index, data, feat_lnum, feat_col = feature_tuples[i]
        featinfo = {
          'parent': construct, 'value': None,
          'line': feat_lnum, 'col': feat_col
        }
        if form == 'feature_key':
          /# We have an explicit feature key ... next index must be a value
          /# for this feature key.
          featkey = featkv
          finfo = featkeys[featkey]
          featinfo['litkey'] = featkey
          featinfo['key'] = finfo['cankey']
          i += 1
          if i < n:
            _, featval, featsel, form, index, data, _, _ = feature_tuples[i]
            if form != 'feature_value':
              self.error(
                'Expecting feature value for feature key %s but found unknown %s' %
                (featkey, featval), line=self.lnum())
            else:
              /# We know featval is a legal feature value (or we wouldn't have
              /# gotten here ... right?), but we don't know for sure that it
              /# is a feature value for featkey
              valkey = featvals[featval]
              assert valkey is not None
              if valkey != featkey:
                self.error(
                  'Expecting feature value for feature key %s but found value %s for key %s' %
                  (featkey, featval, valkey))
              else:
                featinfo['value'] = featval

              /# If there was a selector specified on the feature key, we verify
              /# that the selector matches current baselang. If not, we ignore
              /# the feature attribute/key pair entirely.
              if fsel:
                baselang = construct.baselang()
                suffix = baselang.suffix()
                if '.' + fsel != suffix:
                  print('***** IGNORING %s = %s for %s (specific to %s)' % (
                    featkey, featval, suffix, fsel))
                  featinfo = None

          else:
            self.error(
              'Missing feature value for feature key %s' % featkey,
              line=self.lnum())
        elif form == 'feature_value':
          /# We have an implicit feature key dicated by featval
          featval = featkv
          if featval not in featvals:
            self.error(
              "Invalid feature value '%s' for %s" % (featval, construct.kind()))
            featinfo = None
          else:
            featkey = featvals[featval]
            featinfo['litkey'] = ''
            featinfo['key'] = featkey
            featinfo['value'] = featval
        elif form == 'error':
          self.debug('Fix me!')
          self.error('Invalid token "%s"' % token)
          featinfo = None
        else:
          raise Error('Here with form %s' % form)

        /# Create the FeatureAttribute
        if featinfo:
          feature = metax.attr.FeatureAttribute(**featinfo)
          construct.registerAttribute(feature)

        /# Advance to next feature key/value.
        i += 1

      /# Register the primary with the construct
      construct.registerAttribute(primary)
      construct.termcodeIs(TERM_UNINIT)

      /# If there is an implicit replacer attribute parsed, add it.
      if replacer_attribute:
        replacer_attribute.changeParent(construct)

      /# Now parse secondary attributes.
      while True:
        line = self.line()
        if line is None or line.indent() < indent:
          /# Implicit termination
          construct.termcodeIs(0)
          break

        /# Check if we are currently at end-of-line, and advance if so.
        index = self.index()
        if text[index] == '\n':
          line, index, matches = self.nextLine(indent=indent)
          if not matches:
            /# The new line has a different indent than needed in order for
            /# it to be another attribute, so we must have an implicit
            /# construct termination.
            construct.termcodeIs(0)
            break

        attribute, errtok = self.parseSecondaryAttribute(
          construct, consinfo, indent)
        if not attribute:
          /# There are two possible reasons for attribute to be null:
          /#  1. end-of-construct (explicit or implicit)
          /#  2. syntax error
          /# These are handled below.
          break

      /# Handle termination issues
      termcode = construct.termcode()
      index = self.index()
      if termcode != TERM_UNINIT:
        /# The construct has been successfully parsed.
        self.debug('  termcode %d' % termcode)
        /# We expect the construct to be at end-of-line, except when an
        /# implicit termination was identified.
        if termcode == 0:
          /# An implicit termination was identified.
          /#  - normally, the current index is where we are to start parsing
          /#    the next entity.
          /#  - however, if the last attribute was a simple block, and it ended
          /#    with empty lines, those lines should not be considered part of
          /#    the simple block, so we back up if they exist.
          last_attribute = construct.order()[-1]
          if last_attribute.isSimpleBlock():
            aval = last_attribute.value()
            k = len(aval) - 1
            emptyln = 0
            while k >= 0 and not aval[k].strip():
              k -= 1
              emptyln += 1
              aval.pop()
            if emptyln:
              /# print('Found %d empty lines above %d in %s' % (emptyln, self.lnum(), self.path()))
              
              self.set(lnum=self.lnum() - emptyln)
        else:
          if text[index] == '\n':
            /# This is what we normally expect at end of construct.
            self.nextLine()
          else:
            /# When does this happen?
            print(text[index:index+30])
            raise Error('How to handle this?')
      else:
        /# We have an error, and no recovery has yet been performed.
        self.debug(
          '  parse error on %s' % errtok,
          line=self.lnum(), col=index - line.start())
        construct = None

      /# Return the construct
      return construct
    tests:
      testx basics scope:
        text = (
          'MetaLanguage Test config:\n'
          '  Construct A config:\n'
          '    Attribute default : word = <empty> aliases <=>;\n'
          '    kind primary noval Attribute Attribute : id = <required>;\n'
          '\n'
          '    kind secondary showkey\n'
          '    Attribute type : word = <empty> aliases <:> #:\n'
          '      A comment\n'
          '    config:\n'
          '      FeatureValue f;\n'
          '      FeatureValue g #:\n'
          '        some comment\n'
          '      FeatureValue h;\n'
          '    end Attribute type;\n'
          '  end Construct;\n'
          'end;\n'
        )
        metafile, context = test.schemaParser(text)
        scope = metax.attr.ComplexBlock(
          self.construct, 'scope:', [], None, line=0, col=0)

        /# Parse the simplest construct possible ('FeatureValue f;')
        metafile.set(lnum=9)
        featval = metafile.parseConstruct(
          scope, 6, context.legalInfo(['FeatureValue']))
        test.iseq('FeatureValueConstruct', featval.__class__.__name__)
        test.iseq('FeatureValue', featval.kind())
        test.iseq('f', featval.id())
        test.iseq(1, featval.termcode())
        test.iseqvec(['FeatureValue f'], [a.asStr() for a in featval.order()])

        /# Now a more complex construct with simple secondary keys.
        metafile.set(lnum=2)
        attrdef = metafile.parseConstruct(
          scope, 4, context.legalInfo(['Attribute']))
        test.iseq('AttributeConstruct', attrdef.__class__.__name__)
        test.iseq('Attribute', attrdef.kind())
        test.iseq('default', attrdef.id())
        test.iseq(1, attrdef.termcode())
        test.iseqvec(
          ['Attribute default', ': word', '= <empty>', "aliases <=>"],
          [a.asStr() for a in attrdef.order()])

        /# Now a construct with some feature attributes.
        metafile.set(lnum=3)
        attrprim = metafile.parseConstruct(
          scope, 4, context.legalInfo(['Attribute']))
        test.iseq('AttributeConstruct', attrprim.__class__.__name__)
        test.iseq('Attribute', attrprim.kind())
        test.iseq('Attribute', attrprim.id())
        test.iseqvec(
          ['kind primary', 'noval', 'Attribute Attribute', ': id', '= <required>'],
          [a.asStr() for a in attrprim.order()])

        /# Verify that an attempt to parse a construct at a given indent
        /# when on a line at a different indent yields null.
        metafile.set(lnum=13)
        test.isnull(
          metafile.parseConstruct(
            scope, 6, context.legalInfo(['FeatureValue'])))
        test.isnull(
          metafile.parseConstruct(scope, 2, context.legalInfo(['Construct'])))

        /# Now a construct with feature attributes and block-valued secondaries
        /# (both simple and complex).
        metafile.set(lnum=5)
        /#metafile.debuglevelIs(4)
        /#metafile.show()
        attrtype = metafile.parseConstruct(
          scope, 4, context.legalInfo(['Attribute']))
        /#metafile.printLog()
        fp = test.fp()
        attrtype.write(fp=fp)
        out = fp.getvalue()
        test.iseqtext(
          'kind secondary showkey\n'
          'Attribute type : word = <empty> aliases <:> #:\n'
          '  A comment\n'
          'config:\n'
          '  FeatureValue f;\n'
          '  FeatureValue g #:\n'
          '    some comment\n'
          '  FeatureValue h;\n'
          'end Attribute type;\n',
          out)

        /# Now an edge-case that was at one point causing an infiite loop
        text = (
          'MetaLanguage Meta\n'
          'comment:\n'
          '  Here with notes\n'
          'config:\n'
          'end MetaLanguage;\n'
        )
        metafile, context = test.schemaParser(text)
        scope = metax.attr.ComplexBlock(
          test.construct, 'scope:', [], None, line=0, col=0)
        schema = metafile.parseConstruct(
          scope, 0, context.legalInfo(['MetaLanguage']))
        fp = test.fp()
        schema.write(fp=fp)
        test.iseqtext(
          'MetaLanguage Meta\n'
          'comment:\n'
          '  Here with notes\n'
          'config:\n'
          'end MetaLanguage;\n',
          fp.getvalue())

      testx optionals scope:
        /# Verify that optional primary values work.
        text = (
          'lifecycle params:\n'
          '  var a : int;\n'
          'scope:\n'
          'end;\n')

        _, schema, context, compiler = test.cachedInfo()
        metafile = metax.c.MetaFile('fauxpath', compiler, text)
        metafile.contextIs(context)
        scope = metax.attr.ComplexBlock(None, 'scope:', [], line=0, col=0)

        lifecycle = metafile.parseConstruct(
          scope, 0, context.legalInfo(['lifecycle']))
        test.isfalse(metafile.hasErrors(show=True))
        fp = test.fp()
        lifecycle.write(fp=fp)
        test.iseqtext(
          'lifecycle  params:\n'
          '  var a : int;\n'
          'scope:\n'
          'end;\n',
          fp.getvalue())

      testx replacer scope:
        /# Verify that replacer semantics works.
        text = (
          'case (i > 10) ::\n'
          '  j += 3\n'
          'end;\n'
        )

        _, schema, context, compiler = test.cachedInfo()
        metafile = metax.c.MetaFile('fauxpath', compiler, text)
        metafile.contextIs(context)
        scope = metax.attr.ComplexBlock(None, 'scope:', [], line=0, col=0)

        loop = metafile.parseConstruct(scope, 0, context.legalInfo(['case']))
        test.isfalse(metafile.hasErrors(show=True))
        /# loop.write()

    end method parseConstruct;

    method parseSecondaryAttribute : tuple<metax.attr.Attribute,str> #:
      Parse a secondary attribute, supporting optional keys and values.

      The caller is responsible for ensuring this method is only invoked in
      situations where a secondary attribute or explicit/implicit
      end-of-construct is expected.  This method should not be invoked with
      the current position on whitespace (caller responsibility to advance
      past newlines, etc.)

      SideEffects:
       - self.index() is set to the position after the value (after skipping
         spaces but not newlines, except for block-values, which consume
         newlines up to a line with less indent than needed for the block
         value).
       - construct.termcode() must be TERM_UNINIT when this method is invoked,
         and is changed to 0 or greater if a terminator is found (in which
         case null is returned)

      Returns:
       0) attribute : The parsed attribute or null if:
           - an implicit or explicit end-of-construct is seen
           - if an error is encountered
       1) error_token : str or null
           - null if attribute found, the token at current index if error.
    params:
      var construct : Construct #:
        The construct for which an attribute is being parsed.
      var consinfo : ConsInfo #:
        The construct info needed to parse secondary attributes.
      var indent : int #:
        The indent at which secondary attributes that start a new line are
        required to be indented at.
      var explicit_key : str = null #:
        If present, it implies many things:
         - the second attribute key has already been parsed, and self.index()
           is at the start of the value (whitespace already skipped)
         - the litkey and cankey are the same (and specified by explicit_key)
         - the resulting Attribute instance is NOT registered with the
           construct (normally it is registered ... caller responsible to
           register the attribute if explicit_key is provided).
    scope:
      debug = False
      assert construct.termcode() == TERM_UNINIT
      index = self.index()
      lnum = self.lnum()
      line = self.line()
      key_col = index - line.start()
      text = self.text()
      context = construct.context()

      if explicit_key:
        /# Normally, 'index' is the start of the attribute key, and we parse
        /# both key and value in this method. However, if explicit_key is
        /# non-null, it is an indication that the key has been parsed and index
        /# is the start of the attribute value (whitespace already skpped).
        litkey = explicit_key
        key = explicit_key
        basel = None
        value_start = index
        termcode = TERM_UNINIT
        secondaries = consinfo.secondaries()
        secondary = secondaries.get(explicit_key, None)
        if secondary is None:
          self.error('internal error ... unexpected replacer', line=self.line())
          /# TODO(wmh): Return both null may break caller.
          return (None, None)
        elif secondary['cankey'] != explicit_key:
          self.error(
            'internal error ... unexpected replacer cankey', line=self.line())
          /# TODO(wmh): Return both null may break caller.
          return (None, None)

      else:
        /# Obtain the secondary key (or terminator)
        litkey, key, basel, secondary, value_start, termcode = self.peekSecondaryToken(
          construct, index, context, consinfo)

      /# Check for special-case end-of-parsing
      if line.indent() != indent:
        /# TODO(wmh): Suppose line.indent() is 5. This is currently printing
        /#   E18: Expecting indent 4 not 5.
        /#   E18: Expecting indent 2 not 5.
        /#   E18: Expecting indent 0 not 5.
        /# when it should only print
        /#   E18: Expecting indent 4 not 5.
        self.error('Expecting indent %d not %d' % (indent, line.indent()))
        return (None, litkey)

      elif termcode != TERM_UNINIT:
        /# If we've found an end-of-construct, set it and return.
        construct.termcodeIs(termcode)
        self.indexIs(value_start)
        return (None, litkey)

      elif secondary is None:
        /# The current token does not match a secondary attribute of
        /# 'construct' and is either an implicit termination or a syntax
        /# error. We heuristically determine which by the following logic:
        /#  - if the parsed token is NOT the first one on the current line,
        /#    this cannot be an implicit termination and is an error.
        /#  - if the parsed token is the first on the current line
        /#     - if it is indented less than 'indent', it is definitely
        /#       an implicit end-of-construct indicator
        /#     - if it is indented equal to 'indent', it may be an implicit
        /#       termination or a syntax error:
        /#         - if the token ends in ':', it cannot represent the
        /#           start of a new construct (cannot be a feature key,
        /#           feature value or primary key) and cannot be a terminator,
        /#           so it must be an incorrectly specified secondary token.
        /#         - otherwise we assume it is an implicit termination and
        /#           detect the syntax error in parseConstruct.

        if False and litkey == 'case':
          print(
            '****** HERE with litkey=%s key=%s basel=%s secondary=%s termcode=%d line=%d:%s' % 
            (litkey, key, basel, secondary, termcode, lnum, line.line()))

        ldent = line.indent()
        if index == line.start() + ldent:
          if ldent < indent:
            /# Definite implicit construct termination
            construct.termcodeIs(0)
          elif ldent == indent:
            if litkey is None or litkey[-1] == ':':
              /# This cannot possibly be a feature key, feature value or
              /# primary key, so it isn't the start of a new construct. Must
              /# be an typed secondary key.
              self.error(
                'Unknown secondary token "%s"' % litkey, line=lnum, col=key_col)
              /# The most likely situation is that an attribute key has been
              /# mistyped.
              /#  - TODO(wmh): A common instance of this error is when a user
              /#    specifies a superclass of a class using ':' instead of '<'.
              /#    By skipping to indent-1, we consume the entire namespace,
              /#    and thus only print one error when many classes could be
              /#    having the same problem.
              /#  - Can we find a way of skipping to next construct instead of
              /#    all the way to end of scope?
              self.skipToIndent(indent-1)
              construct.termcodeIs(TERM_UNINIT)
            else:
              /# May or may not be implicit construct termination but we assume
              /# it is an implicit termination and detect errors later.
              construct.termcodeIs(0)
          else:
            /# We have a first-token indented more than indent, which should not
            /# be possibly if our logic is correct.
            raise InternalError('Indent %d > %d' % (ldent, indent))
        else:
          /# Definitely an error.
          self.error(
            'Unknown secondary token "%s"' % litkey, line=lnum, col=key_col)
          /# The most likely situation is that an attribute key has been
          /# mistyped.
          self.skipToIndent(indent-1)
          construct.termcodeIs(TERM_UNINIT)
        return (None, litkey)

      /# Some important values
      plex = False
      type = secondary['type']
      if type == 'simplex':
        /# A block marked as simplex is complex if the attribute selector is
        /# '*', and simple otherwise.
        type = 'complex' if basel == '*' else 'simple'
        /# print('SET type simplex to %s for %s %s' % (type, construct.kindfqn(), basel))
        plex = True

      self.debug('  akey "%s" (%s : %s) [%s] %d' % (litkey, key, type, basel, value_start))

      /# Create the attribute
      /#  - we do this before we parse the value, so that we can register
      /#    the attribute with its construct before the value gets parsed
      /#    (the value can represent almost the entire file, and it is
      /#    useful to have a lexical chain established during parsing for
      /#    debugging purposes).
      attribute = MetaFile.CreateNewAttribute(
        construct, consinfo, litkey, key=key, value=None,
        line=lnum, col=key_col, metafile=self, type=type)

      if basel is not None:
        attribute.baselIs(basel)

      /# Register the attribute with the construct
      /#  - we do not need the value to properly register anything other
      /#    than the primary attribute.
      if not explicit_key:
        construct.registerAttribute(attribute)

      /# Parse the value based on the attribute value type and current char.
      /#  - the type will never be 'feature' here.
      /#  - MUST initialize next_index to be the index one past the end of
      /#    the parsed value.
      valdone = False
      val_col = value_start - line.start()
      c = text[value_start]
      if type in ('id', 'xid', 'word', 'num', 'enum'):
        /# Parse a word and validate against type.
        value, adj, next_index = self.peekWord(value_start)
        type_checker = MetaFile.AttrTypeCheck.get(type, None)
        if type_checker and not type_checker(key, type, value):
          /# We expected a value of type 'type' but 'value' does not match.
          self.error(
            'Expecting %s value of type %s not %s' %
            (key, type, value), line=lnum, col=val_col)
          /# TODO(wmh): Do we do anything to recover?
          value = None

      elif type == 'str':
        eprs = ExprParser(self, row=self.lnum(), col=val_col)
        value = eprs.parse()
        if value:
          next_index = line.start() + eprs.col()
        else:
          /# TODO(wmh): What is the proper thing to do when we are expecting
          /# a literal string and don't find one?  For now, consume a single
          /# word (throwing it away) so that the parser can make progress.
          token, _, next_index = self.peekWord(value_start)
          self.error(
            'Expecting %s value to be a literal string, not %s' %
            (key, token))

      elif type == 'expr':
        /# Obtain an Expr instance.
        eprs = ExprParser(self, row=self.lnum(), col=val_col)
        value = eprs.parse(attribute=attribute)
        if value:
          self.lnumIs(eprs.row())
          line = self.line()
          next_index = line.start() + eprs.col()
        else:
          /# TODO(wmh): What is the proper way to recover from an error in which
          /# we expect an expression and don't find one? For now, we skip
          /# whatever the expression managed to parse (if nothing, we skip one
          /# word).
          if eprs.row() == self.lnum() and eprs.col() == self.column():
            /# No progress was made, so we skip a word
            value, _, next_index = self.peekWord(value_start)
            self.error(
              'Expecting %s value to be an expression, not %s' %
              (key, value))
          else:
            /# We managed to parse something before encountering an error.
            line = self.line(lnum=eprs.row())
            index = line.start() + eprs.col()
            fragment = line.line(start=index)
            self.error(
              'Expecting %s value to be an expression, but failed in "%s"' %
              (key, fragment))
            /# Skipping the next word or skipping to the next line may introduce
            /# more errors (especially if we end up skipping a block-valued
            /# attribute key). So we ...
            value, _, next_index = self.peekWord(value_start)
            /#raise Error('Fix Me!')

      elif type == 'type':
        /# Obtain an Type instance
        /# TODO(wmh): For now, we are requiring types to be encoded in a single
        /# word, but we need to generalize this to allow whitespace in
        /# the template portion of the type.
        word, adj, next_index = self.peekWord(value_start)

        def NF():
          result = construct.ancestor('namespace')
          if result is None:
            /# This can happen if we have a class at File-level. This code is
            /# in parseMeta(), which is executed *before* 
            /# metalang.preExpandFileConstruct(), where the class constructs
            /# are moved into their namespaces.
            print('**** HERE with current %s' % self.current_namespace())

            print('**** Failed to find namespace for %s' % construct.kindfqn())
          return result

        namespace_function = NF

        if False:
          nmsp = namespace_function()
          assert isinstance(nmsp, metax.oopl.NamespaceConstruct), (
            'For type "%s" at %d:%d of %s, namespace_function yields %s = %s' %
            (word, self.lnum(), self.column(), self.path(), nmsp, nmsp.kindid()))
        /# if namespace_function() is None: raise Error('Failed to resolve namespace in %s' % construct.fqn())

        value = Type.Instance(
          word, allow_invalid=True, cons=construct.kind(),
          namespace_function=namespace_function)

      elif type == 'simple':
        /# Parse an indented list of strings
        context = construct.context()
        blockdent = context.token('blockdent')
        /# Initialize the attribute value, which was set to null during creation.
        attribute.valueIs([])
        /# We verify there is no extra text after the scope indicator.
        /#  - TODO(wmh): In the future, we may want to consider allowing such
        /#    extra text to support one-line blocks ala Python.
        /#  - this does not HAVE to be an error (could be a warning), since
        /#    it doesn't affect the correctness of parsing subsequent
        /#    lines
        /#  - a block can be empty.
        /#  - we may want to deal with empty lines at the end of a simple
        /#    block, especially if the block ends due to encountering a
        /#    line indented less than indent (which indicates an implicit
        /#    construct termination).
        fragment = line.line(start=value_start)
        if fragment:
          self.error(
            'Found spurious text after scope indicator: "%s"' % fragment,
            line=self.lnum(), col=value_start)

        /# Advance to next line and start parsing.
        self.nextLine()
        self.parseSimpleBlock(attribute, indent + blockdent)
        value = attribute.value()
        /# The value of attribute and self.index() have already been properly
        /# set. We indicate this with valdone
        valdone = True

      elif type == 'complex':
        /# Parse an indented list of constructs
        /#  - the 'secondaries' dict contains 'children', which is the list
        /#    of legal construct ids within the complex block.
        context = construct.context()
        blockdent = context.token('blockdent')
        line, index, _ = self.nextLine()
        attribute.valueIs([])
        legals = secondary.get('children', None)
        /# self.debug('Parsing complex block', line=99, col=99)
        self.parseComplexBlock(attribute, indent + blockdent, legals=legals)
        value = attribute.value()
        /# The value of attribute and self.index() have already been properly
        /# set. We indicate this with valdone
        valdone = True

      else:
        raise InternalError(
          'Unknown type "%s" in MetaFile.parseSecondaryAttribute' %
          type)

      /# Print out the attr value if debugging.
      vcol = value_start - line.start()
      if attribute.isSimpleBlock():
        self.debug('   val [%d elements]' % len(value), line=lnum, col=vcol)
      elif attribute.isComplexBlock():
        /# Since there will be a whole bunch of sub-constructs parsed
        /# between the debug entry for the attribute key and the attribute
        /# value, it is more confusing than not to print anything here.
        pass
      else:
        self.debug('   val "%s"' % value, line=lnum, col=vcol)

      /# Assign the attribute value.
      if not valdone:
        /# Skip past spaces.
        while text[next_index] == ' ': next_index += 1
        self.indexIs(next_index)
        attribute.valueIs(value)

      /# It is important that we properly set stoken() if attribute is None
      assert attribute is not None
      return (attribute, None)
    tests:
      testx t1 scope:
        text = (
          'MetaLanguage Test config:\n'
          '  Construct A config:\n'
          '    Attribute type : word = <empty> aliases <:> #:\n'
          '      A comment\n'
          '    config:\n'
          '      FeatureValue f;\n'
          '      FeatureValue g #:\n'
          '        some comment\n'
          '      FeatureValue h;\n'
          '    end Attribute type;\n'
          'File f path "/this/is/a/test space.txt";\n'
        )
        badtext = (
          'MetaLanguage Test config:\n'
          '  Construct A config:\n'
          '    Attribute type : word = <empty> aliases >:< #: extra text\n'
          '      A comment\n'
          '    config:\n'
          '      FeatureValue f;\n'
          '      FeatureValue g #:\n'
          '        some comment\n'
          '      FeatureValue h;\n'
          '    end Attribute type;\n'
          'File f path "/this/is/a/test space.txt";\n'
        )
        schema, context, metafile = test.newTestSchema(text)
        badfile, badctx = test.schemaParser(badtext)
        scope = metax.attr.ComplexBlock(
          self.construct, 'scope:', [], None, line=0, col=0)
        file = metax.meta.FileConstruct('f', None, context)
        attr = metax.meta.AttributeConstruct('type', None, context)
        badattr = metax.meta.AttributeConstruct('type', None, context)

        /# Test parsing a secondary attribute of type 'word'
        metafile.set(lnum=2, adj=15)
        test.iseq(':', metafile.line().line(start=metafile.index())[0])
        attrinfo = context.consmap()['Attribute']
        test.iseq('word', attrinfo.secondaries()[':']['type'])
        type, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 4)
        test.iseq('WordAttribute', type.__class__.__name__)
        test.iseq('type', type.key())
        test.iseq(':', type.litkey())
        test.iseq(74, metafile.index())

        /# Test parsing a secondary attribute of type 'enum'
        metafile.set(lnum=2, adj=32)
        test.iseq('aliases', metafile.line().line(start=metafile.index())[0:7])
        test.iseq('enum', attrinfo.secondaries()['aliases']['type'])
        aliases, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 4)
        test.iseq('WordAttribute', type.__class__.__name__)
        test.iseq('aliases', aliases.key())
        test.iseq([':'], aliases.value())
        test.iseq(96, metafile.index())
        test.isfalse(metafile.hasErrors(show=True))
        /# Same test, but with a non-enum value.
        badfile.set(lnum=2, adj=32)
        aliases2, _ = badfile.parseSecondaryAttribute(badattr, attrinfo, 4)
        test.iseq(1, badfile.numErrors())

        /# Test parsing a secondary attribute of type 'simple'
        metafile.set(lnum=2, adj=44)
        test.iseq('#:', metafile.line().line(start=metafile.index())[0:2])
        test.iseq('simple', attrinfo.secondaries()['#:']['type'])
        comment, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 4)
        test.isfalse(metafile.hasErrors(show=True))
        /# Same test, but with extra text after the scope indicator.
        badfile.set(lnum=2, adj=44)
        test.iseq('#: extra text', badfile.line().line(start=badfile.index())[0:13])
        comment2, _ = badfile.parseSecondaryAttribute(
          metax.meta.AttributeConstruct('type', None, badctx), attrinfo, 4)
        test.iseq(2, badfile.numErrors())

        /# Test parsing a secondary attribute of type 'complex'
        metafile.set(lnum=4)
        test.iseq('config:', metafile.line().line(start=metafile.index())[0:7])
        test.iseq('complex', attrinfo.secondaries()['config:']['type'])
        config, _ = metafile.parseSecondaryAttribute(
          metax.meta.AttributeConstruct('type', None, context),
          attrinfo, 4)
        /#test.isfalse(metafile.hasErrors(show=True))
        metafile.hasErrors(show=True)

        /# Test parsing an error that was causing an infinite loop.
        /#   - note that 'children<Attribute>' should be 'children <Attribute>',
        /#     and we expect Meta to report a syntax error here, not go into
        /#     an infinite loop.
        metafile, context = test.schemaParser(
          'Attribute config : complex = <empty> children<Attribute> #:\n'
          'end;\n'
        )
        attr = metax.meta.AttributeConstruct('type', None, context)
        attrinfo = context.consmap()['Attribute']
        metafile.set(lnum=0, index=17)
        typeattr, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 0)
        test.iseq('type', typeattr.key())
        test.iseq(27, metafile.index())
        defattr, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 0)
        test.iseq('default', defattr.key())
        test.iseq(37, metafile.index())
        chattr, _ = metafile.parseSecondaryAttribute(attr, attrinfo, 0)
        test.isnull(chattr)
        test.iseq(16, attr.termcode())
        test.iseq(
          [
            {'message': 'Unknown secondary token "children<Attribute>"', 'line': 0, 'kind': 'E', 'col': 37},
          ],
          metafile._logmap['order'])

        /# TODO(wmh): The collection of attribute types used by Meta(Meta)
        /# is quite sparse.  Parse the Meta(Oopl) schema and use it to
        /# perform a comprehensive testing of all attribute types (with both
        /# legal and illegal values).

      testx t2 scope:
        text = (
          'namespace nm.sp scope:\n'
          '  class Card scope:\n'
          '    method f params:\n'
          '      var a : int;\n'
          '    scope<cc>:\n'
          '      cout << "hello" << endl;\n'
          '    scope<py>:\n'
          '      print("hello")\n'
          '    end;\n'
          '  end;\n'
          'end;\n'
        )
        metafile = test.metafileFor(text=text, metal='oopl', debuglevel=0)
        /#metafile.show()
        metafile.set(index=87, lnum=4)
        context = metafile.context()
        construct = metax.oopl.MethodConstruct.NewFromData(
          'f', context, termcode=metax.c.TERM_UNINIT)
        metax.c.Debug = True

        /# Parse the scope<cc>:
        /#  - should NOT add a 'scope:' key, because cc isn't current baselang.
        attribute, error = metafile.parseSecondaryAttribute(
          construct, context.consinfo('method'), 4)
        test.isnull(error)
        test.iseqvec(
          ['method', 'scope:.cc'],
          sorted(construct._attributes))

        /# Parse the scope<py>:
        /#  - this SHOULD add a 'scope:' key because py is current baselang.
        attribute2, error2 = metafile.parseSecondaryAttribute(
          construct, context.consinfo('method'), 4)
        test.isnull(error)
        test.iseqvec(
          ['method', 'scope:', 'scope:.cc', 'scope:.py'],
          sorted(construct._attributes))
        test.issame(attribute2, construct.attr('scope:'))

    end method parseSecondaryAttribute;

    method parseEnd : tuple<int,int> #:
      Check if the current position is the start of a end-of-construct.

      Returns:
       0) termcode : int
         The termcode. Returns TERM_UNINIT if no terminator was found
       1) index : int
         The index within self.text() after the terminator and skipped spaces.
    params:
      var construct : Construct #:
        The construct being parsed.
      var index : int = -1 #:
        The current position within the current line.  Usually not specified,
        in which case self.index() is used.
    scope:
      self.validate(index=index)

      text = self._text
      if index < 0:
        index = self._index
      line = self.line()
      snippet = text[index:line.end()]
      m = MetaFile.TERM_RE.match(snippet)
      if m:
        termcode = 0x1  # semicolon definitely present.
        index += m.end(0)
        if m.group('end'):
          termcode |= 0x2
        kind = m.group('kind')
        if kind:
          termcode |= 0x4
          if kind != construct.kind():
            self.error(
              'Parsing %s but found terminator for %s' %
              (construct.kind(), kind))
        id = m.group('id')
        if id:
          termcode |= 0x8
          if id != construct.id():
            self.error(
              'Parsing %s %s but found terminator for %s %s' %
              (construct.kind(), construct.id(), kind, id))
      else:
        termcode = TERM_UNINIT
        index = line.start()
      return (termcode, index)
    test:
      text = 'MetaLanguage Test config:\nend MetaLanguage;\n'
      construct, context, metafile = test.newTestSchema(text)
      metafile.nextLine()
      test.iseq((7, 43), metafile.parseEnd(construct))
      construct.termcodeIs(7)
      test.iseq('end MetaLanguage;', construct.termstr())

      metafile, context = test.schemaParser(';\n')
      test.iseq((1, 1), metafile.parseEnd(construct))

      metafile, context = test.schemaParser('end;\n')
      test.iseq((3, 4), metafile.parseEnd(construct))

      metafile, context = test.schemaParser('end MetaLanguage;\n')
      test.iseq((7, 17), metafile.parseEnd(construct))

      metafile, context = test.schemaParser('end MetaLanguage Test;\n')
      test.iseq((15, 22), metafile.parseEnd(construct))
      test.iseq([], metafile.errors())

      metafile, context = test.schemaParser('end Construct;\n')
      test.iseq((7, 14), metafile.parseEnd(construct))
      test.iseq(
        [{'message': 'Parsing MetaLanguage but found terminator for Construct',
         'line': 0, 'kind': 'E', 'col': 0}],
        metafile.errors())

      metafile, context = test.schemaParser('end MetaLanguage Bork;\n')
      test.iseq((15, 22), metafile.parseEnd(construct))
      test.iseq(
        [{'message': 'Parsing MetaLanguage Test but found terminator for MetaLanguage Bork',
         'line': 0, 'kind': 'E', 'col': 0}],
        metafile.errors())
    end method parseEnd;

    method parseWord : tuple<str,int> #:
      Obtain next token and advance position beyond it.

      Returns:
       [0] word : str
         The parsed word
       [1] adj : int
         An integer which, when added to the current column, gives the
         column of the next non-space token within the current line.
       [2] index : int
         The absolute index of the next non-space token within self.text().
    params:
      var start : int;
    scope:
      /# peekWord never advances beyond the current line.
      result = self.peekWord(start)
      self._index = result[2]
      return result
    test:
      text = 'MetaLanguage Test config:\nend MetaLanguage;\n'
      metafile, context = test.schemaParser(text)
      test.iseq(('MetaLanguage', 13, 13), metafile.parseWord(0))
      test.iseq(13, metafile.column())
      test.iseq(('Test', 5, 18), metafile.parseWord(13))
      test.iseq(18, metafile.column())
      test.iseq(('config:', 7, 25), metafile.parseWord(18))
      test.iseq(25, metafile.column())
    end method parseWord;

    method peekWord : tuple<str,int,int> #:
      Obtain next word without advancing position.

      NOTE: This method does NOT skip initial whitespace and raises an exception
      if text[start] is a space or newline. It does however skip past whitespace
      after the word.

      Returns:
       [0] word : str
         The parsed word
       [1] adj : int
         An integer which, when added to the current column, gives the
         column of the next non-space token within the current line.
       [2] index : int
         The absolute index of the next non-space token within self.text().
    params:
      var start : int;
    scope:
      text = self._text
      term = self.context().token('term')
      c = text[start]
      assert c != ' ' and c != '\n', 'Here with c="%s" at index=%d' % (c, start)
      index = start
      /# Consume the word up to next space or newline
      while True:
        c = text[index]
        if c== ' ' or c == '\n' or c == term: break
        index += 1
      word = text[start:index]
      /# Skip trailing spaces (but not newlines!)
      while text[index] == ' ': index += 1
      return (word, index - start, index)
    test:
      text = 'MetaLanguage Test config:\nend MetaLanguage;\n'
      metafile, context = test.schemaParser(text)
      test.iseq(('MetaLanguage', 13, 13), metafile.peekWord(0))
      test.iseq(('Test', 5, 18), metafile.peekWord(13))
      test.iseq(('config:', 7, 25), metafile.peekWord(18))

      assert text[25] == '\n'
      test.raises(AssertionError, metafile.peekWord, 25)

      assert text[12] == ' '
      test.raises(AssertionError, metafile.peekWord, 12)
    end method peekWord;

    method peekFeatureOrPrimaryToken : tuple<str,str,int,any,int,int> #:
      Obtain next feature value, feature key or primary key token.

      Caller must ensure that the current character is not whitespace (this
      means not at a newline, and nowhere on an empty line) and this method
      should only be invoked in situations where a feature key, feature value or
      primary key is expected.

      Returns:
       [0] word : str
         The parsed token
       [1] form : str
         One of 'feature_value', 'feature_key', 'primary_key', or 'error'
       [2] index : int
         The absolute index of the next non-space token within self.text().
       [3] data : any
         A form-specific value (ConsInfo for primary_key, ...). If it has
         the value 'error', an error has arisen.
       [4] lnum : int
         The line number the token appears on (from 0)
       [5] col : int
         The column the token starts at (from 0)
    params:
      var start : int #:
        The index within text to start looking for a new token.
      var consgroup : ConsGroup #:
        The set of legal feature and primary tokens at the current position.
    scope:
      text = self._text
      index = start
      /# Pre: text[index] != ' ' and text[index] != '\n'

      /# Consume word
      langle = -1
      rangle = -1
      while True:
        c = text[index]
        /# TODO(wmh): Replace ';' with token('term')
        if c == ' ' or c == '\n' or c == ';': break
        elif c == '<':
          langle = index
        elif c == '>':
          rangle = index
        index += 1
      token = text[start:index]

      /# Extract out selector if present.
      if langle > -1 and rangle == index - 1:
        selector = text[langle+1:rangle]
        attrkv = text[start:langle]
      else:
        selector = None
        attrkv = token

      /# Skip whitespace
      while text[index] == ' ': index += 1

      /# Establish if the attrkv is a primary, feature or error.
      consinfo = consgroup._primaries.get(attrkv, None)
      if consinfo:
        form = 'primary_key'
        data = consinfo
      else:
        finfo = consgroup._features.get(attrkv, None)
        if finfo:
          /# 0='key' or 'value', 1=canfeatkey, 2=kinds
          form = 'feature_key' if finfo[0] == 'key' else 'feature_value'
          data = finfo
        else:
          form = 'error'
          data = None

      lnum = self._lnum
      line = self._lines[lnum]
      return (token, attrkv, selector, form, index, data, lnum, start - line.start())
    test:
      text = (
        'MetaLanguage Test config:\n'
        '  Construct Cons config:\n'
        '    kind secondary Attribute Attr : word;\n'
        '    kind<py> secondary Attribute Attr2 : word;\n'
        'end MetaLanguage;\n'
      )
      metafile, context = test.schemaParser(text)

      /# Parse the MetaLanguage primary token
      test.iseq(
        ('MetaLanguage', 'MetaLanguage', None, 'primary_key', 13, context.consmap()['MetaLanguage'], 0, 0),
        metafile.peekFeatureOrPrimaryToken(0, context.legalInfo(['MetaLanguage'])))

      /# Parse the Construct primary token
      metafile.lnumIs(1)
      test.iseq(
        ('Construct', 'Construct', None, 'primary_key', 38, context.consmap()['Construct'], 1, 2),
        metafile.peekFeatureOrPrimaryToken(28, context.legalInfo(['Construct'])))

      /# Parse the Attribute 'kind' feature key
      metafile.lnumIs(2)
      test.iseq(
        ('kind', 'kind', None, 'feature_key', 60, ('key', 'kind', ['Attribute']), 2, 4),
        metafile.peekFeatureOrPrimaryToken(55, context.legalInfo(['Attribute'])))

      /# Parse the Attribute 'kind<py>' feature key.
      metafile.lnumIs(3)
      test.iseq(
        ('kind<py>', 'kind', 'py', 'feature_key', 106, ('key', 'kind', ['Attribute']), 3, 4),
        metafile.peekFeatureOrPrimaryToken(97, context.legalInfo(['Attribute'])))

      /# Parse the Attribute 'secondary' feature value of feature 'kind'
      metafile.lnumIs(2)
      test.iseq(
        ('secondary', 'secondary', None, 'feature_value', 70, ('value', 'kind', ['Attribute']), 2, 9),
        metafile.peekFeatureOrPrimaryToken(60, context.legalInfo(['Attribute'])))

      /# Parse the Attribute primary token
      metafile.lnumIs(2)
      test.iseq(
        ('Attribute', 'Attribute', None, 'primary_key', 80, context.consmap()['Attribute'], 2, 19),
        metafile.peekFeatureOrPrimaryToken(70, context.legalInfo(['Attribute'])))

      /# Parse a feature/primary token when one does not exist.
      metafile.lnumIs(0)
      test.iseq(
        ('Test', 'Test', None, 'error', 18, None, 0, 13),
        metafile.peekFeatureOrPrimaryToken(13, context.legalInfo(['MetaLanguage'])))
    end method peekFeatureOrPrimaryToken;

    method peekSecondaryToken : tuple<str,str,str,map,int> #:
      Obtain a secondary key at given position (or explicit end-of-construct).

      Caller must ensure that the current character is not whitespace (this
      means not at a newline, and nowhere on an empty line) and this method
      should only be invoked in situations where a secondary key (or construct
      terminator) is expected.

      Returns:
       0) token : str
         The secondary token or null if no secondary
       1) cankey : str
         The canonical secondary token (or null)
       2) basel : str
         The baselang selector (null for no selector, '*' for Meta* else baselang suffix)
       3) info : map
         The information related to the secondary, or null if no secondary
       4) index : int
         The index after the token (and after spaces have been skipped).
         If termcode is not TERM_UNINIT, this is the index after the terminator
         (spaces skipped but not newlines).
       5) termcode : int
           TERM_UNINIT if a secondary token is identified, else an
           integer identifying an implicit (0) or explict (>0) termination.
    params:
      var construct : Construct #:
        The construct instance being parsed.
      var start : int #:
        The position at which the secondary key (explicit or implicit) starts.
      var context : Context #:
        The current context.
      var consinfo : ConsInfo #:
        The construct info being parsed.
    scope:
      text = self._text
      index = start
      term = context.token('term')
      secondaries = consinfo.secondaries()
      /# Pre: text[index] != ' ' and text[index] != '\n'
      cankey = None
      basel = None

      c = text[index]
      autokey = consinfo.autokeys().get(c, None)

      /#print('**** HERE with c="%s"' % c)

      if c == term:
        /# We have an explicit termination
        (token, info, termcode) = (None, None, 1)
        index += 1

      elif autokey:
        /# We have a value that is implicitly identifying the attribute key.
        /#  - setting litkey to the empty string is how we inform Meta that
        /#    the key was implicit.
        token = ''  # litkey being empty is special semantics to indicate implicitness
        info = secondaries.get(autokey, None)
        if info is None:
          self.error('Failed to find autokey "%s" for "%s"' % (autokey, c))
        cankey = info['cankey']
        /# Advance past the autokey char.
        index += 1
        termcode = TERM_UNINIT

      else:
        /# The next word is either a secondary token, a terminator token, or an
        /# error.
        left = -1
        right = -1
        while True:
          c = text[index]
          if c == ' ' or c == '\n' or c == term: break
          if c == '<' and left == -1:
            left = index
          elif c == '>':
            right = index
          index += 1
        token = text[start:index]

        /# There is a distinction between:
        /#   token:
        /#     the user-provided secondary key token,
        /#   basetoken:
        /#     the token without baselang selector (but including ':' suffix)
        /#   coretoken:
        /#     the token without baselang selector or ':' suffix.
        if left != -1 and right != -1 and right >= index-2:
          /# We have a selector. Note that the current implementation precludes
          /# using '<>' as an operator unless we add special-case code to detect
          /# that.
          basel = text[left+1:right]
          metalang = self.compiler().metalang()
          if metalang and metalang.isValidBase(basel):
            coretoken = text[start:left]
            basetoken = coretoken + (':' if token[-1] == ':' else '')
          else:
            /# This is not a valid selector, so we treat the whole word as
            /# the token.
            basetoken = token
            coretoken = token[:-1] if token[-1] == ':' else token
        else:
          basetoken = token
          coretoken = token[:-1] if token[-1] == ':' else token

        /# print('token=%s basetoken=%s coretoken=%s' % (token, basetoken, coretoken))

        termend = context.token('end')
        if token == termend + term:
          token, info, termcode = (None, None, 3)
        elif token == termend:
          token, info = (None, None)
          termcode, index = self.parseEnd(construct, index=start)
        else:
          /# The current token doesn't match any terminator ... it may or may
          /# not be a secondary.
          termcode = TERM_UNINIT
          info = secondaries.get(basetoken, None)
          if info:
            cankey = info['cankey']

      /#if basel and cankey:
      /#  if cankey[-1] == ':':
      /#    cankey = cankey[:-1] + '<' + basel + '>:'
      /#  else:
      /#    cankey += '<' + basel + '>'

      /# Skip whitespace
      while text[index] == ' ': index += 1

      result = (token, cankey, basel, info, index, termcode)
      return result
    test:
      Construct = metax.meta.Construct

      def Chk(expected, value):
        info = value[3]
        if info is not None:
          /# We need to remove the 'attribute' element so that we can compare
          /# against a literal dict ... this requires some hoops (we cannot
          /# just delete 'attribute' from the passed in value because the
          /# same object can be passed in on different calls, with 'attirbute'
          /# existing then not existing.
          test.isinst(info, dict)
          test.contains('attribute', value[3])
          test.contains('empty', value[3])
          infocopy = copy.copy(info)
          attr = infocopy.pop('attribute')
          empty = infocopy.pop('empty')
          value = (value[0], value[1], value[2], infocopy, value[4], value[5])
        test.iseq(expected, value)

      text = (
        'MetaLanguage Test config:\n'
        '  Construct Cons config:\n'
        '    kind secondary Attribute Attr : word;\n'
        '  end Construct Cons;\n'
        'end MetaLanguage;\n'
        'File a.meta scope:\n'
        'end;\n'
      )
      schema, context, metafile = test.newTestSchema(text)
      cons = metax.meta.ConstructConstruct('Cons', None, context)
      attr = metax.meta.AttributeConstruct('Attr', None, context)

      /# Parse the 'config:' attribute of 'MetaLanguage'
      Chk(
        ('config:', 'config:', None,
         {'valopt': False, 'cankey': 'config:', 'default': '<empty>',
          'keyopt': False, 'type': 'complex', 'autokey': None,
          'children': ['Construct', 'BaseLanguage']},
          25, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(
          schema, 18, context, context.consmap()['MetaLanguage']))

      /# Parse the 'type' attribute of 'Attribute' (litkey ':')
      Chk(
        (':', 'type', None,
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None
          },
         87, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(
          attr, 85, context, context.consmap()['Attribute']))

      /# Parse the ';' at the end of the Attribute.
      metafile.lnumIs(2)
      Chk(
        (None, None, None, None, 92, 1),
        metafile.peekSecondaryToken(
          attr, 91, context, context.consmap()['Attribute']))

      /# Parse the 'end Construct Cons;' at the end of the Construct.
      metafile.lnumIs(3)
      Chk(
        (None, None, None, None, 114, 15),
        metafile.peekSecondaryToken(
          cons, 95, context, context.consmap()['Construct']))

      /# Parse the 'end MetaLanguage;' at the end of the MetaLanguage.
      metafile.lnumIs(4)
      Chk(
        (None, None, None, None, 132, 7),
        metafile.peekSecondaryToken(
          schema, 115, context, context.consmap()['MetaLanguage']))

      /# TODO(wmh): Meta(Meta) does not have any autokey attributes, so we
      /# need Meta(Oopl) to properly test that aspect of peekSecondaryToken().
      /# However, we can fake things up by hacking autokeys.
      /#  - we indicate that if Meta sees '/' when expecting a secondary key,
      /#    it should interpret this as an implicit 'default' secondary
      /#    (which of course doesn't make sense to actually do ... just a test).
      attrinfo = context.consmap()['Attribute']
      attrinfo.autokeys()['/'] = 'default'
      metafile, context = test.schemaParser('Attribute Attr /blah;\n')
      attr = metax.meta.AttributeConstruct('Attr', None, context)
      Chk(
        ('', 'default', None,
         {'valopt': False, 'cankey': 'default', 'default': '<empty>', 'keyopt': False, 'type': 'word', 'autokey': None},
         16, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, 15, context, attrinfo))

      /###
      /# Now perform tests on selector parsing.
      text = (
        'type<meta> type<*> type\n'
        'comment<meta>: comment<*>: comment:\n'
        ':<meta> :<*> :\n'
        ':<meta>: :<*>: ::\n'
      )
      metafile, context = test.schemaParser(text)
      attr = metax.meta.AttributeConstruct('Attr', None, context)
      attrinfo = context.consmap()['Attribute']

      /# First line, variants on 'type' (non-block valued)
      metafile.lnumIs(0)
      Chk(
        ('type<meta>', 'type', 'meta',
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, 11, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, 0, context, attrinfo))
      Chk(
        ('type<*>', 'type', '*',
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, 19, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, 11, context, attrinfo))
      Chk(
        ('type', 'type', None,
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, 23, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, 19, context, attrinfo))

      /# Second line, variants on 'comment' (block-valued)
      metafile.set(lnum=1)
      index = 24
      test.iseq(index, metafile.index())
      Chk(
        ('comment<meta>:', 'comment:', 'meta',
         {'valopt': False, 'cankey': 'comment:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 15, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index, context, attrinfo))
      Chk(
        ('comment<*>:', 'comment:', '*',
         {'valopt': False, 'cankey': 'comment:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 27, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index + 15, context, attrinfo))
      Chk(
        ('comment:', 'comment:', None,
         {'valopt': False, 'cankey': 'comment:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 35, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index + 27, context, attrinfo))

      /# Third line, variants on ':' (alias for 'type')
      metafile.set(lnum=2)
      index = 60
      test.iseq(index, metafile.index())
      Chk(
        (':<meta>', 'type', 'meta',
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, index + 8, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index, context, attrinfo))
      Chk(
        (':<*>', 'type', '*',
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, index + 13, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index + 8, context, attrinfo))
      Chk(
        (':', 'type', None,
         {'valopt': False, 'cankey': 'type', 'default': '<empty>',
          'keyopt': False, 'type': 'word', 'autokey': None}, index + 14, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index + 13, context, attrinfo))

      /# Fourth line, variants on '::' (alias for 'scope')
      /#  - note that '::' isn't defined on 'Attribute', so it fails to
      /#    identify selector info.
      /#  - we switch to MetaLanguage, which defines 'scope:' and '::'.
      metafile.set(lnum=3)
      index = 75
      test.iseq(index, metafile.index())
      Chk(
        (':<meta>:', None, 'meta', None, index + 9, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(attr, index, context, attrinfo))
      schema = metax.meta.ConstructConstruct('MetaLanguage', None, context)
      schemainfo = context.consmap()['MetaLanguage']
      Chk(
        (':<meta>:', 'scope:', 'meta',
         {'valopt': False, 'cankey': 'scope:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 9, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(schema, index, context, schemainfo))
      Chk(
        (':<*>:', 'scope:', '*',
         {'valopt': False, 'cankey': 'scope:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 15, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(schema, index + 9, context, schemainfo))
      Chk(
        ('::', 'scope:', None,
         {'valopt': False, 'cankey': 'scope:', 'default': '<empty>',
          'keyopt': False, 'type': 'simple', 'autokey': None}, index + 17, metax.c.TERM_UNINIT),
        metafile.peekSecondaryToken(schema, index + 15, context, schemainfo))

    end method peekSecondaryToken;

    method nextLine : tuple<Line,int,bool> #:
      Advance to next line.

      Returns:
        [0] line: Line
          The next Line (or null if EOF has been reached).
        [1] index: int
          The new index within self.text(). Callers should update their
          locally cached concept of index within text based on this. This
          will be -1 if EOF has been reached.
        [2] matches: bool
          A boolean indicator of whether the new line indent matches
          expectations. Always true if the 'indent' param is negative.
    params:
      var indent : int = -1 #:
        If zero or greater, it is a request to confirm that the indent of
        the returned line exactly matches the indent specified.
    scope:
      self._lnum += 1
      line = self.line()
      index = (line._start + line._indent) if line else -1
      if False and line is None:
        print(
          'Line %5d: %s in %s (%d)' %
          (self._lnum - 1, self._lines[self._lnum-1].line(), self.path(), index))
        /# raise Error('Found line null')
      self._index = index
      matches = True
      if indent > -1 and indent != line._indent:
        matches = False
        /# We used to log here, but it is probably best to let the caller
        /# decide how to report this.
        /#self.error('Expected token indented %d spaces' % indent)
      return line, index, matches
    test:
      mf, _ = test.schemaParser(
        'MetaLanguage Test config:\n  Construct A config:\n  end;\nend;\n')
      lines = mf.lines()
      test.iseq(0, mf.lnum())

      test.iseq((lines[1], 28, True), mf.nextLine())
      test.iseq(1, mf.lnum())
      test.iseq(2, mf.column())

      test.iseq((lines[2], 50, True), mf.nextLine(indent=2))
      test.iseq(2, mf.lnum())
      test.iseq(2, mf.column())
      test.iseq([], mf.errors())

      test.iseq((lines[3], 55, False), mf.nextLine(indent=2))
      test.iseq(3, mf.lnum())
      test.iseq(0, mf.column())
    end method nextLine;

    method skipEmptyLines : tuple<Line,int,bool,int> #:
      Advance forward past empty lines.

      SideEffects:
        - sets self.col() to first non-space on resulting non-empty line.
        - updates self.lnum()

      Returns:
        [0] line: Line
          The next Line (or null if EOF has been reached).
        [1] index: int
          The new index within self.text(). Callers should update their
          locally cached concept of index within text based on this. This
          will be -1 if EOF has been reached.
        [2] matches: bool
          A boolean indicator of whether the new line indent matches
          expectations. Always true if the 'indent' param is negative.
        [3] precount: int
          The number of empty lines skipped.
    params:
      var indent : int = -1 #:
        If zero or greater, it is a request to confirm that the indent of
        the returned line exactly matches the indent specified.
    scope:
      skipped = 0
      matches = True
      lines = self._lines
      lnum = self._lnum
      n = len(lines)
      while lnum < n and lines[lnum].empty():
        lnum += 1
        skipped += 1
      if lnum < n:
        line = lines[lnum]
        index = line.start() + line.indent()
        if indent > -1 and indent != line.indent():
          matches = False
          /# Used to log here, but probably best to let caller decide how to
          /# report this.
          /# self.error(
          /#  'Expecting token indented %d spaces' % indent, line=self.lnum())
      else:
        line = None
        index = n
      self.set(index=index, lnum=lnum)
      return (line, index, matches, skipped)
    test:
      metafile, _ = test.schemaParser('MetaLanguage Test config:\nend;\n')
      test.iseq((metafile.lines()[0], 0, True, 0), metafile.skipEmptyLines())
      test.iseq(0, metafile.column())
      metafile, _ = test.schemaParser('\n    \nMetaLanguage Test config:\nend;\n')
      test.iseq((metafile.lines()[2], 6, True, 2), metafile.skipEmptyLines())
      test.iseq(0, metafile.column())
      metafile, _ = test.schemaParser( '\n    \n    class Person scope:\n')
      test.iseq((metafile.lines()[2], 10, True, 2), metafile.skipEmptyLines())
      test.iseq(4, metafile.column())
    end method skipEmptyLines;

    method skipToIndent : Line #:
      Advance to the nearest line whose indent is less-equal given indent.
    params:
      var indent : int;
    scope:
      lnum = self.lnum()
      start = lnum
      lines = self.lines()
      n = len(lines)
      while lnum < n and lines[lnum].indent() > indent:
        lnum += 1
      self.lnumIs(lnum)
      result = lines[lnum] if lnum < n else None
      /# self.info('Skipped %d lines' % (lnum - start), line=start)
      return result
    test:
      metafile, _ = test.schemaParser(
        '  a = 1;\n  b = 2;\nMetaLanguage Test config:\nend;\n')
      line = metafile.skipToIndent(0)
      test.iseq('   3: 0:MetaLanguage Test config:', line.asStr())
      test.iseq(2, metafile.lnum())
    end method skipToIndent;

    method validate : bool #:
      Ensure this MetaFile's invariants are true.
    params:
      var index = -1 #:
        The indent to validate (if negative, self.index() is used).
    scope:
      if index < 0:
        index = self.index()
      line = self.line()
      if line.start() > index:
        raise Error(
          'line %d starting %d is > %d current' % (self.lnum(), line.start(), index))
      elif line.end() < index:
        raise Error(
          'line %d ending %d is < %d current' % (self.lnum(), line.end(), index))
      return True
    test:
      /# This is effectively a test method. No test for test methods.
      pass
    end method validate;

    method registerFile #:
      Register a BaseFile.
    params:
      var basefile : BaseFile #:
        The basefile to register.
    scope:
      fs = self.compiler().fs()
      /# Filesystem.addFile() returns null if we are not in disk mode,
      /# otherwise [basepath] or [basepath, mappath]
      paths = fs.addFile(basefile)
      if paths:
        for path in paths:
          self.files().add(path)
        self.basefiles().add(basefile)
    test:
      metafile = test.metafile
      basefile = metax.fs.BaseFile('tmp/fauxfile', 'some contents\n')
      metafile.registerFile(basefile)
    end method registerFile;

    method writeFiles #:
      Write the files this metafile writes to to a stream.
    params:
      var fp : ostream = out #:
        The stream to write to.
    scope:
      fp.write(u'%s\n' % self.path())
      for path in sorted(self.files()):
        assert path == fs.realpath(path)
        fp.write(path.decode('utf8') + '\n')
    test:
      metafile = test.metafile
      metafile.writeFiles(fp=test.fp())
      test.iseq('fauxpath\n', test.out())
    end method writeFiles;

    method readFiles : set<str> #:
      Read files previously written with 'writeFiles'.
    params:
      var ifp : istream #:
        The stream to read from.
    scope:
      result = set()
      srcfilename = ifp.readline().strip()
      if srcfilename != self.path():
        /# This may be ok, but for now raising exception to explore when this
        /# happens.
        raise Error('Found "%s" vs "%s"' % (srcfilename, self.path()))
      for line in ifp:
        result.add(line.strip())
      return result
    test:
      metafile = test.metafile
      ifp = test.fp(u'fauxpath\n/some/path/file1\n/some/other/path/file2\n')
      res = metafile.readFiles(ifp)
      test.iseq(set([u'/some/other/path/file2', u'/some/path/file1']), res)
    end method readFiles;

    method cleanupFiles #:
      Remove any files created last time that were not created this time.
    scope:
      metac = self.compiler()
      fs = metac.fs()
      flags = metac.cli()
      metadir = flags.metadir
      if metadir != metax.c.SPECIAL_CHILD_DIR:
        self.warning(
          'Not performing file caching/cleanup for metadir %s' % metadir)
        return

      /# Establish the file containing last times set of files.
      baselang = metac.baselang()
      path = self.path()
      pdir, filename = fs.split(path)
      basename, suffix = fs.splitext(filename)
      logfile = fs.join(pdir, '.%s.%s.files' % (
        basename, baselang.suffix() if baselang else ''))
      self.files().add(logfile)

      /# Obtain files written last time and this time.
      with open(logfile, 'r') as fp:
        old_files = self.readFiles(fp)
      new_files = self.files()
      del_files = old_files - new_files

      debug = False
      if debug:
        for path in sorted(old_files.union(new_files)):
          nc = 'Y' if path in new_files else ' '
          oc = 'Y' if path in old_files else ' '
          print('%s %s %s' % (nc, oc, path))
        print('Found %d old files and %d new files and %d obselete files' % (
          len(old_files), len(new_files), len(del_files)))

      /# Write the new set of files to disk for next time.
      with open(logfile, 'w') as fp:
        self.writeFiles(fp)

      /# Delete any obsolete files
      for path in del_files:
        if fs.exists(path):
          print('CLEANUP: Removed obsolete %s' % path)
          fs.unlink(path)
    test:
      return

      /# TODO(wmh): Cleanup.
      print('Fix MetaFile.cleanupFiles() test')
      /# test.metafile.cleanupFiles()
    end method cleanupFiles;

    method computeFileStats : map #:
      Compute stats on the basefiles generated for this Metafile.

      Returns:
        Lines: int
          Number of lines in this meta file
        Bytes: int
          Number of bytes in this meta file
        files: int
          Number of files generated
        lines: int
          Number of lines across all files
        reallines: int
          Number of non-trivial lines across all files. Note that comments
          are NOT considered trivial and thus contribute to this value.
        bytes: int
    params:
      var hidden : bool = false #:
        If true, include hidden files.
    scope:
      fs = self.compiler().fs()
      basefiles = self.basefiles()
      numlines = 0
      reallines = 0
      numbytes = 0

      counted = []

      for basefile in basefiles:
        subpath = basefile.subpath()
        basename = fs.basename(subpath)
        if not hidden and basename[0] == '.': continue
        counted.append(basefile)

        contents = basefile.contents()
        if contents:
          numbytes += len(contents)
          lines = contents.split('\n')
          assert contents and contents[-1] == '\n'
          lines.pop()
          numlines += len(lines)
          /# TODO(wmh): Should the lines in the map file associated with basefile
          /# be added? For now we do not.

          /# TODO(wmh): Implement baselang-specific function for following.
          /#  - trivial lines include
          /#     - blank lines
          /#     - lines consisting solely of construct terminators (non-existent in python)
          /#  - trivial lines do NOT include
          /#     - comments
          baselang = self.compiler().baselang()
          fluffre = re.compile(r'^\s*$')
          for line in lines:
            m = fluffre.match(line)
            if not m:
              reallines += 1

      /# TODO(wmh): Remove this!
      /#  - temporary artificial inflation to account for missing autogen
      /#    methods per class.
      numlines = int(numlines * 1.1)
      numbytes = int(numbytes * 1.1)

      numLines = len(self.lines())
      numBytes = len(self.text())
      n = len(counted)
      result = {
        'Files': 1,
        'files': n,
        '%files': n,
        'Lines': numLines,
        'lines': numlines,
        '%lines': float(numlines) / numLines,
        'reallines': reallines,
        'Bytes': numBytes,
        'bytes': numbytes,
        '%bytes': float(numbytes) / numBytes,
      }
      return result
    test:
      res = test.metafile.computeFileStats()
      test.iseqmap(
        {
          'Files': 1, 'files': 0, '%files': 0, 'Bytes': 44, '%bytes': 0.0,
          '%lines': 0.0, 'lines': 0, 'bytes': 0, 'Lines': 2, 'reallines': 0,
        },
        res)
    end method computeFileStats;

    method parseMeta : metax.meta.FileConstruct #:
      Parse the entire contents of this MetaFile instance into a FileConstruct,
      initializing self.construct().
    params:
      var parent_context : Context #:
        The context within which the metafile is to be parsed. The context
        identifies which constructs are legal in the scope.
      var is_schema : bool = false #:
        True if we are parsing a schema file.
    scope:
      /# IMPORTANT: We make a copy of 'context' even though there are no
      /# 'config' changes relative to the passed in 'context'. We do this so
      /# that we can safely set context.metafile() to self without tromping
      /# a previous value.
      self.stateIs('parsing')
      start = time.time()
      context = parent_context.subclone(metafile=self)

      /# We initialized the compiler instance of Context.
      context.compilerIs(self.compiler())

      /# TODO(wmh): The parent of the FileConstruct should be the scope: of
      /# the MetaLanguage of the Metalanguage within which the metafile is defined.
      parent = None

      fs = self.compiler().fs()
      /# print('***** PARSING %s' % fs.realpath(self.path()))

      file_construct = metax.meta.FileConstruct(self.path(), parent, context)
      primary = metax.attr.IdAttribute(file_construct, 'File', self.path(), line=0, col=0)
      scope = metax.attr.ComplexBlock(file_construct, 'scope:', [], line=0, col=0)
      file_construct.registerAttribute(primary)
      file_construct.registerAttribute(scope)
      self.contextIs(context)
      metalang = self.compiler().metalang()
      if metalang is None:
        if is_schema:
          /# TODO(wmh): This is a hack to allow the Compiler initializer to
          /# create MetaLanguageConstruct instances by parsing schema files.
          /# The initializer invokes metalangNamed() which invokes parseMeta()
          /# which invokes this method which needs the compiler().metalang()
          /# before one exists (e.g. while the initializer is unfinished).
          /# Find a better way to handle this bootstrapping issue!
          legals = ['MetaLanguage', 'File']
        else:
          raise Error('Attempt to parse MetaFile without metalang')
      else:
        legals = metalang.toplevelConstructKinds()

      self.debug('Metafile %s' % self.path(), line=0, col=0)
      self.parseComplexBlock(scope, 0, legals=legals)
      self.constructIs(file_construct)

      self.stats()['parse'] = time.time() - start
      self.stateIs('parsed')
      self.phases().append('parse')

      return file_construct
    test:
      file = test.metafile.parseMeta(test.context)
      fp = test.fp()
      file.write(fp=fp)
      out = fp.getvalue()
      test.iseqtext(
        'File fauxpath scope:\n'
        '  MetaLanguage Test config:\n'
        '  end MetaLanguage;\n',
        out)
    end method parseMeta;

    method expandMeta #:
      Expand all top-level constructs in this file.
    scope:
      D.expand.sinfo(self.path())

      self.stateIs('expanding')
      start = time.time()
      self.construct().expandMeta()
      self.stats()['expand'] = time.time() - start
      self.stateIs('expanded')
      self.phases().append('expand')

      D.expand.end()
    test:
      /# TODO(wmh): Verify this does something.
      test.metafile.parseMeta(test.context)
      test.metafile.expandMeta()
    end method expandMeta;

    method importMeta #:
      Import additional .meta files identified during expandMeta.
    scope:
      D.imports.sinfo(self.path())
      
      imports = self.compiler().importlist()
      imports.append(self)
      self.stateIs('importing')
      start = time.time()
      self.construct().importMeta()
      self.stats()['import'] = time.time() - start
      self.stateIs('imported')
      self.phases().append('import')
      imports.pop()

      D.imports.end()
    test:
      /# TODO(wmh): Verify this does something.
      test.metafile.parseMeta(test.context)
      test.metafile.expandMeta()
      test.metafile.importMeta()
    end method importMeta;

    method translateMeta scope:
      D.translate.sinfo(self.path())

      self.stateIs('translating')
      start = time.time()
      self.construct().translateMeta()
      self.stats()['translate'] = time.time() - start
      self.stateIs('translated')
      self.phases().append('translate')

      D.translate.end()
    test:
      /# TODO(wmh): Verify this does something.
      test.metafile.parseMeta(test.context)
      test.metafile.expandMeta()
      test.metafile.translateMeta()
    end method translateMeta;

    method compileMeta scope:
      D.compile.sinfo(self.path())

      self.stateIs('compiling')
      start = time.time()
      self.construct().compileMeta()
      self.stats()['compile'] = time.time() - start
      self.stateIs('compiled')
      self.phases().append('compile')

      D.compile.end()
    test:
      /# TODO(wmh): Verify this does something.
      test.metafile.parseMeta(test.context)
      test.metafile.expandMeta()
      test.metafile.translateMeta()
      test.metafile.compileMeta()
    end method compileMeta;

  end class MetaFile;

  class Compiler #:
    Maintains information about a collection of metafiles and provides
    functionality for parsing, expanding, compiling, analyzing, canonicalizing,
    (etc) those meta files.

    Each Compiler instance is specific to a particular Meta Language. A
    specific BaseLanguage is active at any given time, but can be switched
    during the lifetime of the Compiler instance.
  assocs:
    std usertest assoc collections;
    std assoc copy;
    std assoc io;
    std assoc datetime;
    std assoc difflib;
    std assoc json;
    std assoc importlib;
    std usertest assoc metastrap #:
      TODO(wmh): Establish how to specify a bazel target for metastrap.
    std assoc logging;
    std assoc platform;
    std assoc pprint;
    std assoc re;
    std assoc shlex;
    std assoc sre_constants;
    std assoc subprocess;
    std assoc sys;
    std assoc time;
    std assoc traceback;

    cls assoc metax.c.shell.Shell;
    cls assoc metax.fs.Filesystem;
    cls assoc metax.cli.Command;
    cls assoc metax.cli.Values;

    resource emacs_template path "../templates/meta-mode-template.el";
    resource oopl_tgz path "../templates/oopl.tgz";
    resource test_repo path "./testdata/repo";
  scope:

    meta
    field CLI : metax.cli.Values #:
      The command-line flags and args (and command)

    meta
    field Current : Compiler #:
      Initialized in the MetaxEntry meta-method to the instance created
      there-in.

    meta
    method Initialize #:
      This method must be invoked before anything else in order to initialize
      class-level state based on command-line flags.
    params:
      var metadata : map = null #:
        Maps metalang id to metalang info.
        TODO(wmh): This arg will be changed/removed when we more fully move
        to defining all metalang info in the associated schema.
    scope:
      if metadata:
        /# No longer needed, as we can obtain all data from the schema.meta file
        /# now.
        print('************* NOTE: Passing deprecated METADATA into Compiler!')
        import pprint
        pprint.pprint(metadata)
        /# cls.METADATA.update(metadata)
      config = metax.root.MetaObject.Config()
      cls.CONFIG = config
      errors = []

      /# TODO(wmh): Get this working via Filesystem!
      import os
      if 'bazel' not in config:
        errors.append("Must specify 'bazel' (path to bazel executable)")
      elif not os.path.exists(config['bazel']):
        errors.append('Invalid bazel %s (does not exist)' % config['bazel'])
      if 'src_root' not in config:
        errors.append('Must specify src_root (where Meta is installed)')
      elif not os.path.exists(config['src_root']):
        errors.append(
          'Invalid src_root %s (does not exist)' % config['src_root'])
      if not os.path.exists(config['repository_path']):
        errors.append(
          'Invalid repository_path %s (does not exist)' %
          config['repository_path'])
      if errors:
        for error in errors:
          print('ERROR: %s' % error)
        print('Please edit %s and fix the above errors' % config['config_path'])
        sys.exit(1)
    end;

    meta
    method Bootstrap : tuple<metax.cli.Command,metax.cli.Command,metax.cli.Values> #:
      Perform all actions necessary to initialize Compiler and Object class
      state, and obtain the commands/flags/args resulting from parsing a
      specific metac command line.

      This is useful to invoke in the setup: blocks of of testcase classes
      that require interaction with metac.
    params:
      var argv : vec<str> #:
        The command line (argv[0] is the metac executable, argv[1:] are args to
        the metac binary).
    scope:
      /# Parse the commandline.
      root_command, command, cli = cls.MetaxCLI(argv)

      /# This ensures that CLI and cli() will work properly
      metax.root.Object.Init(cli=cli)

      /# This ensures Compiler.CONFIG is defined.
      cls.Initialize()

      /# Verify invariants
      assert command.root() is root_command

      /# The instantiated command. Clients can obtain root command by calling
      /# command.root()
      return root_command, command, cli
    test:
    end method Bootstrap;

    field metalangs : @map<str,metax.meta.MetaLanguageConstruct> #:
      Maps ids/names of metalanguages to MetaLanguage instances.

    field metalang : metax.meta.MetaLanguageConstruct #:
      The meta language that source files are written in. Determines which
      schema file to load, and thus the set of legal constructs.

    field baselang : BaseLanguage #:
      The base language to compile to. For some operations, this is not
      needed, while for others it is.

    field metafiles : @map<str,MetaFile> #:
      Maps both relative and absolute paths to MetaFile instances.

    field metaorder : @vec<MetaFile> #:
      The MetaFile instances in the order they were parsed.

    field classes : @map<metax.oopl.ClassConstruct> #:
      Maps fqcn to ClassConstruct, for every class that has had expandMeta
      invoked on it across all MetaFiles in this compiler.
      TODO(wmh): Determine if we should register classes earlier than
      expandMeta.

    field argmap : map #:
      A grouping of args into categories.

    field levels : map #:
      Maps the various compilation dimensions to values
        'off', 'low', 'avg', 'high', 'max'.

    field filesystem : metax.fs.Filesystem #:
      The I/O abstraction object.  All I/O should go thru it.

    field repodir : str #:
      The directory containing the repository.

    field shelldata : map #:
      A collection of key/value pairs used in the implementation of shell-like
      features.  Keys include:
        cwd: str
          A conceptual current working directory, with '/' representing top
          of repo, '/nm' representing a particular top-level namespace,
          '/nm/sp' representing a second-level namespace, etc. Commands like
          'ls' and 'show' provide information across baselangs based on this
          value.

    field metadata : @map #:
      Maps (lower) metalang ids to maps providing information about the
      metalang.
      TODO(wmh): This field can be removed now that MetaLanguageConstruct
      and BaseLanguageConstruct exist ... everything about a metalang is
      specifiable in its schema file (although we need to figure out how
      to map constructs to class in the transitory period during which they
      are defined separately ... at some point we'll be able to put the
      definitions directly into the 'scope:' attribute of the constructs in
      the schema file (allowing users to extend the language by modifying
      the schema) but that is a ways away.

    field importlist : @vec<MetaFile> #:
      The list of MetaFile instances currently being imported. If the
      compiler is not currently performing an importMeta() invocation, this
      will be empty (and is thus a way of determining whether we are in
      importation code or not).

    field argdata : @map #:
      Maps strings (merged arg lists) to maps as returned from _parseArgs.
      An optimization to avoid invoking _parseArgs() multiple times.

    lifecycle params:
      var metal : str = 'oopl';
      var basel : str = null;
      var rootdir : str = null #:
        The directory that metadir is relative to. Normally null, in which
        case the current dir is used. This works if current dir contains
        the meta files being parsed. An explicit value can be passed in,
        for example, unit tests.
      var metadir : str = null #:
        The path, relative to rootdir, within which the meta repository resides.
        If this matches metax.c.SPECIAL_CHILD_DIR, it is treated specially in
        various places in the codebase.
      var kind : str = null #:
        The kind of filesystem to use. One of the legal values of the
        metax.c.Filesystem.kind field ('disk', 'memory', 'emulate'). If null,
        established based on value of --inmemory.
      var repodir : str = null #:
        The directory containing the repository. If null, obtained from the
        global config.
      var resources : map = null #:
        Explicit resources (maps fully qualified resource names to explicit
        paths). Used to override the default resource resolution strategy
        of Object.Resource().
      var metalangs : map = null #:
        If present, what the metalangs field should be initialized to. Useful
        when multiple Compiler instances are desired but we do not want to
        parse the metalang schema files each time (e.g. during testing).
    scope:
      if metalangs is not None:
        self.metalangsIs(metalangs)

      cls = self.__class__
      flags = metax.root.MetaObject.CLI()
      if flags:
        optimize_level = flags.optimize_level
        if metadir is None:
          metadir = flags.metadir
        inmemory = flags.inmemory
      else:
        optimize_level = 'high'
        if metadir is None:
          metadir = '.meta'
        inmemory = False

      if resources:
        metax.root.Object.Init(resources=resources)

      levels = {
        'warn': 'max',
        'debug': 'max',
        'optimize': optimize_level if flags else 'off',
        'profile': 'off',
        'inline': 'off',
      }
      self.metalangIs(None)

      /# Save the repodir
      /#  - the repositoryPath() method checks if this is null and if so,
      /#    obtains a value based on METAREP.
      /#  - lazy evaluation done because unittests that rely on it need to
      /#    invoke test.fixenv() first ... most tests do not rely on it, so
      /#    we don't force them all to fixenv.
      self.repodirIs(repodir)

      /# Create the filesystem.
      /#  - TODO(wmh): Add some kind of flag support for turning on 'emulate'.
      /#  - Do we want to replace --inmemory with --iokind?
      if metadir is None:
        metadir = metadir
        if metadir == '.meta':
          metadir = '.meta'
      if kind is None:
        kind = 'memory' if inmemory else 'disk'
      if kind == 'memory':
        logging.warning('Meta compiler is inmemory (no changes will be saved to disk)')
      fs = metax.fs.Filesystem(kind=kind, metadir=metadir, rootdir=rootdir)
      self.filesystemIs(fs)

      /# Every compiler needs access to the Meta(Meta) language, so we load it
      /# up first.
      metameta = self.metalangNamed('meta')

      /# Now create the Meta(L) language that this compiler is parsing source
      /# files for (inherits, directly or indirectly, from metameta).
      metalang = self.metalangNamed(metal)
      if not metalang:
        raise metax.root.Error('Unknown MetaLanguage %s' % metal)

      self.metalangIs(metalang)
      self.levelsIs(levels)

      /# The baselang doesn't need to be set upon creation, but will be
      /# needed for actions involving expansion and compilation.
      /#  - if the metalang in question doesn't have baselangs, the basel
      /#    is completely ignored (e.g. Meta(Meta)).
      if basel and metalang.baselangs():
        baselang = metalang.baselangNamed(basel)
        if not baselang:
          raise metax.root.Error(
            'Unknown BaseLanguage %s for %s' % (basel, metal))
        self.baselangIs(baselang)
      else:
        self.baselangIs(None)

      /# Initialize the shelldata.
      self.shelldataIs({
        'cwd': '/',
      })
    clinit:
      /# TODO(wmh): Provide a better way to specify this information.
      /# For example, add a 'metac _langmap' command (where the underscore means
      /# it is an implementation detail and not part of the public metac action
      /# set) that loads up all metalangs and all baselangs and creates this
      /# mapping (writing to some file that gets included here).
      cls.SUFFIX_HACK = {
        'oopl': {
          'py': 'python',
          'python': 'python',
          'cpp': 'cpp',
          'cc': 'cpp',
          'h': 'cpp',
          'javascript': 'javascript',
          'js': 'javascript',
          'java': 'java',
          'jv': 'java',
        }
      }
      cls.MAP_RE = re.compile(
        r'^\s*(?P<baseline>-?\d+)\s+(?P<metaline>-?\d+)\s+(?P<fullid>\S+)')
      cls.BAZEL_STDOUT_RE = re.compile(
        r'(?P<preamble>.*)'
        r'==================== Test output for (?P<target>\S+):\n'
        r'(?P<stderr>.*'
        r'\nRan (?P<tests>\d+) tests? in (?P<time>\S+)\n\n'
        r'(?P<status>\S+) *(?P<extra>\S*)\n'
        r')'
        r'(?P<stdout>.*)'
        r'\n={80}\n'
        r'(?P<rest>.*)'
        ,
        flags=re.DOTALL)
        
      /# Matches a file in a namespace repository directory. Used by
      /# parseRepositoryNamespace.
      cls.NamespaceFileRE = re.compile(
        r'^(?P<dot>[.]?)(?P<name>[^.]+)(?:\.(?P<suffix>\S+))$')

      cls.HTML_HEAD = (
        >|"""    <style>
        >|    .metafile {
        >|        font-size: %(fontsize)s;
        >|        margin: 0px 0px 0px %(margin)dpx;
        >|        padding: 0px;
        >|        width: %(width)dch;
        >|        background-color: black;
        >|        color: #c5c8c6;
        >|        /* http://crafted-software.blogspot.com/2010/07/css-for-tag-list-of-best-monospaced.html */
        >|        font-family: /* Pragmata,*/ Menlo, 'DejaVu LGC Sans Mono', 'DejaVu Sans Mono', Consolas, 'Everson Mono', 'Lucida Console', 'Andale Mono', 'Nimbus Mono L', 'Liberation Mono', FreeMono, 'Osaka Monospaced', Courier, 'New Courier', monospace;
        >|        border: 1px solid blue;
        >|        float: left;
        >|    }
        >|    .metadex {
        >|        background-color: #c5c8c6;
        >|        color: black;
        >|        position: fixed;
        >|        top: 9px;
        >|        left: 0px;
        >|    }
        >|    .baselangbox {
        >|        padding: 0px;
        >|        margin: 0px;
        >|        font-size: %(fontsize)s;
        >|        width: %(width)dch;
        >|    }
        >|    .baselangcode {
        >|        margin: -10px 0px 0px 12px;
        >|    }
        >|    // For the 'S', 'H' and 'T' letters associated with 'all' in metadex.
        >|    .ctrl1 {
        >|       color: red;
        >|    }
        >|    // For the 'S', 'H' and 'T' letters NOT associated with 'all' in metadex.
        >|    .ctrl2 {
        >|    }
        >|    code {
        >|      font-family: /* Pragmata,*/ Menlo, 'DejaVu LGC Sans Mono', 'DejaVu Sans Mono', Consolas, 'Everson Mono', 'Lucida Console', 'Andale Mono', 'Nimbus Mono L', 'Liberation Mono', FreeMono, 'Osaka Monospaced', Courier, 'New Courier', monospace;
        >|      white-space: pre;
        >|    }
        >|    /* https://developer.mozilla.org/en-US/docs/Web/CSS/color_value */
        >|    /* /usr/X11/share/X11/rgb.txt */
        >|    .face-primary   { color: %(primary)s; }
        >|    .face-primary2  { color: %(primary2)s; }
        >|    .face-feature   { color: %(feature)s; }
        >|    .face-secondary { color: %(secondary)s; }
        >|    .face-featval   { color: %(featval)s; }
        >|    .face-keyword   { color: %(keyword)s; }
        >|    .face-end       { color: %(end)s; }
        >|    .face-name      { color: %(name)s; }
        >|    .face-comment   { color: %(comment)s; }
        >|    .ellipsis       { color: %(ellipsis)s; }
        >|    .ellipsis2      { color: %(ellipsis2)s; }
        >|
        >|    /**
        >|     * Each line of code in a .meta program is specified by:
        >|     *   <div>
        >|     *     <span class="linenum">LINENUM</span>
        >|     *     <span class="indentNUM"></span>
        >|     *     <span class="linetext">SOURCE LINE</span>
        >|     *   </div>
        >|     *
        >|     * Notes:
        >|     *  - the linenum span is a fixed width and subdued coloring
        >|     *  - the indentNUM span is used to provide indentation.
        >|     *  - the linetext span contains the meta source line (appropriately marked up).
        >|     *
        >|     * TODO(wmh):
        >|     *  - Establish why we need to move the linetext span one char to the left
        >|     *  - Establish why there is a 1ch spacing between the linenum span and
        >|     *    the indentNUM spans ... it isn't due to margin or padding in either
        >|     *    of the two spans, as far as I can tell. It is actually working in our
        >|     *    favor, but I'd like to understand where it is coming from.
        >|     */
        >|    .linenum  {
        >|        display: inline-block;
        >|        width: 4ex;
        >|        text-align: right;
        >|        margin: 0px;
        >|        color: rgb(179, 179, 171);
        >|        /* border: 1px solid red; */
        >|    }
        >|    .indent0 { display: inline-block; width:  0ch; /* border: 1px solid green; */ }
        >|    .indent1 { display: inline-block; width:  2ch; /* border: 1px solid green; */ }
        >|    .indent2 { display: inline-block; width:  4ch; /* border: 1px solid green; */ }
        >|    .indent3 { display: inline-block; width:  6ch; /* border: 1px solid green; */ }
        >|    .indent4 { display: inline-block; width:  8ch; /* border: 1px solid green; */ }
        >|    .indent5 { display: inline-block; width: 10ch; /* border: 1px solid green; */ }
        >|    .indent6 { display: inline-block; width: 12ch; /* border: 1px solid green; */ }
        >|    .indent7 { display: inline-block; width: 14ch; /* border: 1px solid green; */ }
        >|    .indent8 { display: inline-block; width: 16ch; /* border: 1px solid green; */ }
        >|    .indent9 { display: inline-block; width: 18ch; /* border: 1px solid green; */ }
        >|    .linetext {
        >|        /* border: 1px solid purple; */
        >|        margin: 0em -1ch;
        >|    }
        >|
        >|    /*background color*/
        >|    .hljs {
        >|      display: block;
        >|      overflow-x: auto;
        >|      padding: 0em;
        >|      background: black;
        >|    }
        >|
        >|    /*selection color*/
        >|    .hljs::selection,
        >|    .hljs span::selection {
        >|      background: #373b41;
        >|    }
        >|
        >|    .hljs::-moz-selection,
        >|    .hljs span::-moz-selection {
        >|      background: #373b41;
        >|    }
        >|
        >|    /*foreground color*/
        >|    .hljs {
        >|      color: #c5c8c6;
        >|    }
        >|
        >|    /*color: fg_yellow*/
        >|    .hljs-title,
        >|    .hljs-name {
        >|      color: #f0c674;
        >|    }
        >|
        >|    /*color: fg_comment*/
        >|    .hljs-comment,
        >|    .hljs-meta,
        >|    .hljs-meta .hljs-keyword {
        >|      color: #707880;
        >|    }
        >|
        >|    /*color: fg_red*/
        >|    .hljs-number,
        >|    .hljs-symbol,
        >|    .hljs-literal,
        >|    .hljs-deletion,
        >|    .hljs-link {
        >|     color: #cc6666
        >|    }
        >|
        >|    /*color: fg_green*/
        >|    .hljs-string,
        >|    .hljs-doctag,
        >|    .hljs-addition,
        >|    .hljs-regexp,
        >|    .hljs-selector-attr,
        >|    .hljs-selector-pseudo {
        >|      color: #b5bd68;
        >|    }
        >|
        >|    /*color: fg_purple*/
        >|    .hljs-attribute,
        >|    .hljs-code,
        >|    .hljs-selector-id {
        >|     color: #b294bb;
        >|    }
        >|
        >|    /*color: fg_blue*/
        >|    .hljs-keyword,
        >|    .hljs-selector-tag,
        >|    .hljs-bullet,
        >|    .hljs-tag {
        >|     color: #81a2be;
        >|    }
        >|
        >|    /*color: fg_aqua*/
        >|    .hljs-subst,
        >|    .hljs-variable,
        >|    .hljs-template-tag,
        >|    .hljs-template-variable {
        >|      color: #8abeb7;
        >|    }
        >|
        >|    /*color: fg_orange*/
        >|    .hljs-type,
        >|    .hljs-built_in,
        >|    .hljs-builtin-name,
        >|    .hljs-quote,
        >|    .hljs-section,
        >|    .hljs-selector-class {
        >|      color: #de935f;
        >|    }
        >|
        >|    .hljs-emphasis {
        >|      font-style: italic;
        >|    }
        >|
        >|    .hljs-strong {
        >|      font-weight: bold;
        >|    }
        >|    </style>
        >|
        >|    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.12.0/build/highlight.min.js"></script>
        >|    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.4.0/highlightjs-line-numbers.min.js"></script>
        >|
        >|    <script type="text/javascript">
        >|
        >|      var allids = %(allids)s;
        >|
        >|      function highlightCode() {
        >|        // console.log('starting!');
        >|        var baselang_divs = document.getElementsByClassName('baselang');
        >|        for (var i = 0; i < baselang_divs.length; ++i) {
        >|          var div = baselang_divs[i];
        >|          // console.log('Highlighting ' + div.id);
        >|          hljs.highlightBlock(div);
        >|        }
        >|        // console.log('finished!');
        >|      }
        >|
        >|      function highlightBaseCode(id) {
        >|        var block = document.getElementById(id);
        >|        if (block) {
        >|           hljs.highlightBlock(block);
        >|           // hljs.lineNumbersBlock(block);
        >|        }
        >|      }
        >|
        >|      function tv(id) {
        >|        // Toggle visibility of node with given id.
        >|        var node = document.getElementById(id);
        >|        if (node) {
        >|          // console.log('Toggling ' + id + ': "' + node.style.display + '"');
        >|          // console.log('Toggling ' + id);
        >|          var display = node.style.display;
        >|          if ((display == 'block') || (display == '')) {
        >|            node.style.display = 'none';
        >|          } else {
        >|            node.style.display = 'block';
        >|          }
        >|        } else {
        >|          console.log('ERROR: Failed to find node with id ' + id);
        >|        }
        >|        var enode = document.getElementById(id + ':e');
        >|        if (enode) {
        >|          // console.log('enode color = ' + enode.style.color);
        >|          var color = enode.style.color;
        >|          enode.style.color = ((color == 'black')||(color=='')) ? 'red' : 'black';
        >|        }
        >|      };
        >|
        >|      function tlist(ids) {
        >|        for (var i = 0; i < ids.length; ++i) { tv(ids[i]); }
        >|      }
        >|
        >|      function sv(id) {
        >|        // Set visibility of node with given id.
        >|        var node = document.getElementById(id);
        >|        if (node) {
        >|          node.style.display = 'block';
        >|        } else {
        >|          console.log('ERROR: Failed to find node with id ' + id);
        >|        }
        >|        var enode = document.getElementById(id + ':e');
        >|        if (enode) {
        >|          enode.style.color = 'black';
        >|        }
        >|      };
        >|
        >|      function slist(ids) {
        >|        for (var i = 0; i < ids.length; ++i) { sv(ids[i]); }
        >|      }
        >|
        >|      function uv(id) {
        >|        // Unset visibility of node with given id.
        >|        var node = document.getElementById(id);
        >|        if (node) {
        >|          node.style.display = 'none';
        >|        } else {
        >|          console.log('ERROR: Failed to find node with id ' + id);
        >|        }
        >|        var enode = document.getElementById(id + ':e');
        >|        if (enode) {
        >|          enode.style.color = 'red';
        >|        }
        >|      };
        >|
        >|      function ulist(ids) {
        >|        for (var i = 0; i < ids.length; ++i) { uv(ids[i]); }
        >|      }
        >|
        >|      window.onload = %(onload)s;
        >|    </script>
        >|""")

      /# TODO(wmh): Temporary hack. The per-construct color mapping should
      /# be obtained from the current Context and its ConsInfo instances.
      cls.ConstructColorMap = {
        /# 'class': 'red',  # 255, 0, 0
        /# 'behavior': 'red',
        /# 'method': 'orange',  # 255, 165, 0
        /# 'field': 'orange',
        /# 'lifecycle': 'orange',
      }
      cls.MetaConstructColorMap = {
        'primary':   'cyan',
        'primary2':  'rgb(0, 100, 0)',      # darkgreen
        /#'feature':   'rgb(85, 107, 47)',    # darkolivegreen
        'feature': 'rgb(41,171,135)',      # jungle green
        /# 'secondary': 'rgb(85, 107, 47)',    # darkolivegreen
        /# 'secondary': 'rgb(173,216,230)',    # light blue
        'secondary': 'rgb(41,171,135)',    # jungle green
        /# 'featval':   'rgb(255,105,180)',    # hotpink
        /#'featval':   'rgb(238, 106, 167)',  # hotpink2
        /#'featval':   'rgb(205,96,144)',  # hotpink3
        'featval':   'purple',
        'keyword':   'rgb(255, 20, 147)',   # deep pink
        'end':       'rgb(139, 139, 131)',  # ivory4
        'name':      'rgb(0, 0, 255)',      # blue1
        'comment':   'rgb(0, 139, 139)',    # cyan4
        'ellipsis':  'black',               # scope collapses (hidden)
        'ellipsis2': 'red',                 # scope collapses (visible)
      }

      /# Initialized in Initialize(). Replaces all envars with a single
      /# file containing all configuration options.
      cls.CONFIG = None

      /# A collection of constants controlling implementation paths.
      cls.IMPL = {
        /# If true, do create an auto-generated test class for the
        /# auto-generated meta-class of each user-class (and put the test blocks
        /# of meta methods defined within user-classes within this test class).
        /# If false, do NOT create a test class for metaclasses of userclasses,
        /# and put the test blocks of meta methods within the testclass of the
        /# userclass instead.
        'testmetaclass': False,
        /# If true, do create an auto-generated metaclass for the auto-generated
        /# testclass of each userclass. If false, do NOT create such a
        /# metaclass. The latter implies that meta fields and meta methods
        /# are not supported on test classes. In general, static fields/methods
        /# should always suffice for auto-generated test classes, but there
        /# will definitely be places where meta fields/methods will be needed
        /# on explicit test-classes provided by users.
        'metatestclass': False,
      }
    setup:
      /# Each test should invoke some variant of
      /#    _, _, _, metac = test.cachedInfo(metal='oopl', basel='python')
      /# specifying the desired return vals and args.
      /#
      /# A common call is:
      /#  _, _, _, metac = test.cachedInfo(basel='python')
    end lifecycle;

    method cli : metax.cli.Values #:
      The command-line flags and args.
    scope:
      return metax.root.MetaObject.CLI()
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      test.isinst(metac.cli(), metax.cli.Values)
    end method cli;

    method updateCLI #:
      Updates the CLI with a new Command instance.

      This should rarely be needed, as the global CLI instance is meant
      to represent the command-line.  However, for interactive shells, the
      Command is updated each time a new command is entered at the shell
      prompt.

      TODO(wmh): Decide whether the interactive shell should maintain its
      own metax.cli.Values() instance so that the global instance remains
      pinned to the command line values.
    params:
      var command : metax.cli.Command #:
        The newly instantiated Command instance.  This should rarely
    scope:
      self.cli()._command_Is(command)
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      command = metax.cli.Command('fauxcmd')
      metac.updateCLI(command)
      test.issame(command, metac.cli()._command_())
    end method updateCLI;

    method registerClass #:
      Register an expanded class with myself.
    params:
      var klass : metax.oopl.ClassConstruct;
    scope:
      fqn = klass.fqn()
      /# print('Registering %s' % fqn)
      classes = self.classes()
      if fqn in classes and classes[fqn] is not klass:
        /#raise Error(
        print('ERROR: ' + (
          'Attempt to double register class %s (%s vs %s)' %
          (fqn, id(klass), id(classes[fqn]))))
      classes[fqn] = klass
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      klass = test.basics()
      n = len(metac.classes().keys())
      metac.registerClass(klass)
      test.iseq(n+1, len(set(metac.classes().keys())))
    end method registerClass;

    method fs : metax.c.Filesystem #:
      The filesystem wrapper.
    scope:
      return self.filesystem()
      /# return self.__class__.Filesystem()
    test:
      _, _, _, compiler = self.cachedInfo(metal='meta')
      test.isinst(compiler.fs(), metax.fs.Filesystem)
    end method fs;

    method metaRoot : str #:
      Obtain the root directory for Meta.
    scope:
      fs = self.fs()
      rootdir = Compiler.CONFIG.get('src_root', None)
      if not rootdir or not fs.exists(rootdir):
        raise Error('Failed to find <<src__root>> %s' % rootdir)
      return rootdir
    test:
      _, _, _, metaoopl = test.cachedInfo()
      test.fixenv()
      rootdir = metaoopl.metaRoot()
      test.iseq(metax.c.Compiler.CONFIG['src_root'], rootdir)
    end method metaRoot;

    method metaPath : str #:
      Obtain a path relative to the meta root.
    params:
      multi var subpaths : vec;
    scope:
      fs = self.fs()
      return fs.join(self.metaRoot(), *subpaths)
    test:
      _, _, _, metaoopl = test.cachedInfo()
      test.fixenv()
      fs = metaoopl.fs()
      rootdir = metax.c.Compiler.CONFIG['src_root']
      test.iseq(
        rootdir + '/oopl/python/meta/test.py',
        metaoopl.metaPath('oopl', 'python', 'meta', 'test.py'))
    end method metaPath;

    method mapPath : str #:
      Obtain the .map variant of given path.
    params:
      var path : str;
    scope:
      fs = self.fs()
      dirname, basename = fs.split(path)
      if basename[0] != '.':
        basename = '.' + basename
      /# We used to return /a/.b.map for /a/b.py or /a/b.cc, but
      /# now we return /a/.b.py.map and /a/.b.cc.map and /a/.b.h.map
      /# so that we have separate map files for b.cc and b.h.
      return fs.join(dirname, basename + '.map')
    test:
      _, _, _, metaoopl = test.cachedInfo()
      test.iseq(
        '/some/rep/a/.b.py.map', metaoopl.mapPath('/some/rep/a/b.py'))
    end method mapPath;

    method repositoryPath #:
      Obtain the path to the meta repository.
    scope:
      result = self.repodir()
      if result is None:
        cls = self.__class__
        fs = self.fs()
        result = Compiler.CONFIG['repository_path']
        self.repodirIs(result)
        /# Disabling until unittests can create fake filesystems.
        /#if not fs.exists(result):
        /#  raise Error('Failed to find meta repository "%s"' % result)
      return result
    test:
      /# TODO(wmh): Get this working.
      _, _, _, metaoopl = test.cachedInfo()
      test.fixenv()
      path = metaoopl.repositoryPath()
      expected = metax.c.Compiler.CONFIG['repository_path']
      test.iseq(expected, path)
    end method repositoryPath;

    method workspaceDirectory : str #:
      The directory containing the baselang-specific WORKSPACE.
      This is the directory from which all unittesting code should be invoked
      (implicitly via bazel, explicitly for raw tests).
    scope:
      return self.fs().join(self.repositoryPath(), self.basePath())
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      test.endswith('meta/oopl/python', metac.workspaceDirectory())
    end method workspaceDirectory;

    method verifyDirectory : bool #:
      Ensure the initial directory is set up.
    params:
      var fp : ostream = out #:
        Where to write diagnostic information.
      var metadir : str = null #:
        The metadir to verify. If null, obtained from state.
    scope:
      result = True
      if metadir is None:
        flags = self.cli()
        metadir = flags.metadir
      assert '/' not in metadir
      repository_path = self.repositoryPath()
      special_metadir = metax.c.SPECIAL_CHILD_DIR
      fs = self.fs()

      def Print(msg):
        if fp: fp.write(msg + '\n')

      if not fs.exists(repository_path):
        Print(
          'ERROR: %s does not exist ... create as directory' % repository_path)
        result = False

      elif fs.exists(metadir):
        /# The metadir directory exists.
        if metadir == special_metadir:
          /# The metadir directory must be a symlink to the official repository.
          if not fs.islink(metadir):
            Print(
              'ERROR: %s must be a symlink to %s' % (metadir, repository_path))
            result = False
          else:
            link = fs.readlink(metadir)
            if link != repository_path:
              Print(
                'ERROR: %s must be a symlink to %s not %s' %
                (metadir, repository_path, link))
              result = False
        else:
          /# Note the special metadir ... must be a directory.
          if not fs.isdir(metadir):
            Print('ERROR: %s must be a directory' % metadir)
            result = False
      else:
        /# The metadir subdir of the current directory does not exist.
        if metadir == special_metadir:
          /# Create a symlink to the repository.
          Print(
            'NOTE: Created symlink from %s to %s' % (metadir, repository_path))
          fs.symlink(repository_path, metadir)
        else:
          /# Create a directory
          Print('NOTE: Created %s' % metadir)
          fs.mkdir(metadir, mode=0o755)

      return result
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      test.istrue(metac.verifyDirectory())
    end method verifyDirectory;

    method bootstrapContext : Context #:
      Obtain a Context capable of parsing a schema file.

      Creates a Context populated with the ConsInfo instances needed to
      parse a schema file.

      This method should be updated any time src/schema/meta/schema.meta is
      modified.
    scope:
      cls = self.__class__
      context = cls.BootstrapContext()
      context.compilerIs(self)
      return context
    test:
      test.basics()
      bootstrap_context = test.compiler.bootstrapContext()
      test.iseq(7, len(bootstrap_context.consmap()))

      /# We verify the bootstrapContext has all the same Construct/Attribute
      /# definitions as the actual Meta(Meta) schema.
      _, schema, schema_context, _ = test.cachedInfo(metal='meta')
      bfp = test.fp()
      bootstrap_context.metafileIs(schema_context.metafile())
      bootstrap_context.show(fp=bfp)
      sfp = test.fp()
      schema_context.show(fp=sfp)
      test.iseqtext(sfp.getvalue(), bfp.getvalue())
    end method bootstrapContext;

    meta
    method BootstrapContext : Context #:
      Obtain a Context capable of parsing a schema file.

      Creates a Context populated with the ConsInfo instances needed to
      parse a schema file.

      This method should be updated any time src/schema/meta/schema.meta is
      modified.
    scope:
      import metax.meta
      clsmap = {
        'MetaLanguage': metax.meta.MetaLanguageConstruct,
        'Construct': metax.meta.ConstructConstruct,
        'Template': metax.meta.TemplateConstruct,
        'Attribute': metax.meta.AttributeConstruct,
        'FeatureValue': metax.meta.FeatureValueConstruct,
        'File': metax.meta.FileConstruct,
        'BaseLanguage': metax.meta.BaseLanguageConstruct,
      }
      childmap = {
        'File': None,
        'MetaLanguage': ['Construct', 'BaseLanguage'],
        'Construct': ['Attribute', 'Template'],
        'Attribute': ['FeatureValue'],
        'BaseLanguage': None,
      }

      /# Add some attributes to all meta-level constructs:
      /#   primary
      /#   comment:
      /#   config:
      empty = '<empty>'
      consmap = {}
      for cons, construct_class in clsmap.items():
        consinfo = ConsInfo(
          cons,
          'word' if cons in ('Attribute', 'File', 'FeatureValue', 'Template')
          else 'id',
          construct_class)
        consmap[cons] = consinfo
        consinfo.registerSecondary('comment:', 'simple', empty, aliases=['#:'])
        if cons not in ('FeatureValue', 'Template'):
          consinfo.registerSecondary(
            'config:', 'complex', empty, children=childmap[cons])

      /# MetaLanguage
      metalanguage = consmap['MetaLanguage']
      metalanguage.registerSecondary('parent', 'xid', empty)
      metalanguage.registerSecondary('name', 'word', '<required>')
      metalanguage.registerSecondary('toplevel', 'enum', empty)
      metalanguage.registerSecondary('nmsp', 'word', empty)
      metalanguage.registerSecondary('color', 'word', empty)
      metalanguage.registerSecondary('scope:', 'simple', empty, aliases=['::'])

      /# Construct
      construct = consmap['Construct']
      construct.registerFeature(
        'presence', default='concrete',
        values={'abstract': None, 'concrete': None})
      construct.registerSecondary('clsname', 'id', empty)
      construct.registerSecondary('pclsname', 'xid', '<empty>')
      construct.registerSecondary('parent', 'xid', empty, aliases=['<'])
      construct.registerSecondary('associations:', 'simple', empty, aliases=['assocs:'])
      construct.registerSecondary('expand:', 'simple', empty)
      construct.registerSecondary('import:', 'simple', empty)
      construct.registerSecondary('translate:', 'simple', empty)
      construct.registerSecondary('compile:', 'simple', empty)
      construct.registerSecondary('scope:', 'simple', empty)

      /# Template
      template = consmap['Template']
      template.registerSecondary(
        'scope:', 'simple', empty, aliases=['::'])

      /# Attribute
      attribute = consmap['Attribute']
      attribute.registerFeature(
        'kind', default='undef',
        values={fk: None for fk in ('undef', 'feature', 'primary', 'secondary')})
      attribute.registerFeature(
        'key', default='showkey',
        values={fk: None for fk in ('nokey', 'showkey', 'aliaskey')})
      attribute.registerFeature(
        'value', default='showval',
        values={fk: None for fk in ('noval', 'userval', 'showval')})
      attribute.registerSecondary('default', 'word', empty, aliases=['='])
      attribute.registerSecondary('type', 'word', empty, aliases=[':'])
      attribute.registerSecondary('children', 'enum', empty)
      attribute.registerSecondary('aliases', 'enum', empty)
      attribute.registerSecondary('autokey', 'str', empty)
      attribute.registerSecondary('replacer', 'word', empty)
      attribute.registerSecondary('delim', 'str', empty)

      /# FeatureValue
      featval = consmap['FeatureValue']
      featval.registerSecondary('aliases', 'enum', empty)

      /# File
      file = consmap['File']
      file.registerSecondary('scope:', 'complex', empty, aliases=['::'])

      /# BaseLanguage
      baselanguage = consmap['BaseLanguage']
      baselanguage.registerFeature(
        'presence', default='concrete',
        values={fk: None for fk in ('concrete', 'abstract')})
      baselanguage.registerSecondary('name', 'word', '<required>')
      baselanguage.registerSecondary('clsname', 'id', '<empty>')
      baselanguage.registerSecondary('pclsname', 'xid', '<empty>')
      baselanguage.registerSecondary('parent', 'xid', '<empty>', aliases=['<'])
      baselanguage.registerSecondary('suffixes', 'enum', empty)
      baselanguage.registerSecondary('scope:', 'simple', empty)

      context = Context(None, consmap, None, None)
      return context
    test:
      bootstrap_context = metax.c.Compiler.BootstrapContext()
      test.iseq(7, len(bootstrap_context.consmap()))
    end method BootstrapContext;

    method bootstrap : metax.meta.MetaLanguageConstruct #:
      Bootstrap the Meta parsing infrastructure.

      In order to parse a .meta file, we need to have a Context identifying
      the legal constructs available in the meta-language that the .meta file
      is implemeted in.

      In order to obtain a Context containing all legal constructs available in
      a meta language, we need to parse the src/schema/<metalang>/schema.meta
      file (which is defined using constructs from Meta(Meta)). This involves
      a circularity ... we need to parse a file in order to parse that file.

      To bootstrap the process, we can manually define the Construct instances
      described in src/schema/meta/schema.meta, and use those manually defined
      Constructs to reparse src/schema/meta/schema.meta, after which we are
      capable of parsing any schema file, and thus any Meta language.

      This method creates ConsInfo instances to represent the constructs in
      Meta(Meta) ... MetaLanguage, Construct, Attribute, FeatureValue and File
      ... and uses them to parse the src/schema/<metalang>/schema.meta file.
    scope:
      /# Now parse <<src_root>>/src/schema/meta/schema.meta
      context = self.bootstrapContext()
      metapath = metax.root.Object.Resource(
        'metameta', fqn='metax.meta.MetaLanguageConstruct')
      fs = self.fs()
      with fs.open(metapath, 'r') as fp:
        text = fp.read()
      metafile = MetaFile(metapath, self, text)
      /#metafile.debuglevelIs(4)
      file_construct = metafile.parseMeta(context)
      scope = file_construct.rawattr('scope:')
      schema = scope.value()[0]
      return schema
    test:
      _, _, _, metac = test.cachedInfo(metal='meta')
      schema = metac.bootstrap()
      /#schema.write()
    end method bootstrap;

    method metalangNamed : metax.meta.MetaLanguageConstruct #:
      Obtain the MetaLanguageConstruct instance specified by a name or id.

      Returns a cached instance if present, else parses the schema file
      associated with the specified metalang.
    params:
      var nori : str #:
        The name (or id) of a Meta Language.
      var schema_path : str = null #:
        Where the schema file resides. Necessarily only if it is not in the standard
        location (<src_root>/src/schema/<metal>/schema.meta).
    scope:
      debug = False
      cls = self.__class__
      metalangs = self.metalangs()
      result = metalangs.get(nori, None)
      can = nori.lower()
      id = can

      if result is None:

        def FindClass(name, modules):
          """Find a class with given name in one or more modules (first one)."""
          result = None
          for mod in modules:
            result = getattr(mod, clsname, None)
            if result:
              break
          return result

        /# Parse the schema file associated with the language.
        fs = self.fs()
        metalang, metafile = self.metalangFromSchema(metal=id, path=schema_path)
        name = metalang.attrval('name')
        toplevel = metalang.attrval('toplevel')
        nmsp = metalang.attrval('nmsp')
        mlparent = metalang.attrval('parent', default=None)

        if debug:
          print('metalangNamed: name=%s mlparent=%s toplevel=%s' % (
            name, mlparent, toplevel))

        /# Establish the modules to look for classes within.
        /#  - each meta language should have its own namespace, either
        /#    metax.<metaid> or something user-specified.
        /#  - currently, Meta(Oopl) and Meta(Doc) are defined here in this
        /#    file, but we will incrementally pull them out. The following
        /#    code supports this incremental approach, allowing us to
        /#    define some metalang clasess in metax.oopl and some in metax.c
        mnames = []
        if nmsp:
          mnames.append(nmsp)
        mnames.append('metax.%s' % id)
        modules = []
        for mname in mnames:
          try:
            module = importlib.import_module(mname)
            modules.append(module)
          except ImportError:
            pass
          except AttributeError:
            /# This can happen if a previous attempt to generate a schema file
            /# leads to corruption (for example).
            pass

        /# We obtain the mapping from construct name (and baselang name) to
        /# python class, via introspection.
        construct_classes = {}
        baselang_classes = {}
        baselang_constructs = {}
        for construct in metalang.attrval('config:'):
          if construct.kind() == 'Construct':
            cid = construct.id()
            clsname = construct.className()
            /# TODO(wmh): Each metalang should have its own namespace!
            /#  metax.oopl, metax.doc, etc. We'll want to dynamically import
            /# the module and introspect on classes. Could be messy in C++.
            klass = FindClass(clsname, modules)
            /# klass = getattr(module, clsname, None)
            if klass:
              if cid[0] == '_':
                pass
              else:
                construct_classes[cid] = klass
            else:
              /# print('WARNING: Failed to find class %s for construct %s' % (
              /#   clsname, cid))
              pass
            if debug:
              print('  %-15s = %-30s = %s' % (cid, clsname, klass))

          elif construct.kind() == 'BaseLanguage':
            cid = construct.id()
            clsname = construct.className()
            klass = FindClass(clsname, modules)
            /# klass = getattr(module, clsname, None)
            baselang_constructs[cid] = construct
            if klass:
              baselang_constructs[klass] = construct
              baselang_classes[cid] = klass
            if debug:
              print('  %-15s = %-30s = %s' % (cid, clsname, klass))
          else:
            raise InternalError('Invalid kind %s' % construct.kind())
        baselang_class_list = baselang_classes.values()
        basesels = ['meta'] if id == 'meta' else []

        if mlparent:
          if mlparent not in metalangs:
            raise Error(
              'Meta(%s) inherits from Meta(%s) which does not exist' %
              (name, mlparent))
          metalangparent = metalangs[mlparent]
        else:
          metalangparent = None

        /# print('id=%s name=%s metalangparent=%s toplevel=%s' % (id, name, metalangparent, toplevel))

        metalang.nameIs(name)
        metalang.metalangparentIs(metalangparent)
        metalang.toplevelIs(toplevel)
        metalang.postCreationInitialization()

        /# Add the construct-to-class mapping for Meta(Meta)
        /#  - TODO(wmh): Every Construct construct has an associated 'class'
        /#    construct (in Meta(Oopl)), and the scope of the class is the
        /#    scope of the Construct.
        /#  - Instead of having the various construct classes defined here
        /#    in parser.meta, the code should be moved into the schema file.
        for construct_name, construct_class in construct_classes.items():
          metalang.registerConstructClass(construct_name, construct_class)

        /# Add any specified basesels.
        /#  - TODO(wmh): This is a hack for Meta(Meta). Normally, each
        /#    BaseLanguage that is registered with a MetaLanguage adds
        /#    one or more suffixes, but Meta(Meta) doesn't really need
        /#    to define any BaseLanguages. Clean this up.
        for basesel in basesels:
          metalang.basesels()[basesel] = None

        /# Create the root Context instance associated with this MetaLanguage.
        context = self.metalangToContext(metalang, metafile)
        metalang.contextIs(context)

        /# Add the baselangs
        /#  - TODO(wmh): Instead of explicitly enumerating baselangs, we should
        /#    parse the 'config:' block of the metalang looking for BaseLanguage
        /#    instances.
        for baselang_class in baselang_class_list:
          if debug:
            print('  baselang %s' % baselang_class)
          /# TODO(wmh): This code is creating a new instance when we already
          /# parsed instances of the constructs ... use them instead!
          /# baselang = baselang_class(None, None, context)
          baselang = baselang_constructs[baselang_class]
          if baselang:
            baselang.postCreationInitialization(metalang=metalang)
            metalang.registerBase(baselang)
          else:
            print('***** ERROR: Failed to find baselang for %s' % baselang_class)

        /# Register metalang in cache.
        metalangs[metalang.id()] = metalang
        metalangs[metalang.id().lower()] = metalang
        metalangs[metalang.name()] = metalang

        result = metalang

      return result

    test:
      _, _, _, metac = test.cachedInfo(metal='meta')
      metameta = metac.metalangNamed('meta')
      metaoopl = metac.metalangNamed('oopl')
      test.issame(metaoopl.metalangparent(), metameta)
      metameta2 = metac.metalangNamed('meta')
      test.issame(metameta2, metameta)
      metaoopl2 = metac.metalangNamed('oopl')
      test.issame(metaoopl2, metaoopl)

      test.iseqvec(test.metameta_consids, sorted(metameta._consmap))
      test.iseqvec(test.metaoopl_consids, sorted(metaoopl._consmap))
    end method metalangNamed;

    method metalangFromSchema : tuple<metax.meta.MetaLanguageConstruct,MetaFile> #:
      Obtain a MetaLanguageConstruct from a schema.meta file.
    params:
      var metal : str = null #:
        The id of the meta. If given, it must be id, not name. That is what is
        used in forming the directory path within which the schema is stored.
        One of metal or path is needed.
      var path : str = null #:
        Where the schema path resides. One of metal or path is needed.
    scope:
      fs = self.fs()
      if path:
        /# Do we still want to support explicit path now that paths are in config?
        pass
      else:
        config = metax.root.MetaObject.Config()
        metalangs = config['metalangs']
        path = metalangs.get(metal, None)
        if path is None:
          raise Error(
            'Failed to find %s in config (%s)' %
            (metal, ','.join(metalangs.keys())))
        /# print('FOUND %s for %s' % (path, metal))
      if not fs.exists(path):
        raise Error('%s does not exist' % path)

      bootstrap_context = self.bootstrapContext()
      metafile = self.parseMeta(
        path, context=bootstrap_context, is_schema=True)
      metafile.hasErrors(show=True)

      file = metafile.construct()
      scope = file.rawattr('scope:')
      value = scope.value()
      if len(value) != 1:
        raise Error('Found %d constructs in %s' % (len(value), path))
      result = value[0]
      if not isinstance(result, metax.meta.MetaLanguageConstruct):
        raise Error('Found %s not MetaLanguageConstruct' % result.__class__)

      if metal is not None and metal != result.id():
        raise Error(
          'metalangFromSchema: requested %s found %s' % (metal, result.id()))

      return result, metafile
    test:
      return

      metac = metax.c.Compiler(metal='oopl', basel='python')
      metalang, metafile = metac.metalangFromSchema('meta')
      test.iseq('meta', metalang.id())
    end method metalangFromSchema;

    method metalangToContext : Context #:
      Given a MetaLanguageConstruct, produce a Context instance.

      TODO(wmh): This needs to be generalized. It should not take a
      MetaLanguageConstruct as input, but rather a ComplexBlock of Construct
      instances (so that it can be applied to 'config:' blocks too).
      It should also pass in a Context (null if we are defining the
      top-level context) that is used to establish defaults.
    params:
      var metalang : metax.meta.MetaLanguageConstruct #:
        The metalang.
      var metafile : MetaFile #:
        The metafile storing the metalang file.
    scope:
      debug = False

      def AttrVal(attribute_construct, key, default=REQUIRED):
        """Obtain an attribute value.

        Obtains the value of the attribute within attribute_construct
        identified by 'key'. If not present locally, look in parent
        before failing.

        Args:
          attribute_construct: metax.meta.AttributeConstruct
          key: str
          default: any
        """
        attr = attribute_construct.rawattr(key, default=None)
        if attr is None:
          /# Not present locally, but parent Constructs may define the same
          /# Attribute.
          parent = attribute_construct
          while parent and not attr:
            parent = self.attributeParent(parent)
            if parent:
              attr = parent.rawattr(key, default=None)
        if attr is None:
          result = default
          if default is REQUIRED:
            raise Error(
              'Failed to find attribute "%s" in %s' %
              (key, attribute_construct.path()))
        else:
          result = attr.value()
        return result

      /# We maintain mappings from Construct ids to ComplexBlock instances,
      /# representing the 'config:' block of each Construct. This is used
      /# to perform lookup in Construct parents.
      configmap = {}
      consmap = {}

      /# This metalang starts with all constructs defined in the parent
      /# Meta class.
      metalang_parent = metalang.rawval('parent', default='meta')
      if metalang_parent != metalang_parent.lower():
        print('WARNING: metalang uid %s not %s' % (metalang_parent, metalang_parent.lower()))

      if metalang_parent == 'meta':
        /# We can add the ConsInfo instances from bootstrapContext instead of
        /# having to parse the Meta(Meta) metalang.
        bootstrap_context = self.bootstrapContext()
        for cons, consinfo in bootstrap_context.consmap().items():
          consmap[cons] = consinfo
      else:
        raise Error('Not yet supporting MetaLang parent %s' % metalang_parent)

      /# The returned Context is the root of the lexical chain of Contexts for
      /# this metalang. As such, there is no parent Context, and no need for a
      /# MetaFile. Note that MetaFile.parseMeta() will invoke subclone() on this
      /# instance to create a metafile-specific Context instance.
      /#metalang.write()

      for construct in metalang.rawattr('config:').value():

        if debug:
          print(construct.kindid())

        if construct.kind() == 'Construct':
          kind = construct.id()
          presence = construct.rawval('presence', 'concrete')
          config = construct.rawattr('config:')
          configmap[kind] = config

          /# Establish the class implementing this construct.
          /#
          /# TODO(wmh): For now, this is based on
          /# MetaLanguageConstruct.consmap() and explicit registration via
          /# MetaLanguageConstruct.registerConstructClass(), but should be
          /# determined by the 'scope:' block of Construct instances found
          /# anywhere in the config: chain.  When that happens, we can remove
          /# consmap(), registerConstructClass() and getConstructClass().
          construct_class = metalang.getConstructClass(kind)

          if presence == 'abstract':
            /# The current construct is abstract, so it doesn't produce any
            /# attributes directly. However, other constructs may inherit from
            /# it, in which case the constructs found here will be used to
            /# provide default values.
            continue

          /# Establish if this Construct has a conceptual (not lexical) parent
          /# from which Attributes are inherited.
          parent_name = construct.rawval('parent', None)
          if parent_name is not None:
            /# This Construct construct inherits attributes from parent_name
            parent_config = configmap[parent_name]
          else:
            parent_config = None

          primary = config.cons(kind, default=None)
          if primary is None:
            raise Error(
              'Construct %s does not contain a primary %s attribute' %
              (kind, kind))

          ptype = primary.rawattr('type').value()
          consinfo = ConsInfo(kind, ptype, construct_class)
          consmap[kind] = consinfo
          for attribute in config.value():
            if attribute.kind() == 'Template':
              template = attribute.rawattr('scope:').valueAsStr()
              consinfo.registerTemplate(attribute.id(), template)
            else:
              if debug:
                print('  ' + attribute.kindid())
              aconfig = attribute.rawattr('config:', default=None)
              if aconfig:
                for featval in aconfig.value():
                  if debug:
                    print('    ' + featval.kindid())

              if parent_config:
                parent_attribute = parent_config.cons(attribute.id(), default=None)
                pa = self.attributeParent(attribute)
                assert parent_attribute is pa
              else:
                parent_attribute = None

              akey = attribute.id()
              akind    = AttrVal(attribute, 'kind')
              default  = AttrVal(attribute, 'default')
              type     = AttrVal(attribute, 'type')
              key      = AttrVal(attribute, 'key',      default=None)
              value    = AttrVal(attribute, 'value',    default=None)
              children = AttrVal(attribute, 'children', default=None)
              aliases  = AttrVal(attribute, 'aliases',  default=None)
              autokey  = AttrVal(attribute, 'autokey',  default=None)
              replacer = AttrVal(attribute, 'replacer', default=None)
              comment  = AttrVal(attribute, 'comment',  default=None)

              if replacer:
                consinfo.setReplacer(replacer)

              if False and aliases:
                print('%s is %s : %s = %s (%s) [%s]' % (construct.kindfqn(), akey, type, default, aliases, consinfo.primary()))

              keyopt = False
              valopt = False
              autokey = None

              if False and debug:
                print(
                  '    akind=%s key=%s type=%s default=%s aliases=%s keyopt=%s valopt=%s autokey=%s' %
                  (akind, akey, type, default, aliases, keyopt, valopt, autokey))

              if akind == 'feature':
                /# consinfo.registerFeature()
                featvals = metax.attr.EnumAttribute.StrToEnum(type)
                values = {fv: None for fv in featvals}
                consinfo.registerFeature(
                  akey, values=values, default=default, aliases=aliases, delim=None)
              elif akind == 'primary':
                consinfo.order().append(kind)
                pinfo = consinfo.primary()
                if default == '<auto>':
                  /# The primary key is optional.
                  /# consinfo.primary() maps primary tokens all to the same map.
                  pinfo[kind]['valopt'] = True
                if aliases:
                  /# We need to add the aliases to consinfo.primary(), pointing
                  /# to the same value as consinfo.primary()[kind]
                  for alias in aliases:
                    pinfo[alias] = pinfo[kind]
              elif akind == 'secondary':
                /# if default == '<special>': default = None
                consinfo.registerSecondary(
                  akey, type=type, default=default, aliases=aliases,
                  keyopt=keyopt, valopt=valopt, autokey=autokey, children=children)

        elif construct.kind() == 'BaseLanguage':
          pass

        else:
          print('********* WARNING: Not processing %s' % construct.kindid())

      context = Context(None, consmap, self, metafile)

      return context
    test:
      /# cachedInfo() invokes compiler.metalang() which invokes
      /# compiler.metalangToConstruct().
      _, metalang, context, compiler = test.cachedInfo(metal='meta')
      test.iseq(7, len(context.consmap()))

      /# We compare the context produced from metalangToContext() with
      /# bootstrapContext(). They should be identifical ... if not, it means the
      /# definition of Meta(Meta) in
      /#   <<src_root>>/src/schema/meta/schema2.meta
      /# has diverged from the definition of Meta(Meta) in
      /#   metax.c.Compiler.bootstrapContext()
      /# The latter code needs to be updated.
      bootstrap_context = compiler.bootstrapContext()
      bfp = test.fp()
      bootstrap_context.metafileIs(context.metafile())
      bootstrap_context.show(fp=bfp)
      fp = test.fp()
      context.show(fp=fp)
      test.iseqtext(fp.getvalue(), bfp.getvalue())

      /# Now we obtain the context for Meta(Oopl)
      metax.c.Debug = True
      _, metalang, context, compiler = test.cachedInfo()
      test.iseqvec(
        test.metaoopl_consids2,
        sorted(context.consmap()))
      consgroup = context.legalInfo(['method', 'field'])
      /# consgroup.show()
      /# context.show()
    end method metalangToContext;

    method attributeParent : metax.meta.AttributeConstruct #:
      Obtain the parent Attribute of a given Attribute.
    params:
      var attribute_construct : metax.meta.AttributeConstruct;
    scope:
      assert isinstance(attribute_construct, metax.meta.AttributeConstruct)
      /# Obtain the Construct within which the Attribute resides.
      construct_construct = attribute_construct.parent().parent()
      /# Check if the Construct has a 'parent'
      parent_name = construct_construct.rawval('parent', None)
      if parent_name:
        /# Find the parent, which must exist within the 'config:' block
        /# that the Construct resides within.
        parent_construct = construct_construct.parent().cons(
          parent_name, default=None)
        if not parent_construct:
          raise Error(
            '%s has parent %s which does not exist' % (
              construct_construct.id(), parent_name))
        /# Obtain the AttributeConstruct within parent_construct that matches
        /# attribute_construct.
        config = parent_construct.rawattr('config:')
        result = config.cons(attribute_construct.id(), default=None)
      else:
        /# No parent.
        result = None
      return result
    test:
      _, metalang, _, compiler = test.cachedInfo(metal='oopl', basel='python')
      /# In Meta(Oopl), Construct 'class' inherits from '_oopl_' and
      /# has Attribute 'comment:'.
      ac = metalang.child('class@config/comment:@config')
      test.iseq('/oopl/class@config/comment:@config', ac.path())
      acp = compiler.attributeParent(ac)
      test.iseq('/oopl/_classic_@config/comment:@config', acp.path())
      acpp = compiler.attributeParent(acp)
      test.iseq('/oopl/_symbol_@config/comment:@config', acpp.path())
      acppp = compiler.attributeParent(acpp)
      test.iseq('/oopl/_oopl_@config/comment:@config', acppp.path())
      acpppp = compiler.attributeParent(acppp)
      test.isnull(acpppp)
    end method attributeParent;

    method basePath : str #:
      Obtain the path within which to write a BaseFile instance.
    params:
      var fqn : str = null #:
        An fqn to convert to a subpath.
      var prefix : str = '' #:
        What to insert before last component of fqn
      var suffix : str = '' #:
        What to insert after last component of fqn
    scope:
      fs = self.fs()
      /#flags = self.cli()
      /#root = fs.join(flags.metadir)
      if fqn:
        parts = fqn.split('.')
        parts[-1] = prefix + parts[-1] + suffix
      else:
        parts = []
      return fs.join(
        self.metalang().id().lower(), self.baselang().id(), *parts)
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      test.iseq(
        'oopl/python/nm/sp/Class.py',
        metac.basePath('nm.sp.Class', suffix='.py'))
      test.iseq(
        'oopl/python/nm/sp/.Class.map',
        metac.basePath('nm.sp.Class', prefix='.', suffix='.map'))
    end method basePath;

    method basePathToMeta : tuple<str,bool> #:
      Given a baselang path to a namespace or class file, obtain the path of
      the .meta source file associated with it.

      Returns:
       0. the .meta path, or null if not found
       1. true if the path exists, false if it does not.
    params:
      var basepath : str #:
        The baselang path.
      var map_path : str = null #:
        This is almost always null, and is obtained from basepath. But if
        it is known by the caller, it can be provided (in which case basepath
        is ignored and can be null).
    scope:
      result = None
      exists = False
      fs = self.fs()

      /# map_path = fs.join(
      /#   fs.dirname(basepath), '.' + fs.basename(basepath) + '.map')
      if map_path is None:
        map_path = self.mapPath(basepath)
      if fs.exists(map_path):
        with fs.open(map_path, 'r') as fp:
          result = fp.readline()[:-1]
          m = metax.c.SUFFIX_RE.match(result)
          if m and fs.exists(result):
            exists = True
      return result, exists
    test:
      _, _, _, compiler = test.cachedInfo(metal='oopl')
      fs = compiler.fs()
      pypath = fs.join(
        compiler.workspaceDirectory(), 'demo', 'cards0', '__init__.py')
      expected_metapath = test.resourcePath('ex2')
      metapath, _ = compiler.basePathToMeta(pypath)
      test.iseq(expected_metapath, metapath)
    end method basePathToMeta;

    method loadMapFile : MetaFile #:
      Load a MapFile from disk.

      This method is paired with MapFile.serialize().
    params:
      var path : str #:
        The path to the .map file.
    scope:
      mapping = []
      map_re = Compiler.MAP_RE
      fs = self.fs()
      with fs.open(path, 'r') as fp:
        /# The first line contains
        /#   <source>
        /# (where <source> is the source .meta file), and all subsequent lines
        /# contain
        /#   <baseline> <metaline> <fullid>
        /# However,in meta1, the first line contains
        /#   <baseline> <metaline> <fullid> <source>
        /# We support both variants while we are using meta1 to compile the
        /# parser.meta code. When we have parser.meta implemented we can
        /# remove the special case code.
        metapath = fp.readline().rstrip()
        parts = metapath.split()
        if len(parts) == 1:
          /# New style
          pass
        elif len(parts) == 4:
          /# Old style
          mapping.append((int(parts[0]), int(parts[1]), parts[2]))
          metapath = parts[3]
        else:
          raise Error('Invalid metapath: %s' % metapath)
        for line in fp:
          m = map_re.match(line)
          if m:
            mapping.append(
              (int(m.group('baseline')),
              int(m.group('metaline')),
              m.group('fullid')))
          else:
            fs.close(fp)
            with fs.open(path, 'r') as fp:
              print(fp.read())
            raise Error('Invalid line "%s"' % line)
      result = MapFile(path, metapath, mapping)
      return result
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      fs = metac.fs()
      path = fs.join(
        metac.workspaceDirectory(), 'demo', 'cards0', '.Card.py.map')
      mapfile = metac.loadMapFile(path)
      test.iseq(
        (8, 5, 'demo.cards0.Card:class'),
        mapfile.mapping()[0])
    end method loadMapFile;

    method parseMeta : MetaFile #:
      Unconditinoally parse a metafile.
    params:
      var path : str #:
        The path to parse. Even if text is provided, path must be also.
      var text : str = null #:
        The text representing the contents of the metafile to parse.
        Provided to support in-memory parsing in situations where
        a filesystem isn't easily available.
      var debuglevel : int = 0 #:
        How much debugging info to print out.
      var context : Context = null #:
        The context to use to parse the metafile. This is normally null,
        in which case the context associated with the metalang is used. If
        that too is null, we use self.bootstrapContext().
      var is_schema : bool = false #:
        True if we are parsing a schema file.
    scope:
      /# We canonicalize the path
      fs = self.fs()
      realpath = fs.realpath(path)
      abspath = fs.abspath(realpath)
      if fs.exists(path):
        if abspath != realpath and text is None:
          raise Error(
            'abspath of realpath should equal realpath? %s vs %s' %
            (abspath, realpath))
      elif text is None:
        raise Error('Path %s does not exist' % path)
      metafiles = self.metafiles()

      /# Obtain text if not already provided.
      if text is None:
        with fs.open(realpath, 'r') as tfp:
          text = tfp.read()

      /# (Sometimes) print a warning if we are reparsing
      if True:
        if path in metafiles:
          print('WARNING: Reparsing %s (path)' % path)
        elif realpath in metafiles:
          print('WARNING: Reparsing %s (realpath)' % path)

      /# Unconditionally parse.
      if context is None:
        metalang = self.metalang()
        context = metalang.context()
        if context is None:
          raise Error('Failed to find a context for Meta(%s)' % metalang.name())
      metafile = MetaFile(realpath, self, text, debuglevel=debuglevel)
      metafile.parseMeta(context, is_schema=is_schema)

      /# Determine a unique abbrev for this metafile.
      def AbbrevExists(abr):
        return abr in metafiles and metafiles[abr] is not metafile
      abbrev = fs.basename(abspath).replace('.meta', '')
      abbrev2 = fs.basename(fs.dirname(abspath)) + '_' + abbrev
      if not AbbrevExists(abbrev):
        pass
      elif False and not AbbrevExists(abbrev2):
        abbrev = abbrev2
      else:
        orig = abbrev
        num = 1
        while AbbrevExists(abbrev):
          num += 1
          abbrev = orig + '_' + str(num)
      metafile.abbrevIs(abbrev)

      /# Register variants of the path in metafiles.
      metafiles[path] = metafile
      metafiles[realpath] = metafile
      metafiles[abbrev] = abbrev
      self.metaorder().append(metafile)

      return metafile
    test:
      /# We create standalone compilers instead of using the cached ones to
      /# ensure a full test.

      /# Parse ex1.meta, which is written in Meta(Meta)
      /#_, _, _, metac = test.cachedInfo(metal='meta')
      metac = metax.c.Compiler(metal='meta', basel='stub')
      ex1, scope, construct, _ = test.getMetaFile(
        'meta', 'ex1', context=metac.bootstrapContext(), compiler=metac)
      test.isinst(ex1, metax.c.MetaFile)
      test.isinst(scope, metax.attr.ComplexBlock)
      test.isinst(construct, metax.meta.MetaLanguageConstruct)

      /# Parse ex2.meta, which is written in Meta(Oopl)
      /# metax.c.Debug = True
      metac = metax.c.Compiler(metal='oopl', basel='python')
      ex2, scope, construct, path = test.getMetaFile(
        'oopl', 'ex2', debuglevel=0, compiler=metac)
      /# Verify there were no errors during parsing
      test.isfalse(ex2.hasErrors(show=True))
      /# Confirm that the canonicalization of the result matches the
      /# input (this assumes the ex2 input is kept in clean form)
      with metac.fs().open(path, 'r') as fp:
        text = fp.read()
      fp = test.fp()
      construct.write(fp=fp)
      out = fp.getvalue()
      test.iseqtext(text, out)
    end method parseMeta;

    method getMetas : tuple<vec<MetaFile>,int,int> #:
      Parse, expand, translate and compile .meta files (only if not already
      parsed)
    params:
      var paths : vec<str> #:
        The .meta files to process.
      var debug : bool = false #:
        If true, print out progress.
      var fp : ostream = null #:
        If non-null, write out progress to given stream.
      var expand : bool = true #:
        If false, do not expand (or import or translate or compile)
      var imports : bool = true #:
        If false, do not import (or translate or compile)
      var translate : bool = true #:
        If false, do not translate (or compile)
      var compile : bool = true #:
        If false, do not compile.
    scope:
      errors = 0
      warnings = 0
      fs = self.fs()
      metafiles = []
      for path in paths:
        base = fs.basename(path)
        if base == 'schema.meta':
          /# print('HERE in compile with %s' % path)
          pass
        else:
          metafile = self.getMeta(
            path, debug=debug, fp=fp,
            expand=expand, imports=imports, translate=translate,
            compile=compile)
          errors += len(metafile.errors())
          warnings += len(metafile.warnings())
          metafiles.append(metafile)
      return metafiles, errors, warnings
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      paths = []
      for name in ('ex1', 'ex2', 'ex3', 'ex4'):
        paths.append(test.resourcePath(name))
      metafiles, _, _ = metac.getMetas(paths, compile=False)
      test.iseq(4, len(metafiles))
    end method getMetas;

    method processMeta : tuple<MetaFile,int,int> #:
      Parse, expand, translate and compile a single .meta file.

      Returns:
       0) The MetaFile instance
       1) The number of errors encountered.
       2) The number of warnings encountered.
    params:
      var path : str #:
        The .meta file to process.
      var text : str = null #:
        The contents of the file to be parsed. Provided for testing purposes,
        not normally used in production.
      var metafile : MetaFile = null #:
        If not present, we parse from first principles, else we ensure that
        any phases requested but not yet performed are performed.
      var debug : bool = false #:
        If true, print out progress.
      var fp : ostream = null #:
        If non-null, write out progress to given stream.
      var expand : bool = true #:
        If false, do not expand (or import or translate or compile)
      var imports : bool = true #:
        If false, do not import (or translate or compile)
      var translate : bool = true #:
        If false, do not translate (or compile)
      var compile : bool = true #:
        If false, do not compile.
    scope:
      flags = self.cli()
      context = self.metalang().context()
      errors, warnings = (0, 0)
      if debug:
        print('processMeta: processing %s' % path)

      /# Parse
      if metafile is None:
        metafile = self.parseMeta(
          path, text=text, debuglevel=flags.debug, context=context)
      phases = metafile.phases()

      if metafile.hasErrors(show=True):
        errors += 1
      elif expand:
        /# Expand
        if 'expand' not in phases:
          if debug:
            print('processMeta: expanding %s' % path)
          metafile.expandMeta()
        if metafile.hasErrors(show=True):
          errors += 1
        elif imports:
          /# Import
          if not flags.disable_imports and 'import' not in phases:
            if debug:
              print('processMeta: importing %s' % path)
            metafile.importMeta()
          if metafile.hasErrors(show=True):
            errors += 1
          elif translate:
            /# Translate
            if 'translate' not in phases:
              if debug:
                print('processMeta: translating %s' % path)
              metafile.translateMeta()
            if metafile.hasErrors(show=True):
              errors += 1
            elif compile:
              /# Compile
              if 'compile' not in phases:
                if debug:
                  print('processMeta: compiling %s' % path)
                metafile.compileMeta()
              if metafile.hasErrors(show=True):
                errors += 1
              if metafile.hasErrors(show=True, category='W'):
                warnings += 1
              metafile.stateIs('complete')
      return metafile, errors, warnings
    test:
      return

      _, _, _, metac = test.cachedInfo(basel='python')
      path = test.resourcePath('ex1')
      metafile, _, _ = metac.processMeta(path)
      test.iseq(path, metafile.path())
    end method processMeta;

    method getMeta : MetaFile #:
      Obtain a metafile, parsing if necessary but using parsed version if
      available.
    params:
      var path : str #:
        The path of the metafile.
      var expand : bool = true #:
        If false, do not expand (or import or translate or compile)
      var imports : bool = true #:
        If false, do not import (or translate or compile)
      var translate : bool = true #:
        If false, do not translate (or compile)
      var compile : bool = true #:
        If false, do not compile.
      var debug : bool = false #:
        If true, print out progress.
      var fp : ostream = null #:
        If non-null, write out progress to given stream.
    scope:
      /# Canonicalize path.
      fs = self.fs()
      if not fs.exists(path):
        print('************* WARNING: %s does not exist' % path)
        return None
      realpath = fs.realpath(path)

      /# We may have already obtained (and partially/fully process) the MetaFiile
      /# so we check for a cached version.
      metafile = self.metafiles().get(realpath, None)

      /# Even if we have a cached version, we may not have performed all of
      /# phases on it that are specified by the args to this method. The
      /# processMeta() method knows which phases have been completed and avoids
      /# repeating them.
      result, _, _ = self.processMeta(
        realpath, metafile=metafile, debug=debug, fp=fp,
        expand=expand, imports=imports, translate=translate, compile=compile)

      return result
    test:
      metac = metax.c.Compiler(metal='oopl', basel='python')
      path = test.resourcePath('ex1')
      metafile = metac.getMeta(path, compile=False)
    end method getMeta;

    method writeSummary #:
      Summarize the status of the given MetaFiles after parsing/compiling.

      Prints out the number of constructs of each kind for each metafile in a
      table (rows are metafiles, columns are construct kinds, cells are integer
      counts).
    params:
      var metafiles : vec<MetaFile> #:
        The metafiles to summarize.
      var fp : ostream = err #:
        Where to write output
      var indent : str = '' #:
        What each line starts with.
      var groups : map = null #:
        Maps group name to list of meta file paths in the group.
    scope:
      indent = u'' + indent
      fs = self.fs()
      flags = self.cli()
      show_counts = flags.summary_counts
      show_times = flags.summary_times
      show_files = flags.summary_files
      nofiles = flags.summary_nofiles

      /# This produces
      /#   AttributeError: 'str' object has no attribute 'decode'
      /# when indent is a str. If errors occur trying to write to an io.StringIO,
      /# do something else.
      /#indent = indent.decode('utf8')

      if groups is None:
        groups = {}

      consmap = {
        'namespace': 'nmsp',
        'behavior': 'beh',
        'class': 'cls',
        'method': 'meth',
        /# 'initializer': 'init',
        'lifecycle': 'life',
        'field': 'fld',
        'receiver': 'rcv',
        'category': 'cat',
        'native': 'ntv',
        'accessor': 'acc',
        'remark': 'rem',
        'resource': 'res',
        'command': 'cmd',
      }
      consorder = [
        'namespace', 'class', 'method', 'field', 'resource', 'lifecycle', 
        'behavior', 'receiver', 
        'command', 'flag',
        'native',
        /# 'category', 'remark',
      ]
      time_titles = [
        ('parse', 't:p'),
        ('expand', 't:e'),
        ('translate', 't:t'),
        /# ('compile', 't:c'),
      ]
      file_titles = [
        ('Files', 'Files', 5),
        ('files', 'files', 5),
        ('%files', '%F', 4),
        ('Lines', 'Lines', 7),
        ('lines', 'lines', 7),
        ('%lines', '%L', 4),
        ('Bytes', 'Bytes', 8),
        ('bytes', 'bytes', 8),
        ('%bytes', '%B', 4),
      ]

      def ValStr(data, kind, width):
        val = data[kind]
        if kind[0] == '%':
          corekind = kind[1:]
          coreval = data[corekind]
          if coreval == val:
            vstr = ''
          else:
            form = '%4.1f'
            vstr = form % val
          result = vstr.rjust(width)
        else:
          vstr = str(val)
          if kind == 'Files' and val == 1:
            vstr = ''
          result = vstr.rjust(width)
        return result

      def ComputePerc(data):
        /# Compute the percentage of files/lines/bytes auto-generated.
        /#  - used to just be the fraction lines/Lines, but the new
        /#    value is more intuitive.
        /# This initializes %files, %lines, and %bytes.
        for key in ('files', 'lines', 'bytes'):
          capkey = key.capitalize()
          val = data[key]
          cap = data[capkey]
          perc = (100.0 - ((100.0 * cap) / val)) if val else 0.0
          pkey = '%' + key
          data[pkey] = perc

      def TotalRow(totals, name, nmf):
        parts = []
        numstr = str(nmf)
        nmstr = '%-15s' % name
        /#ln = len(numstr)
        /#fstr = nmstr[:-ln] + numstr
        /#assert len(fstr) == 15
        fstr = nmstr

        parts.append(indent + fstr)
        if show_counts:
          for kind in order:
            parts.append(' %4d' % totals[kind])
        if show_times:
          for kind, abbrev in time_titles:
            parts.append(' %4.1f' % totals[kind])
        if show_files:
          /# print('lines: %d vs %d' % (totals['lines'], totals['Lines']))
          /# print('bytes: %d vs %d' % (totals['bytes'], totals['Bytes']))
          totals['Files'] = nmf
          ComputePerc(totals)
          for kind, abbrev, kwidth in file_titles:
            parts.append(' ' + ValStr(totals, kind, kwidth))
        line = ''.join(parts)
        return line

      /# TODO(wmh): Once wmh.table has been migrated into a meta library, we
      /# can use it instead of this homegrown approach.  For now, I'm trying to
      /# avoid having meta code rely on any wmh modules.
      totals = {}

      /# This is only used if groups is defined.
      gtotals = None

      /# Obtain a mapping from metafile name to construct kind to integer
      /# count of number of instances of that construct kind. Also obtain the
      /# set of all construct kinds.
      cset = set()
      data = {}
      filemap = {}
      namemap = {}
      for metafile in metafiles:
        path = metafile.path()
        basename = fs.basename(path)
        m = metax.c.SUFFIX_RE.match(basename)
        if not m:
          raise InternalError('Failed to find suffix for %s' % path)
        name = m.group('base')
        /# We obtain either 'all constructs' or 'user-defined constructs'
        output = metafile.constructs() if flags.summary_autogen else metafile.userconstructs()
        cset.update(output.keys())
        data[path] = {kind: len(output[kind]) for kind in output}
        filemap[path] = metafile
        namemap[path] = name

      if data:
        /# Print header.
        order = consorder
        numc = len(order)

        /# Establish how many chars in each row.
        width = 15
        if show_counts:
          width += (numc*(4+1))
        if show_times:
          width += len(time_titles) * (4+1)
        if show_files:
          for kind, abbrev, kwidth in file_titles:  
            width += 1 + kwidth
        sep = indent + '-' * width + '\n'
        /# fp.write(sep)
        fp.write(u'\n')

        /# Print the title line
        parts = []
        parts.append('%s%-15s' % (indent, 'Group/File'))
        if show_counts:
          for kind in order:
            abbrev = consmap.get(kind, kind[:4])
            parts.append(' %4s' % abbrev)
            totals[kind] = 0
        if show_times:
          for kind, abbrev in time_titles:
            parts.append(' %4s' % abbrev)
            totals[kind] = 0
        if show_files:
          for kind, abbrev, kwidth in file_titles:
            parts.append(' ' + abbrev.rjust(kwidth))
            totals[kind] = 0
        line = ''.join(parts)
        fp.write(indent + line + '\n')
        fp.write(sep)

        /# Compute (but do not yet print) the data rows.
        rows = []
        group_indices = []
        group_totals = []
        group_names = []
        name_group_map = {}

        current_group = None
        for path in sorted(data):
          name = namemap[path]
          metafile = filemap[path]
          filedata = data[path]
          group = groups.get(path, None)
          if group:
            name = '  ' + name
            if group != current_group:
              group_indices.append(len(rows))
              gtotals = {'__list__': []}
              group_totals.append(gtotals)
              group_names.append(group)
              name_group_map[group] = gtotals
              rows.append(group)  # will be replaced later.
              current_group = group
            gtotals['__list__'].append(path)

          parts = []
          parts.append('%s%-15s' % (indent, name))
          if show_counts:
            for kind in order:
              cnt = filedata.get(kind, 0)
              totals[kind] += cnt
              if gtotals:
                gtotals.setdefault(kind, 0)
                gtotals[kind] += cnt
              if cnt:
                parts.append(' %4d' % cnt)
              else:
                parts.append(' %-4s' % '')
          if show_times:
            timestats = metafile.stats()
            for kind, abbrev in time_titles:
              cnt = timestats.get(kind, 0)
              totals[kind] += cnt
              if gtotals:
                gtotals.setdefault(kind, 0)
                gtotals[kind] += cnt
              parts.append(' %4.1f' % cnt)
          if show_files:
            filestats = metafile.computeFileStats()
            ComputePerc(filestats)
            /#print('%s = %s' % (name, filestats))
            for kind, abbrev, kwidth in file_titles:
              val = filestats[kind]
              totals[kind] += val
              if gtotals:
                gtotals.setdefault(kind, 0)
                gtotals[kind] += val
              vstr = ValStr(filestats, kind, kwidth)
              /# print('  %-20s %-20s %-20s' % (kind, val, vstr))
              parts.append(' ' + vstr)
          line = ''.join(parts)
          rows.append(line)

        /# Obtain lines for gtotals, inserting into proper indices of rows.
        assert len(group_indices) == len(group_totals)
        for i in range(0, len(group_totals)):
          gtotals = group_totals[i]
          gindex = group_indices[i]
          rows[gindex] = TotalRow(
            gtotals, group_names[i], len(gtotals['__list__']))

        /# Print the data rows.
        for line in rows:
          if nofiles and line[0] == ' ': continue
          fp.write(indent + line + '\n')

        /# Print total row.
        nmf = len(metafiles)
        if nmf > 1:
          /# fp.write(sep)
          line = TotalRow(totals, 'TOTAL', nmf)
          fp.write(indent + line + '\n')
        fp.write(sep)
    test:
      _, _, _, metac = test.cachedInfo(basel='python')
      paths = []
      for name in ('ex1', 'ex2', 'ex3'):
        paths.append(test.resourcePath(name))
      metafiles, _, _ = metac.getMetas(paths, compile=False)
      metac.writeSummary(metafiles, fp=test.fp())
      out = test.out()
      test.contains(
        'Group/File      Files files   %F   Lines   lines   %L    Bytes    bytes   %B',
        out)
    end method writeSummary;

    method _parseArgs : map #:
      Parse args into categories.

      Returns:
        metafiles: vec<str>
          Paths to .meta files that do exist.
        badfiles: vec<str>
          Paths to .meta files that don't exist
        fqns: vec<str>
          Fully qualified namespace/class/method names.
        args: vec<str>
          Anything not in one of the above lists.
        details: vec<map>
          This list has the same number of elements as 'args' (unless 'args' is
          empty and implicit is True). Each map contains:
            arg: str
              some arg-specific string (an absolute path if the arg is
              a metafile, the arg itself if it is an fqn or unknown)
            kind: str
              metafile: the arg is a metafile
              badfile: the arg is not a metafile
              fqn: the arg is a namespace[.class[.method]] fqn.
              unknown: the arg type is unknown
            path: str
              For metafiles, this is just the abspath of the metafile path,
              but for fqns it is the path of the namespace identified by the
              fqn.
            construct: Construct
              Only exists if resolve is true
               - for metafiles, is a FileConstruct (a metafile is obtained
                 by calling Compiler.getMeta(), which will parse but NOT
                 expand/translate/compile the metafile if it hasn't already
                 been loaded). Caller must do these things if they are
                 desired.
               - for fqns, it is a NamespaceConstruct or ClassConstruct or
                 MethodConstruct or FieldConstruct as dictated by the fqn.
    params:
      var args : vec<str> #:
        The non-flag args provided on the command line.
      var errors : bool = false #:
        If true, print out meta files that don't exist.
      var implicit : bool = false #:
        If true, assume that no args means 'find all .meta files in current
        dir'
      var resolve : bool = false #:
        If true, a valid metafile or fqn is to be resolved into a construct
        (available as third element of the triples in result['pair']). If
      var verbose : bool = false #:
        If true, print out details of the parsing.
    scope:
      pkey = ''.join(args)
      result = self.argdata().get(pkey, None)
      if result:
        /# Found cached result.
        return result

      fs = self.fs()
      cli = self.cli()
      baselang = self.baselang()
      metafile_paths = []
      bad_paths = []
      fqns = collections.OrderedDict()
      other = []
      details = []
      rootdir = fs.join(self.repositoryPath(), self.basePath())
      
      groupmap = None  # maps metafile to group it belongs to.
      if cli.metasrcfile:
        groupmap = {}
        /# We parse the specified file and add to args.
        msre = re.compile(r'^(?P<group>[^: \t]+):\s*(?P<list>.+)')
        reldir = fs.cwd()
        with fs.open(cli.metasrcfile, 'r') as msfp:
          for line in msfp:
            line = line.strip()
            if not line: continue
            if line[0] == '#': continue
            m = msre.match(line)
            if m:
              group = m.group('group')
              for mfile in m.group('list').strip().split():
                if fs.isdir(mfile):
                  reldir = mfile
                else:
                  mpath = fs.normpath(fs.join(reldir, mfile))
                  /# TODO(wmh): Clean up code so that we aren't calling
                  /# _parseArgs multiple times, then we don't need to do this
                  /# O(N*N) checking!
                  if mpath not in args:
                    args.append(mpath)
                  groupmap[mpath] = group
            else:
              raise Error(
                'Invalid --metasrcfile %s: %s' % (cli.metasrcfile, line))
        /# We clear the flag so that subsequent invocations of _parseArgs don't
        /# process this code again.
        /#  - clearing does not work because it stops the second parsing from
        /#    creating a groups key!
        /# cli.metasrcfile = ''

      all_files = fs.listdir(fs.cwd())

      def ImplicitMatches(base):
        """Are there any files in the directory that implicitly match base?"""
        result = []
        for candidate in filter(lambda f: f.startswith(base + '.') and not f.endswith('~'), all_files):
          m = metax.c.SUFFIX_RE.match(candidate)
          if m:
            result.append(candidate)
        return result

      if not args:
        if implicit:
          for f in all_files:
            m = metax.c.SUFFIX_RE.match(f)
            if m:
              path = fs.abspath(f)
              metafile_paths.append(path)
              details.append({'arg': f, 'path': path, 'kind': 'metafile'})
      else:
        for arg in args:
          suffmatch = metax.c.SUFFIX_RE.match(arg)
          if verbose:
            print('Compiler._parseArg: working on %s:' % arg)

          argmatch = None if suffmatch else ImplicitMatches(arg) 

          if suffmatch and fs.exists(arg):
            /# A meta source file
            abspath = fs.abspath(arg)
            metafile_paths.append(abspath)
            construct = self.pathToConstruct(abspath, resolve=resolve)
            details.append(
              {'arg': abspath, 'kind': 'metafile', 'construct': construct})
            if verbose:
              print('  is metafile')
          elif argmatch:
            /# An implicit .meta file
            if len(argmatch) > 1:
              /# An ambiguous basename of multiple .meta files within the local
              /# directory.
              print('  WARNING: multiple matches for %s: %s' % (arg, ' '.join(argmatch)))
              details.append({
                'arg': arg,
                'path': None,
                'kind': 'badfile',
                'reason': 'ambiguous: %s' % ' '.join(argmatch),
                'construct': None
              })
            else:
              /# The basename of a unique .meta file within the local directory.
              argplus = argmatch[0]
              abspath = fs.abspath(argplus)
              metafile_paths.append(abspath)
              construct = self.pathToConstruct(abspath, resolve=resolve)
              details.append({
                'arg': arg,
                'path': abspath,
                'kind': 'metafile',
                'construct': construct,
              })
              if verbose:
                print('  implicit match')
          else:
            /# Check if the arg represents a valid fqn target. 
            /#  - if we are looking at arg 'nm.sp.Class.methname', we check
            /#    for 'nm.sp.Class.methname' in $repo/nm/sp/.Class.py.map
            /#  - if the arg 'nm.sp.Class.methname' is part of a test request
            /#    (almost always the case!), we should actually be looking for
            /#    'nm.sp.ClassTest.test_methname' in 
            /#    $repo/nm/sp_test/.ClassTest.py.map instead!
            tdata = baselang.fqnToTarget(arg, verbose=verbose)
            if tdata.get('error', None) is None:
              final_path = fs.join(rootdir, tdata['path'])
              fqn = arg
              construct = None
              metapath, _ = self.basePathToMeta(final_path)
              if metapath:
                file_construct = self.pathToConstruct(metapath, resolve=resolve)
                if file_construct:
                  construct = file_construct.child(fqn)
                  if not construct:
                    print(
                      'WARNING: Failed to find %s in %s' %
                      (fqn, file_construct.kindfqn()))
                /# print('**** HERE with %s and %s and %s and %s' % (fqn, metapath, resolve, file_construct))
              details.append({
                'arg': fqn,
                'path': final_path,
                'kind': 'fqn',
                'construct': construct,
              })
              fqns[fqn] = details[-1]
              if verbose:
                print('  is fqn (%s)' % final_path)
            elif suffmatch:
              if errors or verbose:
                print('  metafile %s does not exist (ignored)' % arg)
              bad_paths.append(arg)
              details.append({
                'arg': arg,
                'path': None,
                'kind': 'badfile',
                'reason': '%s does not exist' % arg,
                'construct': None,
              })
            else:
              other.append(arg)
              details.append({
                'arg': arg,
                'kind': 'unknown',
                'path': None,
                'construct': None,
              })
              if verbose:
                print('  is unknown')
        assert len(details) == len(args), '%s not same size as %s' % (details, args)
      result = {
        'metafiles': metafile_paths,
        'badfiles': bad_paths,
        'fqns': fqns,
        'args': other,
        'details': details,
        'groups': groupmap,
      }
      /# Cache the result so that the next time we can just return it.
      self.argdata()[pkey] = result

      /# pprint.pprint(result)
      return result
    test:
      /# TODO(wmh): Create a faux filesystem with some valid .meta files and
      /# some missing files.
      _, _, _, compiler = test.cachedInfo()
      res = compiler._parseArgs(
        ['a.meta', 'b.meta', 'nm.sp', 'nm.sp.Class', 'nm.sp.Class.meth', 'c.met'])
      test.iseq(
        {
          'args': ['nm.sp', 'nm.sp.Class', 'nm.sp.Class.meth', 'c.met'],
          'badfiles': ['a.meta', 'b.meta'],
          'details': [{'arg': 'a.meta',
                       'construct': None,
                       'kind': 'badfile',
                       'path': None,
                       'reason': 'a.meta does not exist'},
                      {'arg': 'b.meta',
                       'construct': None,
                       'kind': 'badfile',
                       'path': None,
                       'reason': 'b.meta does not exist'},
                      {'arg': 'nm.sp',
                       'construct': None,
                       'kind': 'unknown',
                       'path': None},
                      {'arg': 'nm.sp.Class',
                       'construct': None,
                       'kind': 'unknown',
                       'path': None},
                      {'arg': 'nm.sp.Class.meth',
                       'construct': None,
                       'kind': 'unknown',
                       'path': None},
                      {'arg': 'c.met',
                       'construct': None,
                       'kind': 'unknown',
                       'path': None}],
          'fqns': collections.OrderedDict(),
          'groups': None,
          'metafiles': [],
        },
        res)
    end method _parseArgs;

    method canonicalize #:
      Canonicalize metafiles
    params:
      var metafile_paths : vec<str> #:
        The paths to metafiles to canonicalize.
      var mode : map = null #:
        See Construct.write() for details on mode semantics.
    scope:
      fs = self.fs()
      flags = self.cli()
      debuglevel = flags.debug

      for metafile_path in metafile_paths:
        /# Parse the metafile.
        metafile = self.parseMeta(metafile_path, debuglevel=debuglevel)
        if metafile.errors():
          print('Found parse errors for ' + metafile_path)
          errors += 1
        else:
          /# Canonicalize the constructs in the MetaFile instance.
          file_cons = metafile.construct()
          new_path = metafile_path.replace(metax.c.SUFFIX, '-new' + metax.c.SUFFIX)
          m = metax.c.SUFFIX_RE.match(metafile_path)
          new_path2 = m.group('base') + '-new.meta' + m.group('metasuffix')
          if new_path != new_path2:
            print('FIX ME: In canonicalize with new_path:\n%s\n%s' % (new_path, new_path2))
          if fs.exists(new_path):
            print('ERROR: %s already exists - not replacing' % new_path)
            continue

          /# Write a canonicalized version of the file
          fp = fs.open(new_path, 'w')
          first = True
          for construct in file_cons.rawattr('scope:').value():
            if not first:
              fp.write('\n')
            construct.write(fp=fp, mode=mode)
            first = False
          fp.close()

          /# Show a diff of old and new files, and interactively allow user
          /# to replace old with new or not.
          if Compiler.PromptDiff(metafile_path, new_path, kind='delta'):
            nowstr = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
            backup_path = metafile_path.replace(
              metax.c.SUFFIX, '-' + nowstr + metax.c.SUFFIX)
            backup_path2 = m.group('base') + '-' + nowstr + '.meta' + m.group('metasuffix')
            if backup_path != backup_path2:
              print('FIX ME: In canonicalize with backup_path:\n%s\n%s' % (new_path, new_path2))
            if backup_path == metafile_path:
              print('ERROR: not supporting files with %s suffix' % metax.c.SUFFIX)
              sys.exit(1)
            print('Moved %s to %s' % (
              fs.relpath(metafile_path), fs.relpath(backup_path)))
            fs.rename(metafile_path, backup_path)
            fs.rename(new_path, metafile_path)
          else:
            print('Not replacing ' + metafile_path)
            fs.unlink(new_path)
    test:
      metac = metax.c.Compiler(metal='oopl', basel='python')
      test.captureStdout()
      path = test.resourcePath('ex2')
      metac.canonicalize([path])
      out = test.getStdout()
      test.contains('No differences found', out)
    end method canonicalize;

    protected
    method pathToConstruct : metax.meta.FileConstruct #:
      Obtain the FileConstruct for a given metafile.
    params:
      var path : str #:
        The path to a metafile.
      var resolve : bool = false #:
        Only parse the path if this is true.
    scope:
      construct = None
      if resolve:
        metafile = self.getMeta(
          path, expand=False, translate=False, compile=False)
        if metafile.hasErrors(show=True):
          print('WARNING: Not returning construct from pathToConstruct due to errors')
        else:
          construct = metafile.construct()
      return construct
    test:
      metac = metax.c.Compiler(metal='oopl', basel='python')
      test.isnull(metac.pathToConstruct('/some/faux/path', resolve=False))
      /# TODO(wmh): Test real .meta file.
    end method pathToConstruct;

    meta
    method PromptDiff : bool #:
      Show a diff.

      Returns:
        True if the old file is to be replaced with the new file.
    params:
      var original_path : str #:
        The original file
      var new_path : str #:
        The new file to compare against.
      var kind : str  = 'delta' #:
         - if 'raw', do not print out side-by-side diff (normal diff)
         - if 'delta', do not show common lines
         - if 'left', show only left side for common lines
         - if 'full', show all lines for both files.
    scope:
      result = False
      fp = sys.stdout
      args = ['diff']
      if kind == 'raw':
        pass
      else:
        args.append('--side-by-side')
        args.append('--width=166')
        if kind == 'delta':
          args.append('--suppress-common-lines')
        elif kind == 'left':
          args.append('--left-column')
        elif kind != 'full':
          print('ERROR: Invalid kind %s' % kind)
          sys.exit(1)
      args.append(original_path)
      args.append(new_path)
      fp.write('#' * 166 + '\n')
      fp.write('Command: %s\n' % ' '.join(args))
      fp.write('-' * 166 + '\n')
      fp.write('%-80s  | %s\n' % ('Existing Content', '    Canonicalized Content'))
      fp.write('-' * 166 + '\n')
      rc = subprocess.call(args)
      if rc == 0:
        # No differences.
        result = False
        fp.write('No differences found\n')
      else:
        legal = ['replace', 'skip', 'raw', 'delta', 'left', 'full']
        while True:
          fp.write('Action (%s)? ' % '|'.join(legal))
          ans = sys.stdin.readline().strip()
          if ans in legal:
            break
        if ans == 'skip':
          result = False
        elif ans == 'replace':
          result = True
        else:
          result = cls.PromptDiff(original_path, new_path, kind=ans)
      return result
    test:
      /# No testing of this.
      pass
    end method PromptDiff;

    method generateMajorMode : map #:
      Instantiate a major mode by parsing its schema and writing a .el file.
    params:
      var metalang : MetaLanguage #:
        The language to generate an emacs major-mode for.
      var out_path : str = null #:
        Where to write output. If not provided, a default location is used.
      var fp : ostream = out #:
        Where to write diagnostic information (NOT where the .el file is
        written).
      var dryrun : bool = false #:
        If True, compute but do not write. Useful for testing, where the
        real filesystem is read-only.
    scope:
      fs = self.fs()
      context = metalang.context()
      consmap = context.consmap()
      metaid = metalang.id()
      MetaLang = metalang.name()
      metaprefix = 'meta%s' % metaid

      in_file = metax.root.Object.Resource(
        'emacs_template', fqn='metax.c.Compiler')

      if out_path is None:
        config = metax.root.MetaObject.Config()
        schema_path = config['metalangs'].get(metaid, None)
        out_path = fs.join(fs.dirname(schema_path), 'meta%s-mode.el' % metaid)

      fp.write(
        u'Creating major mode %s for %s (%s) from %s\n' % (
          out_path, metaid, MetaLang, in_file))

      featkeys = {}
      featvals = {}
      cons_kvs = {}
      allkvs = set()
      secondaries = {}
      ckeys = {}

      for cid, consinfo in consmap.items():
        fks = consinfo.features()
        fvs = consinfo.featvals()
        featkeys.update(fks)
        featvals.update(fvs)
        ckeys.update(consinfo.primary())
        secondaries.update(consinfo.secondaries())
        kvs = set()
        kvs.update(fks.keys())
        kvs.update(fvs.keys())
        allkvs.update(fks.keys())
        allkvs.update(fvs.keys())
        cons_kvs[cid] = kvs

      akeys = filter(
        lambda f: len(f) > 0,
        sorted(
          [key.rstrip(':') for key in
           set(featkeys.keys()).union(set(secondaries.keys()))]))
      fvals = sorted(featvals.keys())

      cons_lines = []
      cons_lines.append('(setq RE (make-hash-table))')
      for cid in sorted(cons_kvs):
        cons_lines.append(
          '(puthash \'%s-%s-kv (concat "\\n\\\\([ \\t]*\\\\)\\\\(" (regexp-opt \'(%s)) "\[ \\t\]\\\\)*") RE)' %
          (metaprefix, cid, ' '.join(['"%s"' % e for e in sorted(cons_kvs[cid])])))
        cid_list = [cid]  # TODO(wmh): Add in cid abbrevs when they exist.
        cons_lines.append(
          '(puthash \'%s-%s-line (concat (gethash \'%s-%s-kv RE) "\\\\(%s\\\\)[ \\t]+\\\\([^ \\t]+\\\\)") RE)' %
          (metaprefix, cid, metaprefix, cid, '\\\\|'.join(cid_list)))
      cons_lines.append(
          '(puthash \'%s-all-kv (concat "\\n\\\\([ \\t]*\\\\)\\\\(" (regexp-opt \'(%s)) "\[ \\t\]\\\\)*") RE)' %
          (metaprefix, ' '.join(['"%s"' % e for e in sorted(allkvs)])))
      cons_lines.append(
        '(puthash \'%s-construct-line (concat (gethash \'%s-all-kv RE) "\\\\(" %s-constructs-re "\\\\)[ \\t]+\\\\([^ \\t]+\\\\)") RE)' %
        (metaprefix, metaprefix, metaprefix))

      kkeys = [
        /# The following are types in Meta(Meta).
        /#  - TODO(wmh): These should only be colored in MetaLanguage files.
        'id', 'xid', 'word', 'num', 'str', 'type', 'expr', 'enum',
        'simple', 'complex',
      ]
      bkeys = set()
      for baselang in metalang.baselist():
        bkeys.update(baselang.keywords())
      fp.write(
        u'  Construct  [%3d]: %s\n' % (len(ckeys), ' '.join(sorted(ckeys))))
      fp.write(
        u'  Attributes [%3d]: %s\n' % (len(akeys), ' '.join(sorted(akeys))))
      fp.write(
        u'  Featvals   [%3d]: %s\n' % (len(fvals), ' '.join(sorted(fvals))))
      fp.write(
        u'  Keywords   [%3d]: %s\n' % (len(kkeys), ' '.join(sorted(kkeys))))
      fp.write(
        u'  Basewords  [%3d]: %s\n' % (len(bkeys), ' '.join(sorted(bkeys))))

      kwds = {'metaprefix': metaprefix}
      replacements = {
        '<CONSTRUCTS-HERE>': ' '.join(['"%s"' % e for e in sorted(ckeys)]),
        '<ATTRIBUTE-KEYS-HERE>': ' '.join(['"%s"' % e for e in sorted(akeys)]),
        '<FEATURE-VALUES-HERE>': ' '.join(['"%s"' % e for e in sorted(fvals)]),
        '<KEYWORDS-HERE>': ' '.join(['"%s"' % e for e in sorted(kkeys)]),
        '<BASEWORDS-HERE>': ' '.join(['"%s"' % e for e in sorted(bkeys)]),
        '<SPACE-BINDINGS-HERE>': '',
        '<SECONDARY-FONT-LOCK-HERE>':
        '(cons (concat "\\\\<" %(metaprefix)s-keywords-re "\\\\>") font-lock-%(metaprefix)s-keyword-face)' % kwds,
        '<TERTIARY-FONT-LOCK-HERE>':
        '(cons (concat "\\\\<" %(metaprefix)s-basewords-re "\\\\>") font-lock-%(metaprefix)s-baseword-face)' % kwds,
        '<CONS-RES-HERE>': '\n'.join(cons_lines),
      }

      if not dryrun:
        dirname = fs.dirname(out_path)
        if not fs.exists(dirname):
          fs.makedirs(dirname)

        fs.chmod(out_path, 0o644)
        ofp = fs.open(out_path, 'w')
        ifp = fs.open(in_file, 'r')
        replace = False
        for line in ifp:
          if not replace:
            if "'MetaLang' and 'metalang'" in line:
              replace = True
          else:
            line = line.replace('metalang', 'meta%s' % metaid)
            line = line.replace('MetaLang', 'Meta(%s)' % MetaLang)

            reps = []
            reps = replacements.keys()
            for rep in reps:
              if rep in line:
                line = line.replace(rep, replacements[rep])
                reps.append(rep)
                del replacements[rep]

          ofp.write(line)
        fs.close(ifp)
        fs.close(ofp)
        fs.chmod(out_path, 0o444)

      return replacements
    test:
      _, metalang, _, metac = test.cachedInfo(metal='meta')
      fs = metac.fs()
      try:
        fp = test.fp()
        fs.setenv('METAROOT', '/tmp')
        _, _, _, meta = test.cachedInfo(metal='meta')
        replacements = metac.generateMajorMode(metalang, fp=fp, dryrun=True)
        /# import pprint
        /# pprint.pprint(replacements)
        test.iseq(
          '"Attribute" "BaseLanguage" "Construct" "FeatureValue" '
          '"File" "MetaLanguage" "Template"',
          replacements['<CONSTRUCTS-HERE>'])
        /#print(fp.getvalue())
      finally:
        fs.unsetenv('METAROOT')
    end method generateMajorMode;

    method runUnitTests #:
      Invoke the test harness on the specified fqns.
    params:
      var fqns : vec<str> #:
        A collection of fully qualified namespaces and/or classes and/or
        methods (to be converted into BUILD unittest targets) or arbitrary
        fully-qualified BUILD targets.
      var verbose : bool = false #:
        If true, print output of tests, etc.
      var basebinary : str = 'default' #:
        The binary to use for the baselang. Can be either an executable path,
        or one of 'default', 'old' or 'new' (semantics is baselang-dependent).
    scope:
      /# TODO(wmh): This needs to be implemented on a per-baselang basis as
      /# a behavior (or at least parts of it).

      /# Set this to true to debug baselang parsing of bazel output.
      debug = False

      if not fqns:
        raise Error('here')

      flags = self.cli()
      baselang = self.baselang()
      fs = self.fs()
      showout = verbose
      showerr = True

      metarep = self.repositoryPath()
      rootdir = fs.join(metarep, self.basePath())
      cwd = rootdir

      suffix = baselang.suffix()
      basel = baselang.id()

      /# TODO(wmh): Clean this up when moved to metacnew
      try:
        rawtests = flags.rawtests
      except AttributeError:
        rawtests = flags.rawtests2

      if basel == 'javascript':
        /# No raw mode for javascript.
        rawtests = False

      rawmap = {
        /# Maps baselang id to shell executable to invoke for raw tests.
        /# If a id does not exist, it means that baselang does not support
        /# raw testing.
        'python': {
          'default': 'python',
          'old': 'python2',
          'new': 'python3',
        }
      }
      if basebinary and basebinary[0] == '/' and fs.exists(basebinary):
        rawexec = basebinary
      else:
        rawexec = rawmap.get(baselang.id(), {}).get(basebinary, None)
        if rawtests and not rawexec:
          print('WARNING: %s does not support raw testing' % baselang.id())
          rawtests = False

      if verbose:
        if rawtests:
          print('Running raw tests (without bazel)')
        else:
          print('Running tests with bazel')

      tester_map = {}
      raw_commands = []
      for fqn in fqns:
        /# Establish target info for the specified fqn.
        newdata = baselang.fqnToTarget(fqn)

        /# Validate fqn
        error = newdata.get('error', None)
        if error:
          print('ERROR: %s' % error)
          continue
        /# pprint.pprint(newdata)
        test_target = newdata['test_target']
        test_arg = newdata.get('test_arg', None)

        /# Establish the command to execute.
        if rawtests:
          /# Do not use bazel
          /#  - TODO(wmh): Should BaseLanguageOopl.fqnToTarget(fqn) compute
          /#    command?
          command = [rawexec, newdata['test_path']]
          if test_arg:
            command.append(test_arg)
        else:
          /# DO use bazel
          command = [
            Compiler.CONFIG['bazel'],
            'test',
            /#'--explain',
            /#'--verbose_explanations',
          ]
          if flags.write_goldens:
            /# https://docs.bazel.build/versions/master/user-manual.html#flag--test_env
            command.append('--test_env=WRITE_GOLDENS=true')
          if test_arg:
            command.append('--test_arg=' + test_arg)
          command.append('--test_output=summary')
          command.append(test_target)

        /# Print out the command being executed.
        if verbose:
          print(' %% cd %s' % cwd)
          print(' %% %s%s' % (' '.join(command), ' | special_filtering'))
          print('=' * 80)

        /# Establish the env to use for the test harness.
        env = copy.copy(fs.environ())
        if baselang.id() == 'python':
          env['PYTHONPATH'] = '.:' + env['PYTHONPATH']
          if flags.write_goldens:
            env['WRITE_GOLDENS'] = 'true'

        /# Execute the command
        p = subprocess.Popen(
          command, cwd=cwd, env=env,
          stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        /# Process the result
        if rawtests:
          stdout, stderr = p.communicate()

          if False:
            print('#' * 80)
            print('TODO(wmh): Add this to the test method for processTestOutput')
            print(stdout)
            print('=' * 80)
            print(stderr)
            print('-' * 80)
            print('cwd = %s' % cwd)
            print('namespace = %s' % newdata['namespace'])
            print('nofilt = %s' % flags.raw)
            print('#' * 80)
          baselang.processTestOutput(
            stdout, stderr, cwd, newdata['namespace'],
            nofilt=flags.raw, verbosity=1 if verbose else 0)
        else:
          try:
            tests = self.parseBazelOutput(
              stdout=p.stdout, stderr=p.stderr, debug=debug)
          except Error as e:
            print('Internal Error: %s' % str(e))
          else:
            if tests:
              self.formatBazelOutput(tests, showout=showout, showerr=showerr)
    test:
      /# Not sure how testable this is.
      pass
    end method runUnitTests;

    method fqnToTarget : tuple<str,str,str,str,vec<str>> #:
      Given a fully qualified namespace/class/method, obtain target info.

      Returns:
       0. the target.
       1. the test target.
       2. the path to a baselang file.
       3. the test path to a baselang file.
       4. the args to pass in to the test binary identified by 0 and 1.
    params:
      var fqn : str #:
        The fqn to obtain info for.
      var debug : bool = false #:
        Turn on debugging.
    scope:
      raise Error(
        '***************** DEPRECATED IN FAVOR OF behavior fqnToTarget')

      fs = self.fs()
      baselang = self.baselang()
      namespace_primary = baselang.config('namespace_primary')
      basel = baselang.id()
      rootdir = fs.realpath(self.workspaceDirectory())

      if debug:
        print('ROOTDIR: %s' % rootdir)

      /# The collection of arguments/flags to pass into the test harness
      test_args = []

      /# Identify the prefix portion of fqn that corresponds to directories
      /# in the filesystem.
      parts = fqn.split('.')
      index = None
      path = rootdir
      for i, part in enumerate(parts):
        newpath = fs.join(path, part)
        if not fs.exists(newpath):
          if debug:
            print('Failed to find %s' % newpath)
          index = i
          break
        if debug:
          print('Found %s' % newpath)
        path = newpath
      namespace_dir = path

      /# At this point, 'path' is the directory containing the namespace portion
      /# of fqn, and parts[index:] represents class/method symbols.
      nmparts = parts[:index]
      if nmparts:
        if namespace_primary:
          if basel == 'python':
            /# The __init__.py file contains the namespace data.
            namespace_path = fs.join(namespace_dir, '__init__.py')
            testspace_path = fs.join(
              metax.oopl.NamespaceConstruct.TestifyName(namespace_dir), '__init__.py')
            final_path = namespace_path
            final_testpath = testspace_path
          else:
            raise Error('Not yet supporting %s' % basel)
        else:
          /# In class-primary languages there is no single file containing
          /# the namespace, so the paths stay as directories.
          namespace_path = namespace_dir
          testspace_path = metax.oopl.NamespaceConstruct.TestifyName(namespace_dir)
          /# These will be modified below if a class name is present in parts.
          final_path = namespace_path
          final_testpath = testspace_path

        if debug:
          print(parts)
          print(index)
          print(nmparts)
          print(final_path)
          print(final_testpath)

        /# The target and test_target are the same for both namespace-primary and
        /# class-primary languages, but are implemented differently (e.g. in
        /# python the test target is a py_test target, in class-primary languages
        /# it is a test_suite of test class targets).
        target = '//%s:%s' % ('/'.join(nmparts), nmparts[-1])
        testspace_base = metax.oopl.NamespaceConstruct.TestifyName(nmparts[-1])
        if len(nmparts) == 1:
          test_target = '//%s:%s' % (testspace_base, testspace_base)
        else:
          test_target = '//%s/%s:%s' % (
            '/'.join(nmparts[:-1]), testspace_base, testspace_base)
      else:
        /# This is clearly not a valid fqn
        target = None
        test_target = None
        indext = None

      if debug:
        print('index = %s' % index)

      if index is not None:
        /# There are some left-over parts of the fqn not matching directories,
        /# so they represent a class (and method).
        if namespace_primary:
          if basel == 'python':
            class_name = parts[index]
            class_path = fs.join(namespace_dir, '.' + class_name + '.py')
          else:
            raise Error('Not yet supporting %s' % basel)
        else:
          class_name = parts[index]
          class_path = fs.join(namespace_path, class_name + baselang.suffix())
          final_path = class_path
          /# TODO(wmh): In addition to BaseLanguageOopl.classSubPath(), there
          /# should be a BaseLanguageOopl.classTestBase() method that returns
          /# the basename of the file containing the tests for a class. Both
          /# classSubPath() and this method could then use that method.
          /# Alternatively, we could just obtain the basename of the result
          /# of a call to baselang.classSubPath(), but we currently need a
          /# class construct ... generalize the method to support fqn.
          baselang_test_infix = '_test' if basel == 'javascript' else ''
          final_testpath = fs.join(
            testspace_path,
            metax.oopl.ClassConstruct.TestifyName(class_name)
            + baselang_test_infix + baselang.suffix())

        if fs.exists(class_path):
          if namespace_primary:
            test_args.append(metax.oopl.ClassConstruct.TestifyName(class_name))
          if len(parts) > index+1:
            test_method = metax.oopl.ExecutableConstruct.TestifyName(parts[index+1])
            if test_args:
              test_args[-1] += '.' + test_method
            else:
              test_args.append(test_method)
        else:
          /# print('ERROR: %s is not a valid class' % '.'.join(parts[:index+1]))
          final_path = None
          final_testpath = None
      return (target, test_target, final_path, final_testpath, test_args)
    test:
      /# This code is deprecated! See behavior fqnToTarget instead.
      return

      def Chk(expected_target, expected_test_target, expected_suffix,
              expected_test_suffix, expected_test_args, res):
        target, test_target, path, test_path, test_args = res
        test.iseq(expected_target, target)
        test.iseq(expected_test_target, test_target)
        test.endswith(expected_suffix, path)
        test.endswith(expected_test_suffix, test_path)
        test.iseqvec(expected_test_args, test_args)

      /# Python
      testpy = test.getTestCompiler(basel='python')

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/python/demo/cards2/__init__.py',
        'testdata/repo/oopl/python/demo/cards2_test/__init__.py',
        [],
        testpy.fqnToTarget('demo.cards2'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/python/demo/cards2/__init__.py',
        'testdata/repo/oopl/python/demo/cards2_test/__init__.py',
        ['CardTest'],
        testpy.fqnToTarget('demo.cards2.Card'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/python/demo/cards2/__init__.py',
        'testdata/repo/oopl/python/demo/cards2_test/__init__.py',
        ['DeckTest.test_shuffle'],
        testpy.fqnToTarget('demo.cards2.Deck.shuffle'))

      /# Javascript
      testjs = test.getTestCompiler(basel='javascript')

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/javascript/demo/cards2',
        'testdata/repo/oopl/javascript/demo/cards2_test',
        [],
        testjs.fqnToTarget('demo.cards2'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/javascript/demo/cards2/Card.js',
        'testdata/repo/oopl/javascript/demo/cards2_test/CardTest_test.js',
        [],
        testjs.fqnToTarget('demo.cards2.Card'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/javascript/demo/cards2/Deck.js',
        'testdata/repo/oopl/javascript/demo/cards2_test/DeckTest_test.js',
        ['test_shuffle'],
        testjs.fqnToTarget('demo.cards2.Deck.shuffle'))

      /# C++
      testcc = test.getTestCompiler(basel='cpp')

      return

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/cpp/demo/cards2',
        'testdata/repo/oopl/cpp/demo/cards2_test',
        [],
        testcc.fqnToTarget('demo.cards2'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/cpp/demo/cards2/Card.js',
        'testdata/repo/oopl/cpp/demo/cards2_test/CardTest_test.js',
        [],
        testcc.fqnToTarget('demo.cards2.Card'))

      Chk(
        '//demo/cards2:cards2',
        '//demo/cards2_test:cards2_test',
        'testdata/repo/oopl/cpp/demo/cards2/Deck.js',
        'testdata/repo/oopl/cpp/demo/cards2_test/DeckTest_test.js',
        ['test_shuffle'],
        testcc.fqnToTarget('demo.cards2.Deck.shuffle'))

    end method fqnToTarget;

    method verifyBazelOutput #:
      Verify bazel output matches expectations.
       - invokes the test code for a given fqn using raw and bazel modes,
         capturing stdout and stderr of each command.
       - verifies that the reverse engineered structure of bazel output
         relative to raw output is as expected.
       - verifies that the specified fqn can be tested using bazel or raw.

      From commandline:
        % meta2 bazel-verify demo.cards2
        % meta2 bazel-verify demo.cards2.Card
        % meta2 bazel-verify demo.cards2.Deck.shuffle
    params:
      var fqn : str;
    scope:
      verbose = True   # show commands if true
      debug = True     # show debugging info if true
      error = None
      fs = self.fs()
      rundir = fs.realpath(self.workspaceDirectory())

      /# TODO(wmh): Convert this to use the fqnToTarget behavior defined on
      /# the BaseLanguageOopl hierarchy, and delete Compiler.fqnToTarget.
      baselang = self.baselang()
      tdata = self.fqnToTarget(fqn)
      test_path = tdata['test_path']
      test_args = tdata['test_args']

      def Run(args, cwd, verbose=False, debug=False):
        if verbose:
          print(' %% cd %s' % cwd)
          print(' %% %s' % ' '.join(args))
        p = subprocess.Popen(
          args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd)
        stdout, stderr = p.communicate()
        if debug:
          print('#' * 70)
          print(stdout)
          print('@' * 70)
          print(stderr)
          print('#' * 70)
        return {'args': args, 'stdout': stdout, 'stderr': stderr}

      /# Modify the environment so that invocations of 'python' will work
      /# properly.
      python_path = fs.getenv('PYTHONPATH')
      fs.setenv('PYTHONPATH', '%s:%s' % (rundir, python_path))

      /# We first invoke the raw test command.
      raw_args = ['python', test_path] + test_args
      rawdata = Run(raw_args, rundir, verbose=verbose, debug=debug)

      /# Now we invoke the bazel test command.
      bazel_args = [
        /# TODO(wmh): Make this bazel path more generalized (hermetic?)
        '/usr/local/bin/bazel',
        'test', '--test_output=all']
      for test_arg in test_args:
        bazel_args.append('--test_arg=%s' % test_arg)
      bazel_args.append(tdata['test_target'])
      bazeldata = Run(bazel_args, rundir, verbose=verbose, debug=debug)

      /# Verify expectations
      /#  - raw_stdout is:
      /#     |<class>.<method>           ... <us> us [<status>]
      /#     |...
      /#
      /#  - raw_stderr is:
      /#     |<status_line>
      /#     |<failure>
      /#     |...
      /#     |
      /#     |----------------------------------------------------------------------
      /#     |Ran 5 tests in 0.002s
      /#     |
      /#     |FAILED (failures=2)
      /#
      /#  - bazel_stdout is:
      /#     |==================== Test output for <test_target>:
      /#     |<raw_stderr>
      /#     |<raw_stdout>
      /#     |================================================================================
      /#     |<summary>
      /#     |Executed <m> out of <n> test: <k> fails locally.
      /#
      /#  - bazel_stderr is:
      /#     |____Loading...
      /#     |____Found 1 test target...
      /#     |blaze: Entering directory `/private/var/tmp/_bazel_wmh/daa2249567ca0e385fd2b02766058831/execroot/python/'
      /#     |FAIL: //demo/cards2_test:cards2_test (see /private/var/tmp/_bazel_wmh/daa2249567ca0e385fd2b02766058831/execroot/python/bazel-out/local-fastbuild/testlogs/demo/cards2_test/cards2_test/test.log)
      /#     |____From Testing //demo/cards2_test:cards2_test:
      /#     |blaze: Leaving directory `/private/var/tmp/_bazel_wmh/daa2249567ca0e385fd2b02766058831/execroot/python/'
      /#     |Target //demo/cards2_test:cards2_test up-to-date:
      /#     |  bazel-bin/demo/cards2_test/cards2_test
      /#     |____Elapsed time: 0.442s, Critical Path: 0.27s
      bazel_stdout_re = Compiler.BAZEL_STDOUT_RE
      m = bazel_stdout_re.match(bazeldata['stdout'])
      if not m:
        error = 'Failed to match bazel stdout against expected regexp!'
        print('#' * 70)
        print(bazeldata['stdout'])
        print('@' * 70)
        print(bazel_stdout_re.pattern)
        print('#' * 70)

      else:
        def Patch(val):
          /# In stderr, generalize the summary line.
          val = re.sub(r'Ran \d+ tests? in \S+', 'Ran <m> tests in <time>', val)
          /# Generalize time references.
          val = re.sub(r' *\d+(?:\.\d+)?\s*(s|us)( |$)', r' <time>\2', val)
          /# Generalize file paths.
          val = re.sub(r'File \"/.*(oopl/python|__main__)/', 'File \"', val)
          return val.rstrip()

        def MultiLineEqual(expected_text, text):
          result = True
          expected_text = Patch(expected_text)
          text = Patch(text)
          if expected_text != text:
            expected_lines = expected_text.splitlines(True)
            lines = text.splitlines(True)
            diff = '\n' + ''.join(difflib.ndiff(expected_lines, lines))
            print('#' * 80)
            print('Found differences between expected and actual text:')
            print(diff)
            print('#' * 80)
            result = False
          return result

        if not MultiLineEqual(rawdata['stdout'], m.group('stdout')):
          error = 'mismatch in stdout'
        elif not MultiLineEqual(rawdata['stderr'], m.group('stderr')):
          error = 'mismatch in stderr'

      if error:
        print('ERROR: %s' % error)
      else:
        /# print('Verified raw vs bazel stdout/stderr for %s' % fqn)
        pass
      return not bool(error)
    test:
      /# TODO(wmh): This test method only works when ./testdata/oopl/<baselang>
      /# is made writeable (these dirs are intentionally made read-only in
      /# testdata/Makefile to that tests do NOT write into it).
      if False:
        testpy = test.getTestCompiler(basel='python')
        testpy.verifyBazelOutput('demo.cards2')
    end method verifyBazelOutput;

    method parseBazelOutput : map #:
      Parse bazel output and analyzing log files.

      Some invariants related to bazel output:
       % cd <<repository_path>>/oopl/python
       % python metax/c_test.py > out.raw 2> err.raw
       % bazel test --test_output=all //metax:c_test > out.bzl 2> err.bzl

      Returns:
        Keys are bazel class test targets, values are maps containing:
          cached: str
            ???
          count: int
            Number of methods in this class test
          dir: str
            The directory containing the logs for this test
          log: str
            The contents of the log for this test
          logpath: str
            The path to the logfile for this class test
          methods: map
            maps class.method to map:
              stdout: str
                the stdout of the test method
              stderr: str
                the stderr of the test method
              us: int
                microseconds taken for this method test
          status: str
            The status of the test as reported during the bazel summary
          status2: str
            The status of the test as reported in the log file
          target: str
            The target of this class test (same as the key storing this map)
          time: str
            The time of the test(s) as reported during the bazel summary
          time2: str
            The time of the test(s) as reported in the log file
    params:
      var stdout : istream = in #:
        A file handle opened for reading on the stdout of the bazel command.
      var stderr : istream = in #:
        A file handle opened for reading on the stderr of the bazel command.
      var logdir : str = null #:
        Where to find the logs produced by bazel. Normally null, in which
        case the dir is obtained from the input stream. Can be set explicitly
        to perform unittests.
      var debug : bool = false #:
        If true, enable debugging output.
    scope:
      tests = {}
      fs = self.fs()
      stdout_lines = stdout.readlines()
      stdout_text = ''.join(stdout_lines)
      stderr_lines = stderr.readlines()
      stderr_text = ''.join(stderr_lines)
      baselang = self.baselang()

      if debug:
        dsep('Compiler.parseBazelOutput Input', subtitle='stdout')
        print(''.join(stdout_lines))
        dsep(delim='-', subtitle='stderr')
        print(''.join(stderr_lines))
        dsep('Compiler.parseBazelOutput Input', end=True)

      /# If syntax errors were found, stdout will contain a line like
      /#    Executed 0 out of 1 test: 1 fails to build.
      if re.search(r' \d+ fail\S+ to build', stdout_text):
        /# TODO(wmh): Perform baseline-to-metaline conversion on stderr!
        print('#' * 37 + ' STDERR ' + '#' * 37)
        print(stderr_text)
        print('#' * 80)
        return None

      if not logdir:
        /# No logdir has been explicitly provided (rarely is), so we need to
        /# establish the log directory from the output.  The stderr of bazel
        /# looks like:
        /#    ____Loading...
        /#    ____Found 8 test targets...
        /#    blaze: Entering directory `/private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/execroot/python/'
        /#    FAIL: //demo/cards2_test:FrenchPackTest (see /private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/execroot/python/bazel-out/local-fastbuild/testlogs/demo/cards2_test/FrenchPackTest/test.log)
        /#    blaze: Leaving directory `/private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/execroot/python/'
        /#    ____Elapsed time: 0.315s, Critical Path: 0.22s
        /# and we can obtain the logdir from the 'blaze: Entering directory' line
        logroot = None
        dir_re = re.compile(
          r'^(?:bazel|blaze): Entering directory `(?P<path>.*)\'$')
        for line in stderr_lines:
          m = dir_re.match(line);
          if m:
            logroot = m.group('path')
            break
        if not logroot:
          print('#' * 80)
          print(''.join(stderr_lines))
          print('#' * 80)
          raise Error('Failed to find a log directory')

      /#pprint.pprint(tests)
      if logdir is None:
        assert logroot is not None
        fastbuild = 'darwin-fastbuild'
        logdir = fs.join(logroot, 'bazel-out', fastbuild, 'testlogs')

      /# Now parse the bazel stdout. The stdout from bazel looks like:
      /#    //demo/cards2_test:CardTest                                     (cached) PASSED in 0.3s
      /#    //demo/cards2_test:Card__MetaTest                               (cached) PASSED in 0.3s
      /#    //demo/cards2_test:FrenchPack__MetaTest                         (cached) PASSED in 0.3s
      /#    //demo/cards2_test:PackTest                                     (cached) PASSED in 0.3s
      /#    //demo/cards2_test:Pack__MetaTest                               (cached) PASSED in 0.3s
      /#    //demo/cards2_test:PileTest                                     (cached) PASSED in 0.3s
      /#    //demo/cards2_test:Pile__MetaTest                               (cached) PASSED in 0.2s
      /#    //demo/cards2_test:FrenchPackTest                                        FAILED in 0.2s
      /#      /private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/execroot/python/bazel-out/local-fastbuild/testlogs/demo/cards2_test/FrenchPackTest/test.log
      /#
      /#    Executed 1 out of 8 tests: 7 tests pass and 1 fails locally.
      /#
      /# and we are interested in the target lines (starting with '//')
      test_re = re.compile(
        r'^(?P<target>//\S+)\s+'
        r'(?P<cached>\(cached\))?\s*'
        r'(?P<status>PASSED|FAILED|NO STATUS)'
        r'(?:\s+in\s+(?P<time>\S+))?'
      )
      for line in stdout_lines:
        m = test_re.match(line)
        if m:
          tests[m.group('target')] = m.groupdict()
        else:
          if line.startswith('//'):
            raise Error('Line "%s" does not match test_re but should' % line[:-1])

      if debug:
        import pprint
        pprint.pprint(tests)

      /# Parse the log out for each target found in tests
      for target in sorted(tests):
        tdata = tests[target]
        subpath = target[2:].replace(':', '/')
        parts = subpath.split('/')
        nmsp = '.'.join(parts[:-1]).replace('_test', '')
        tdata['namespace'] = nmsp
        /# TODO(wmh): This is terribly hacky, and does not work for python, where
        /# the lowest target is namespace (narrowing to class or method requires
        /# use of --test_arg, so assuming subpath contains the class is invalid.
        /# We are not passing in --test_arg values, so in Python we don't know
        /# the class without parsing the methods (paresBazelLog).
        tdata['class'] = parts[-1].replace('Test', '')
        status = tdata['status']
        if status == 'NO STATUS':
          print('Skipping %-30s: %s' % (subpath, status))
          continue

        /# Identify the directory containing log info for this target
        /#   test.cache_status
        /#   test.log
        /#   test.xml
        testdir = fs.join(logdir, subpath)
        tdata['dir'] = testdir
        /#print(fs.listdir(testdir))

        /# Read/cache the test.log file
        logpath = fs.join(testdir, 'test.log')
        tdata['logpath'] = logpath
        logdata = fs.read(logpath)
        tdata['log'] = logdata

        /# Each log file contains results for zero or more methods:
        /#  - how long the test took
        /#  - stderr
        /#  - stdout
        methods = collections.OrderedDict()
        tdata['methods'] = methods

        /# Parse the log file (baselang-specific).
        if False:
          print('#' * 80)
          print('TODO(wmh): Add this to the parseBazelLog test')
          print(logdata)
          print('=' * 80)
          print(tdata)
          print('#' * 80)
        baselang.parseBazelLog(logdata, tdata, debug=debug)
        if debug:
          pprint.pprint(tdata)
      return tests
    test:
      _, _, _, metac = test.cachedInfo()
      fs = metac.fs()
      sample_logs = test.resourcePath('sample_logs')
      stdout = test.fp(unicode(fs.read(fs.join(sample_logs, 'bazel_stdout'))))
      stderr = test.fp(unicode(fs.read(fs.join(sample_logs, 'bazel_stderr'))))
      tests = metac.parseBazelOutput(
        stdout=stdout, stderr=stderr, logdir=sample_logs)
      tdata = tests['//demo/cards2_test:FrenchPackTest']
      for key in ('dir', 'log', 'logpath'):
        del tdata[key]
      test.iseq(
        {'cached': None,
         'class': 'FrenchPack',
         'count': 2,
         'methods': {'FrenchPack.__init__': {'stdout': 'demo.cards2.FrenchPack.__init__ missing unittest\n',
                                             'us': 14},
                     'FrenchPack.asStr': {'stderr': '----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "/private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/bazel-sandbox/e96aaaed-7873-4fb6-a866-0c97391c7dd1-0/execroot/python/bazel-out/local-fastbuild/bin/demo/cards2_test/FrenchPackTest.runfiles/__main__/demo/cards2_test/FrenchPackTest.py", line 13, in test_asStr\n    card = demo.cards2.Card(1, 2)\nAttributeError: \'module\' object has no attribute \'Card\'\n\n----------------------------------------------------------------------',
                                          'stdout': '',
                                          'us': 163}},
         'namespace': 'demo.cards2',
         'status': 'FAILED',
         'status2': 'FAILED',
         'target': '//demo/cards2_test:FrenchPackTest',
         'time': '0.2s',
         'time2': '0.001s'},
        tdata)
    end method parseBazelOutput;

    method formatBazelOutput #:
      Produce output based on parsed bazel output
    params:
      var tests : map #:
        A map as returned from parseBazelOutput.
      var fp : ostream = out #:
        Where to write output.
      var indent : str = '' #:
        What to add before each line.
      var showerr : bool = false #:
        If true, show error output
      var showout : bool = false #:
        If true, show stdout
    scope:
      scope_sep = Context.Tokens()['scope_sep']
      for target in sorted(tests):
        tdata = tests[target]
        namespace_name = tdata['namespace']
        class_name = tdata['class']
        fqcn = namespace_name + scope_sep + class_name
        /# the amount of time taken to run the whole class test is in tenths of
        /# seconds (not great resolution
        clstime = '%6dms' % (1000 * float(tdata['time'][:-1]))
        cstatus = tdata['status']
        cstatus2 = tdata['status2']
        if cstatus2 == 'OK': cstatus2 = ''
        fp.write(
          u'%s%-60s %10s   %-6s\n' %
          (indent, fqcn, clstime, cstatus))
        meths = tdata['methods']
        for cmname in sorted(meths):
          clsname, method_name = cmname.split(scope_sep)
          fqn = namespace_name + scope_sep + cmname
          mdata = meths[cmname]
          mstatus = ' FAIL' if 'stderr' in mdata else ''
          fp.write(
            u'%s  %-60s %8dus%s\n' %
            (indent, method_name, mdata['us'], mstatus))
          if showout:
            stdout = mdata.get('stdout', '')
            if stdout:
              for line in stdout.rstrip().split('\n'):
                fp.write(u'%s     |%s\n' % (indent, line))
          if showerr:
            stderr = mdata.get('stderr', '')
            if stderr:
              for line in stderr.rstrip().split('\n'):
                fp.write(u'%s    E|%s\n' % (indent, line))

        /#pprint.pprint(tdata)
    test:
      _, _, _, metac = test.cachedInfo()
      fs = metac.fs()
      sample_logs = test.resourcePath('sample_logs')
      stdout = test.fp(unicode(fs.read(fs.join(sample_logs, 'bazel_stdout'))))
      stderr = test.fp(unicode(fs.read(fs.join(sample_logs, 'bazel_stderr'))))
      tests = metac.parseBazelOutput(
        stdout=stdout, stderr=stderr, logdir=sample_logs)

      ofp = test.fp()
      metac.formatBazelOutput(tests, fp=ofp)
      test.iseqtext(
        >|"""demo.cards2.Card                                                  300ms   PASSED
        >|  __init__                                                           18us
        >|demo.cards2.Card__Meta                                            300ms   PASSED
        >|demo.cards2.FrenchPack                                            200ms   FAILED
        >|  __init__                                                           14us
        >|  asStr                                                             163us FAIL
        >|demo.cards2.FrenchPack__Meta                                      300ms   PASSED
        >|  __init__                                                           36us
        >|demo.cards2.Pack                                                  300ms   PASSED
        >|  asStr                                                              15us
        >|  shuffle                                                             4us
        >|demo.cards2.Pack__Meta                                            300ms   PASSED
        >|demo.cards2.Pile                                                  300ms   PASSED
        >|demo.cards2.Pile__Meta                                            200ms   PASSED
        >|""",
        ofp.getvalue())

      ofp = test.fp()
      metac.formatBazelOutput(tests, fp=ofp, showerr=True, showout=True)
      test.iseqtext(
        >|"""demo.cards2.Card                                                  300ms   PASSED
        >|  __init__                                                           18us
        >|     |demo.cards2.Card.__init__ missing unittest
        >|demo.cards2.Card__Meta                                            300ms   PASSED
        >|demo.cards2.FrenchPack                                            200ms   FAILED
        >|  __init__                                                           14us
        >|     |demo.cards2.FrenchPack.__init__ missing unittest
        >|  asStr                                                             163us FAIL
        >|    E|----------------------------------------------------------------------
        >|    E|Traceback (most recent call last):
        >|    E|  File "/private/var/tmp/_bazel_wmh/8a547b9529defa4d451cf083bf4156d1/bazel-sandbox/e96aaaed-7873-4fb6-a866-0c97391c7dd1-0/execroot/python/bazel-out/local-fastbuild/bin/demo/cards2_test/FrenchPackTest.runfiles/__main__/demo/cards2_test/FrenchPackTest.py", line 13, in test_asStr
        >|    E|    card = demo.cards2.Card(1, 2)
        >|    E|AttributeError: 'module' object has no attribute 'Card'
        >|    E|
        >|    E|----------------------------------------------------------------------
        >|demo.cards2.FrenchPack__Meta                                      300ms   PASSED
        >|  __init__                                                           36us
        >|     |demo.cards2.FrenchPack__Meta.__init__ missing unittest
        >|demo.cards2.Pack                                                  300ms   PASSED
        >|  asStr                                                              15us
        >|     |demo.cards2.Pack.asStr missing unittest
        >|  shuffle                                                             4us
        >|     |demo.cards2.Pack.shuffle missing unittest
        >|demo.cards2.Pack__Meta                                            300ms   PASSED
        >|demo.cards2.Pile                                                  300ms   PASSED
        >|demo.cards2.Pile__Meta                                            200ms   PASSED
        >|""",
        ofp.getvalue())
    end method formatBazelOutput;

    method filterMetaOutput #:
      Replace baselang-specific file references in ifp with meta-level refs.
    params:
      var baselang : metax.c.BaseLanguage = null #:
        The baselanguage generating the output being processed.
      var cwd : str = null #:
        The directory to use when making relative paths absolute. If None,
        the current working directory is used.
      var ifp : istream = in #:
        The input to be processed.
      var ofp : ostream = out #:
        Where output should be written.
      var debug : bool = false #:
        If True, print out information useful in debugging this method.
      var metakind : str = 'relpath' #:
        How to handle metafiles. Valid values are:
          abbrev: print metapath abbrevs (and the abbrev/path mapping afterwards)
          path: keep original path
          relpath: use relative path
      var basekind : str = 'abbrev' #:
        How to handle base files. Valid values are:
          abbrev: print base path abbrevs (and the abbrev/path mapping afterwards)
          path: keep original path
          relpath: use relative path
          none: do not show
    scope:
      fs = self.fs()
      if baselang is None:
        baselang = self.baselang()

      meta_paths = {}
      base_paths = {}

      metarep = self.repositoryPath()

      def PathAbbrev(paths, path):
        /# Return an abbrev for a path.
        /#
        /# var paths : dict
        /#   The current set of paths with abbrevs.
        /# var path: str
        /#   The path to obtain an abbrev for.
        /#
        /# Returns: str
        /#   The basename of the path, potentially with a one-char addition.
        distinguishers = ('', '@', '#', '$', '%', '^', '&')
        base = fs.basename(path)
        result = None
        for dist in distinguishers:
          basename = base + dist
          if basename in paths:
            if paths[basename] == path:
              /# This basename already exists and is for the desired path,
              /# so it is what we want to return.
              result = basename
              break
            else:
              /# This basename refers to a different path, so we need to
              /# try another basename.
              pass
          else:
            /# This basename/path has never been seen before, so we create
            /# the mapping and return this basename.
            paths[basename] = path
            result = basename
            break
        return result

      if cwd is None:
        cwd = fs.cwd()
      /# TODO(wmh): Should these regexps be placed in the individual
      /# baselang classes (OoplPython, OoplCpp, etc.)?
      LANG_RE = {
        'python': {
          'match': re.compile(
            r'(?P<indent>\s*)File \"(?P<path>[^\"]+)\", line (?P<line>\d+), '
            r'in (?P<method>\S+)'),

          /# This contains a match, and multiple possible replacements.
          'replace': (
            r'File \"[^\"]+\", line (\d+)',
            {'both': '%(metapath)s:%(metaline)d (%(path)s:%(line)s)',
             'meta': '%(metapath)s:%(metaline)d'}),
        },
        'cpp': {
          'match': re.compile(
            r'^(?P<path>[^ :]+):(?P<line>\d+):(?P<column>\d+): (?P<error>.*)'),

          /# This contains a match, and multiple possible replacements.
          'replace': (
            r'^[^ :]+:\d+:\d+:',
            {'meta': '%(metapath)s:%(metaline)d:%(column)s',
             /# TODO(wmh): Fix this ... add in the baselang info.
             'both': '%(metapath)s:%(metaline)d:%(column)s'}),
        },
        'javascript': {
          'match': re.compile(r'^(?P<path>[^:]+):(?P<line>\d+): (?P<error>.*)'),

          /# This contains a match, and multiple possible replacements.
          'replace': (
            r'^[^:]+:\d+:',
            {'both': '%(metapath)s:%(metaline)d (%(path)s:%(line)s)',
             'meta': '%(metapath)s:%(metaline)d'}),
        },
      }
      repeat = fs.getenv('METAFILTECHO', 'false') == 'true'
      if repeat:
        /# ofp.write('META: repeat=%s\n' % repeat)
        pass
      error_re = LANG_RE[baselang.id()]['match']
      matcher, replace_options = LANG_RE[baselang.id()]['replace']
      mappings = {}

      if debug:
        print('#' * 70)
        print(fs.cwd())
        print('matcher = %s' % str(matcher))
        print('repopts = %s' % str(replace_options))
        /# print(fs.join(fs.cwd(), 'metax'))
        /# print(fs.listdir(fs.join(fs.cwd(), 'metax')))
        /#print(fs.listdir('/Users/wmh/src/meta/lib/beta/python/metax'))
        /#fp = fs.open('/Users/wmh/src/wmh/lib/meta/oopl/python/metax/c.py', 'r')
        /#print('HERE with %s' % Mapping)
        /#print('#' * 70)

      while True:
        line = ifp.readline()
        if not line: break

        error_match = error_re.match(line)
        if error_match:
          /# We attempt to map the baselang-level file/line reference to a
          /# meta-level file/line.  The 'line' variable will be modified if
          /# successful, and stays the same if not successful.
          /# Establish the baselang path and line number.
          metadata = error_match.groupdict()
          if debug:
            print('#' * 70)
            sys.stdout.write('Found error match for: ' + line)
            pprint.pprint(metadata)
            print('#' * 70)
          linenum = int(metadata['line'])
          path = metadata['path']
          if path[0] != '/':
            path = fs.normpath(fs.join(cwd, path))

          /# Special case to handle tracebacks encountered during bazel-based
          /# test runs. The paths cited no longer exist by the time this code
          /# is encountered.  However, we assume the bazel test applies to code
          /# found in METAREP, and map the bazel path to an appropriate subpath
          /# of METAREP.
          if '/bazel-sandbox/' in path:
            maintext = '/__main__/'
            idx = path.find(maintext)
            if idx == -1:
              raise Error('Unexpected failed to find %s in %s' % (maintext, path))
            subpath = path[idx + len(maintext):]
            /#print('**** HERE: %s' % subpath)
            path = fs.join(metarep, 'oopl', 'python', subpath)
            /#print('**** NOW: %s' % path)

          /# Obtain the base-to-meta mapping file for 'path'
          realpath = fs.realpath(path)
          map_path = self.mapPath(realpath)

          /# print('PATH: %s\nREAL: %s\nMAP : %s' % (path, realpath, map_path))

          mapfile = mappings.get(map_path, None)
          if mapfile is None:
            if fs.exists(map_path):
              mapfile = self.loadMapFile(map_path)
              mappings[map_path] = mapfile
              if debug:
                ofp.write('META: Loading %s\n' % map_path)
                print('PATH: ' + path)
                print('MAPP: ' + map_path)
            else:
              if debug:
                ofp.write('META: Ignoring %s (no %s)\n' % (path, map_path))
                print('PATH: ' + path)
                print('REAL: ' + realpath)
                print('MAPP: ' + map_path)
              metadata = None

          if mapfile:
            metapath, metaline = mapfile.baseToMeta(linenum)
            /# Establish the metapath string to write.
            if debug:
              print('NOTE: Converting baseline %d to meta gives %s' % (linenum, metaline))
            if metakind == 'path':
              pass
            elif metakind == 'abbrev':
              metadata['metapath'] = PathAbbrev(meta_paths, metapath)
            elif metakind == 'relpath':
              metadata['metapath'] = fs.relpath(metapath)
            else:
              raise Error('Invalid metakind %s' % metakind)

            /# Establish the metapath line number.
            if metaline is None:
              /# print('NO metaline')
              metadata = None
            else:
              metadata['metaline'] = metaline

          if metadata:
            /# Conditionally reformat the file paths
            metapath = metadata['metapath']
            if '/' in metapath and len(metapath) > 20:
              metadata['metapath'] = PathAbbrev(meta_paths, metapath)

            replacer = replace_options['both']
            if basekind is None or basekind == 'none':
              replacer = replace_options['meta']
            elif basekind == 'path':
              pass
            elif basekind == 'relpath':
              metadata['path'] = fs.relpath(path)
            elif basekind == 'abbrev':
              metadata['path'] = PathAbbrev(base_paths, path)
            else:
              raise Error('Invalid basekind %s' % basekind)
            if repeat:
              ofp.write(line)  # newline already present

            /# Rewrite the line based on metadata.
            line = re.sub(matcher, replacer % metadata, line)
        ofp.write(line)  # newline already present

      if meta_paths or base_paths:
        dsep('Meta File Map', delim='-', fp=ofp)
        maxwidth = max([len(k) for k in meta_paths] + [len(k) for k in base_paths])
        for kind, paths in (('meta', meta_paths), ('base', base_paths)):
          if paths:
            for abbrev in sorted(paths):
              /# Used to encode abbrev, but that poses problems in python3:
              /#    TypeError: descriptor 'ljust' requires a 'str' object but received a 'bytes'
              /# If problems occur, find a different solution.
              astr = abbrev.encode('utf8', 'ignore') if sys.version_info.major < 3 else abbrev
              ofp.write(
                '%s = %s\n' % (str.ljust(astr, maxwidth), paths[abbrev]))
        /# too noisy for no real gain
        /# dsep(' End File Map', delim='-', fp=ofp)

    test:
      /# IMPORTANT: Be careful with print out the input lines during testing.
      /# If you are running meta in a mode that invokes metafilt, the printed
      /# lines will get converted by metafilt and look like they are being
      /# converted by this code!
      /#test.fixenv()

      /# TODO(wmh): FIX BROKEN TEST
      /#  - The following is failing because the python file in the
      /#    errors (/Users/wmh/src/meta/lib/beta/python/metax/c.py) has a
      /#    non-existent mapfile
      /#      /Users/wmh/src/meta/src/kernel/.meta/oopl/python/metax/.c.py.map
      /#    Need to provide a way to provide a mocked mapfile.
      /# print('Fix Compiler.filterMetaOutput')
      return

      _, _, _, metac = test.cachedInfo()
      /# TODO(wmh): The following is very fragile ... need to stop relying on
      /# actual filesystem
      ifp = test.fp("""
        >|Traceback (most recent call last):
        >|  File "/Users/wmh/src/meta/bin/meta2", line 40, in <module>
        >|    Main()
        >|  File "/Users/wmh/src/meta/bin/meta2", line 36, in Main
        >|    metac.interact(args)
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 15436, in interact
        >|    self.compileHook()
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 15520, in compileHook
        >|    metafiles, errors, warnings = self.processMeta(metafile_paths, fp=fp)
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 15376, in processMeta
        >|    file_construct.translateMeta()
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 8693, in translateMeta
        >|    child.translateMeta()
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 9279, in translateMeta
        >|    basefiles = self.compilePython(kind='merge', triples=triples)
        >|  File "/Users/wmh/src/meta/lib/beta/python/metax/c.py", line 9428, in compilePython
        >|    print 'HERE with %s' % initpath
        >|TypeError: this is just an example error, don't be misled!
        >|""")
      ofp = test.fp()
      metac.filterMetaOutput(ifp=ifp, ofp=ofp, debug=False)
      out = ofp.getvalue()
      print(out)
      return
      test.iseqtext("""
        >|Traceback (most recent call last):
        >|  File "/Users/wmh/src/meta/bin/meta2", line 40, in <module>
        >|    Main()
        >|  File "/Users/wmh/src/meta/bin/meta2", line 36, in Main
        >|    metac.interact(args)
        >|  ../../../../../meta2/src/kernel/parser.meta:12706 (c.py:15436), in interact
        >|    self.compileHook()
        >|  ../../../../../meta2/src/kernel/parser.meta:13006 (c.py:15520), in compileHook
        >|    metafiles, errors, warnings = self.processMeta(metafile_paths, fp=fp)
        >|  ../../../../../meta2/src/kernel/parser.meta:12646 (c.py:15376), in processMeta
        >|    file_construct.translateMeta()
        >|  ../../../../../meta2/src/kernel/parser.meta:6710 (c.py:8693), in translateMeta
        >|    child.translateMeta()
        >|  ../../../../../meta2/src/kernel/parser.meta:7487 (c.py:9279), in translateMeta
        >|    basefiles = self.compilePython(kind='merge', triples=triples)
        >|  ../../../../../meta2/src/kernel/parser.meta:7536 (c.py:9428), in compilePython
        >|    print 'HERE with %s' % initpath
        >|TypeError: not all arguments converted during string formatting
        >|-------------------------------- Meta File Map ---------------------------------
        >|c.py = /Users/wmh/src/meta/lib/beta/python/metax/c.py
        >|""",
        out)
    end method filterMetaOutput;

    method executeBazelCommand : tuple<int,str,str> #:
      Execute a bazel command and return stdout and sterr.

      Returns:
       0) rc: int
            The return code.
       1) stdout: str
       2) stderr: str
    params:
      var args : vec<str> #:
        The args (not including the bazel command itself).
      var cwd : str = null #:
        The directory to execute within.  If null, current directory is used.
      var dryrun : bool = false #:
        If true, do NOT execute the command, just print it out.
      var quiet : bool = false #:
        If true, do NOT print out the command being executed.
      var prompt : bool = false #:
        If true, prompt before executing the command. If the user indicates
        no execution, the returned values are (1, None, None).
      var show : bool = false #:
        If true, print out stdout and stderr.
    scope:
      return self.executeCommand(
        'bazel', args, cwd=cwd, dryrun=dryrun, quiet=quiet, prompt=prompt,
        show=show)
    test:
      /# TODO(wmh): Fix Compiler.executeBazelCommand test
      if False:
        _, _, _, compiler = self.cachedInfo(metal='oopl')
        test.captureStdout()
        rc, out, err = compiler.executeBazelCommand(['info'])
        test.iseq(0, rc)
        test.contains('committed-heap-size:', out)
        test.iseq('', err)
    end method executeBazelCommand;

    method executeCommand : tuple<int,str,str> #:
      Execute a bazel command and return stdout and sterr.

      Returns:
       0) rc: int
            The return code.
       1) stdout: str
       2) stderr: str
    params:
      var command : str #:
        The command being executed.
      var args : vec<str> #:
        The args (not including the bazel command itself).
      var cwd : str = null #:
        The directory to execute within.  If null, current directory is used.
      var dryrun : bool = false #:
        If true, do NOT execute the command, just print it out.
      var quiet : bool = false #:
        If true, do NOT print out the command being executed.
      var prompt : bool = false #:
        If true, prompt before executing the command. If the user indicates
        no execution, the returned values are (1, None, None).
      var show : bool = false #:
        If true, print out stdout and stderr.
    scope:
      fs = self.fs()
      env = copy.copy(fs.environ())
      extra_env = []

      if command == 'bazel':
        /# We do some special-casing for bazel.
        command = Compiler.CONFIG['bazel']
        /# TODO(wmh): Decide whether to limit the env passed to bazel.  Not
        /# hermetic by relying on existing env!  Should we set env to {}?
        env['CC'] = Compiler.CONFIG['cpp_compiler']
        env['BAZEL_USE_CPP_ONLY_TOOLCHAIN'] = '1'
        extra_env = ['CC', 'BAZEL_USE_CPP_ONLY_TOOLCHAIN']

      allargs = [command] + args

      if not quiet:
        print('NOTE: %sExecuting command:' % ('(NOT) ' if dryrun else ''))
        if cwd:
          print(' %% cd %s' % cwd)
        argstr = ' '.join(args)
        if extra_env:
          print(' %% %s \\' % ' '.join(
            ['%s=%s' % (evar, env[evar]) for evar in extra_env]))
          print('    %s %s' % (command, argstr))
        else:
          print(' %% %s %s' % (command, argstr))
      else:
        if prompt:
          raise Error('Cannot specify quiet and prompt at the same time')

      /# Prompt if prompting desired.
      proceed = not dryrun
      if prompt and proceed:
        while True:
          ans = raw_input('Execute (Y/n)? ').strip().lower()
          if not ans or ans[0] == 'y':
            proceed = True
            break
          elif ans[0] == 'n':
            proceed = False
            break
          else:
            /# Not legal ... reprompt.
            pass

      /# Execute the command.
      if proceed:
        p = subprocess.Popen(
          allargs, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
          env=env, cwd=cwd)
        stdout, stderr = p.communicate()
        rc = p.returncode

        if show:
          if stdout:
            for line in stdout.strip().split('\n'):
              print(' |' + line)
          if stderr:
            for line in stderr.strip().split('\n'):
              print('E|' + line)
      else:
        rc = 1
        stdout = None
        stderr = None

      return rc, stdout, stderr
    test:
      _, _, _, compiler = self.cachedInfo(metal='oopl')
      test.captureStdout()
      rc, out, err = compiler.executeCommand('ls', ['-l'])
      test.iseq(0, rc)
      test.iseq('', err)
    end method executeCommand;

    method parseRepository #:
      Parse a meta repository
    params:
      var repopath : str = null #:
        Which repository to parse. If null, the one from Config() is used.
      var fp : ostream = out #:
        Where output is sent.
    scope:
      if repopath is None:
        repopath = self.repositoryPath()
      fs = self.fs()

      /# We will produce a mapping from basel to namespace id to class id to
      /# map of class data:
      /#   decl: str
      /#     The path of the declaration. For languages with no separation,
      /#     returns the sole file representing the class.
      /#   defn: str
      /#     The path of the definition. e.g. in C++, this is the .cc file.
      /#   map: str
      /#     The map file
      /#   bazel: str
      /#     The file containing the BUILD snippet for the class.

      top_re = re.compile(
        r'^(?:BUILD|README|bazel-|WORKSPACE|CROSSTOOL.*|metastrap|__init__\.py|\.meta__stub).*')
      odir = fs.join(repopath, 'oopl')
      for basel in fs.listdir(odir):
        if basel == 'meta':
          /# Special-case directory
          /# TODO(wmh): Perform special parsing of this dir.
          continue

        if basel != 'python':
          fp.write(u'WARNING: Not yet handling parseRepository on %s\n' % basel)
          continue

        /# TODO(wmh): Ignore basel if it isn't a legal baselang for metaoopl.
        topdir = fs.join(odir, basel)
        for base in fs.listdir(topdir):
          m = top_re.match(base)
          if m:
            /# a bazel-related file
            pass
          else:
            path = fs.join(topdir, base)
            if fs.isdir(path):
              /# Presumably a namespace.
              if base.endswith('_test'):
                /# Ignored here, as it will be handled by the non-test code.
                pass
              else:
                /# print path
                self.parseRepositoryNamespace(base, path, fp=fp)
            else:
              /# We do not expect any other top-level files.
              fp.write(u'ERROR: %s is unexpected\n' % path)
    test:
      _, _, _, metaoopl = test.cachedInfo()
      metaoopl.parseRepository(fp=test.fp())
      out = test.out()
      /# TODO(wmh): Do some checking on the output.
      /# print out
    end method parseRepository;

    method parseRepositoryNamespace : map #:
      Parse a directory representing a namespace.
    params:
      var name : str #:
        The fully qualified name of the namespace
      var path : str #:
        The repository path to parse as a namespace.
      var fp : ostream = out #:
        Where output is sent.
    scope:
      fs = self.fs()

      /# The legal suffixes for this baselang/namespace.
      /#   TODO(wmh): Customize by baselang!
      suffixes = {
        'py': 'defn',
        'py.map': 'map',
        'bld': 'bld',
      }
      /# TODO(wmh): The following should be baselang-specific too.
      /# Be careful with how many things are ignored ... we want the repo
      /# hierarchy to stay clean.
      ignore_re = re.compile('^__init__\.pyc|~$')

      /# Obtain the files in the associated test path.
      testpath = metax.oopl.NamespaceConstruct.TestifyName(path)
      testrelpath = fs.relpath(testpath, path)
      if fs.isdir(testpath):
        testdata = {base: base for base in fs.listdir(testpath)}
        testdata.pop('.', None)
        testdata.pop('..', None)
      else:
        testdata = {}

      /# Record errors here. Maps relpaths to error message.
      errors = {}

      /# Define the skeleton of the return result (for user and test spaces).
      result = {
        'user': {
          'name': name,
          'path': path,
          /# classes: map
          /#   user: map
          /#     defn: str
          /#       The basename of the file containing the definition. In
          /#       baselangs without distinction, this exists but decl does not.
          /#     decl: str
          /#       The basename of the declaration file (only in langs with
          /#       defn/decl distinction).
          /#     map: str
          /#       The basename of the map file
          /#   test: map
          /#     same structure as user
          /#   meta: map
          /#p     same structure as user
          'classes': {},
          /# child namespaces
          'namespaces': {},
        },
        'test': {
          'path': testpath,
          /# classes has same structure as above for user_nmsp['classes']
          'classes': {},
          'basemap': testdata,
        }
      }

      for base in fs.listdir(path):
        subpath = fs.join(path, base)
        if base == 'BUILD':
          /# BUILD (process test BUILD too)
          result['user']['build'] = base
          if testdata.pop(base, None):
            result['test']['build'] = base
        elif base == '__init__.py':
          /# The __init__.py file (process test __init__.py too)
          /# TODO(wmh): This is only for python!
          result['user']['src'] = base
          if testdata.pop(base, None):
            result['test']['src'] = base
        elif ignore_re.search(base):
          /# This file is explicitly to be ignored.
          pass
        elif fs.islink(subpath):
          /# A symlink ... ignored?
          fp.write(u'SKIPPING link %s\n' % subpath)
        else:
          /# This is either a class file, executable, or an error.
          self.parseRepositoryFile(
            base, suffixes, errors, result['user'], testnmspmap=result['test'],
            fp=fp)
          
      /# testdata contains all unprocessed files in the test namespace
      /# directory associated with this namespace directory.
      /#  - process each file as if it were a class file, populating
      /#    the test namespace result.
      for testbase in testdata.keys():
        if self.parseRepositoryFile(
          testbase, suffixes, errors, result['test'], fp=fp
        ):
          del testdata[testbase]

      if testdata:
        for testbase in testdata:
          testfull = fs.join(testpath, testbase)
          testrelpath = fs.relpath(testfull, path)
          errors[testrelpath] = 'unrecognized test file'

      /# Delete empty entries from our result.
      for nmsp in result.values():
        for key in ('classes', 'basemap', 'namespaces'):
          if key in nmsp and not nmsp[key]:
            /# The key exists but is empty, so we remove it.
            del nmsp[key]

      if errors:
        result['errors'] = errors
        fp.write(u'#' * 80 + '\n')
        fp.write(u'%s: unrecognized files:\n' % path)
        for subpath in sorted(errors):
          fp.write(u'  %s\n' % subpath)
          fp.write(u'    %s\n' % errors[subpath])
        fp.write(u'#' * 80 + '\n')

      return result
    test:
      _, _, _, metaoopl = test.cachedInfo()
      root = metaoopl.repositoryPath()
      fs = metaoopl.fs()
      path = fs.join(root, 'oopl', 'python', 'metax', 'root')
      res = metaoopl.parseRepositoryNamespace('metax.root', path)
      homedir = fs.getenv('HOME')
      test.iseqmap(
        {
          'test': {
            'bld': '.__init__.bld',
            'build': 'BUILD',
            'map': '.__init__.py.map',
            'path': path + '_test',
            'src': '__init__.py',
          },
          'user': {
            'bld': '.__init__.bld',
            'build': 'BUILD',
            'classes': {
              'Error': {
                'user': {
                  'defn': '.Error.py',
                  'map': '.Error.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/root.meta',
                }
              },
              'InternalError': {
                'user': {
                  'defn': '.InternalError.py',
                  'map': '.InternalError.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/root.meta',
                }
              },
              'Object': {
                'meta': {
                  'defn': '.ObjectMeta.py',
                  'map': '.ObjectMeta.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/root.meta',
                },
                'test': {
                  'defn': '../root_test/.ObjectTest.py',
                  'map': '../root_test/.ObjectTest.py.map',
                },
                'user': {
                  'defn': '.Object.py',
                  'map': '.Object.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/root.meta',
                },
              },
              'ObjectMetaRoot': {
                'user': {
                  'defn': '.ObjectMetaRoot.py',
                  'map': '.ObjectMetaRoot.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/root.meta',
                },
              },
            },
            'map': '.__init__.py.map',
            'name': 'metax.root',
            'path': path,
            'src': '__init__.py',
          },
        },
        res, width=160)

      path2 = fs.join(root, 'oopl', 'python', 'metax', 'test')
      res2 = metaoopl.parseRepositoryNamespace('metax.test', path2)
      test.iseqmap(
        {
          'test': {
            'bld': '.__init__.bld',
            'build': 'BUILD',
            'map': '.__init__.py.map',
            'path': '/Users/wmh/src/wmh/lib/meta/oopl/python/metax/test_test',
            'src': '__init__.py',
          },
          'user': {
            'bld': '.__init__.bld',
            'build': 'BUILD',
            'classes': {
              'FakeFcntl': {
                'meta': {
                  'defn': '.FakeFcntlMeta.py',
                  'map': '.FakeFcntlMeta.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                },
                'test': {
                  'defn': '../test_test/.FakeFcntlTest.py',
                  'map': '../test_test/.FakeFcntlTest.py.map',
                },
                'user': {
                  'defn': '.FakeFcntl.py',
                  'map': '.FakeFcntl.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                }
              },
              'StubHolder': {
                'meta': {
                  'defn': '.StubHolderMeta.py',
                  'map': '.StubHolderMeta.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                },
                'test': {
                  'defn': '../test_test/.StubHolderTest.py',
                  'map': '../test_test/.StubHolderTest.py.map',
                },
                'user': {
                  'defn': '.StubHolder.py',
                  'map': '.StubHolder.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                },
              },
              'TestCase': {
                'meta': {
                  'defn': '.TestCaseMeta.py',
                  'map': '.TestCaseMeta.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                },
                'resources': {
                  'cipherfile': '.__resources/TestCase_cipherfile',
                  'entry_mre': '.__resources/TestCase_entry_mre',
                },
                'test': {
                  'defn': '../test_test/.TestCaseTest.py',
                  'map': '../test_test/.TestCaseTest.py.map',
                },
                'user': {
                  'defn': '.TestCase.py',
                  'map': '.TestCase.py.map',
                  'metapath': homedir + '/src/meta/src/kernel/test.meta',
                },
              },
            },
            'map': '.__init__.py.map',
            'name': 'metax.test',
            'path': '/Users/wmh/src/wmh/lib/meta/oopl/python/metax/test',
            'src': '__init__.py',
          },
        },
        res2, width=160)

      path3 = fs.join(root, 'oopl', 'python', 'metax')
      res3 = metaoopl.parseRepositoryNamespace('metax', path3)
      test.isfalse('errors' in res3)
    end method parseRepositoryNamespace;

    method parseRepositoryFile : bool #:
      Parse a file within a namespace.
       - class source/header file
       - .map or .bld file
       - otherwise unknown

      Returns:
        true if file parsed, false if not recognized.
    params:
      var base : str #:
        is a file within the namespace directory being parsed
      var suffixes : map #:
        The legal suffixes for current namespace and baselang.
      var errors : map #:
        Maps full paths to error messages.
      var nmspmap : map #:
        the namespace dict for the path being parsed. May be either
        user data or test data depending on where it is called from.
      var testnmspmap : map = null #:
        the test namespace (if we are processing user namespace) or null.
      var fp : ostream = out #:
        Where output is sent.
    scope:
      result = False   # true if we successfully identified a file
      fs = self.fs()
      path = nmspmap['path']
      fullpath = fs.join(path, base)
      testdirmap = testnmspmap['basemap'] if testnmspmap else None

      m = Compiler.NamespaceFileRE.match(base)

      if fs.isdir(fullpath):
        /# We have a subdirectory.
        if base == RESOURCES_SUBDIR:
          /# Parse resource files.
          for resbase in fs.listdir(fullpath):
            parts = resbase.split('_', 1)
            if len(parts) == 2:
              clsname, resname = parts
              rescls = nmspmap['classes'].get(clsname, None)
              if rescls:
                /# TODO(wmh): rescls consists of the following:
                /#    meta: map
                /#    user: map
                /#    test: map
                /#    resources: map
                /# The first three are similar-maps, while 'resources' is
                /# different. Should we be putting 'resources' into 'user'
                /# instead?
                rescls.setdefault('resources', {})[resname] = '%s/%s' % (
                  base, resbase)
              result = True
            else:
              errors[fs.join(base, resbase)] = 'Unknown resource file'
        elif base == SPECIAL_CHILD_DIR:
          /# We've found a '.meta' file .. that is broken!
          errors[base] = 'Should not appear in repo!'
        elif base == PYCACHE:
          /# Ignore __pycache__: https://www.python.org/dev/peps/pep-3147/
          result = True
        else:
            /# We assume this is a recursive namespace
          if base.endswith('_test') or not testnmspmap:
            /# If we are in a test namespace, we do not call
            /# parseRepositoryNamespace().
            /#
            /# confusingly, we are processing a user namespace if testnmspmap
            /# is set, and are parsing a test namespace if it isn't set.
            pass
          else:
            subname = nmspmap['name'] + '.' + base
            nmspmap['namespaces'][base] = self.parseRepositoryNamespace(
              subname, fullpath, fp=fp)
      elif m:
        data = m.groupdict()

        cname = data['name']
        suffix = data['suffix']
        ckey = 'user'
        if cname.endswith('Meta'):
          ckey = 'meta'
          cname = cname[:-4]
        subkey = suffixes.get(suffix, None)

        if cname == '__init__':
          /# namespace info.
          nmspmap[subkey] = base
          if testdirmap and testdirmap.pop(base, None):
            testnmspmap[subkey] = base
          result = True
        elif subkey:
          /# this is a defn or map file for a class (ckey indicates meta or user)
          /#  - we need to check for an associated test class in testdata
          clsinfo = nmspmap['classes'].setdefault(cname, {}).setdefault(ckey, {})
          clsinfo[subkey] = base

          /# If we have a map file, parse it.
          if subkey == 'map':
            metapath, meta_exists = self.basePathToMeta(None, map_path=fullpath)
            if not meta_exists:
              /# The .meta file specified in the map file does not exist,
              /# which means that this entire class is stale and should be
              /# deleted!
              errors[path] = '%s references non-existent %s' % (base, metapath)
            else:
              clsinfo['metapath'] = metapath

          if testnmspmap:
            /# This means nmspmap refers to user data (not test data).
            tname = '%s%sTest.%s' % (data['dot'], cname, suffix)
            tbase = testdirmap.pop(tname, None)
            if tbase:
              fs = self.fs()
              tpath = fs.join(testnmspmap['path'], tbase)
              nmspmap['classes'].setdefault(cname, {}).setdefault('test', {})[subkey] = (
                fs.relpath(tpath, path))
          result = True
        else:
          errors[base] = 'unrecognized class file'
      else:
        ok = False
        if fs.isfile(fullpath) and fs.is_x(fullpath):
          with open(fullpath, 'r') as rfp:
            contents = rfp.read()
          if METAX_ENTRY_NAME in contents:
            ok = True
            nmspmap.setdefault('executables', []).append(base)
          else:
            /# print('WARN: Failed to find %s in %s' % (METAX_ENTRY_NAME, fullpath))
            pass
        if not ok:
          errors[base] = 'unrecognized namespace file'
      return result
    test:
      _, _, _, metaoopl = test.cachedInfo()
      root = metaoopl.repositoryPath()
      fs = metaoopl.fs()
      path = fs.join(root, 'oopl', 'python', 'metax', 'root')
      suffixes = {'bld': 'bld', 'py': 'defn', 'py.map': 'map'}
      errors = {}

      /# Note that parseRepositoryNamespace() invokes parseRepositoryFile()
      /# for each file found in the namespace dir.
      nmspmaps = metaoopl.parseRepositoryNamespace('metax.root', path)
      nmspmap = nmspmaps['user']

      /# Parse .NewClass.py, which should add an entry to nmspmap['classes']
      test.iseq(
        ['Error', 'InternalError', 'Object', 'ObjectMetaRoot'],
        sorted(nmspmap['classes'].keys()))
      res = metaoopl.parseRepositoryFile(
        '.NewClass.py', suffixes, errors, nmspmap)
      test.iseq(
        ['Error', 'InternalError', 'NewClass', 'Object', 'ObjectMetaRoot'],
        sorted(nmspmap['classes'].keys()))
      test.iseq(
        {'user': {'defn': '.NewClass.py'}},
        nmspmap['classes']['NewClass'])

      /# TODO(wmh): There are many additional paths to be tested.
    end method parseRepositoryFile;

    method generateUmlDiagram #:
      Generate a UML diagram (using graphviz dot) for all metafiles.
    params:
      var metafiles : vec<MetaFile>;
      var destpath : str #:
        Where to write the dot output.
      var config : map #:
        Specifies information about how and what should be displayed in the UML.
        Legal keys are:
          field: dict
            name: str
              Only those fields whose name matches the regexp are chosen.
            visibility: restr
              Only those fields whose visibility matches the regexp are chosen.
            level: restr
              Only those fields whose level matches the regexp are chosen.
          method: dict
            name: str
              Only those fields whose name matches the regexp are chosen.
            visibility: restr
              Only those methods whose visibility matches the regexp are chosen.
            level: restr
              Only those methods whose level matches the regexp are chosen.
            params: str = 'none'
              One of
                none = do not show params
                required-names = show required names, no types, no optionals
                required = show required names and types, no optionals
                all-names = show required and optional names, no types or defaults
                all = show required and optional names and types, no defaults
                all* = show required and optional names and types, with default vals
      var show_user : bool = true #:
        Show user classes.
      var show_meta : bool = false #:
        Show metaclasses. If false, means do not show user-defined meta
        classes either.
      var show_test : bool = false #:
        Show testclasses. If false, means do not show user-defined test
        classes either.
      var display : bool = false #:
        If True, display the generated UML image.
      var verbose : bool = false #:
        If true, print out details of actions performed.
      var size : str = '8' #:
        Number of inches of width and height. Can be comma-separated, or
        single value.
        TODO(wmh): Use a more sensible unit.
    scope:
      debug = False
      fs = self.fs()

      /# See
      /#   http://www.ffnn.nl/pages/articles/media/uml-diagrams-using-graphviz-dot.php
      /#   https://fsteeg.wordpress.com/2006/11/17/uml-class-diagrams-with-graphviz/
      /# for a discussion on how we can use graphviz dot to render UML class
      /# diagrams.
      /#
      /# See also
      /#   http://www.umlgraph.org/
      /#   https://www.graphviz.org/doc/info/attrs.html
      /#   http://rich-iannone.github.io/DiagrammeR/graphviz_and_mermaid.html (more for the visualization of graphviz options than for DiagrammeR)
      /#   http://rich-iannone.github.io/DiagrammeR/img/X11_Color_Names.png
      basepath, suffix = fs.splitext(destpath)
      if suffix != '.dot':
        /# We do this to ensure the person didn't accidentaly type something like:
        /#   % metac -U env.meta root.meta
        /# which would tromp over env.meta. Should be
        /#   % metac -U out.dot env.meta root.meta
        print('ERROR: UML output file "%s" must end with .dot' % (
          destpath))
        return False
      impath = basepath + '.png'

      /# IMPLEMENTATION:
      /#  - We need to know:
      /#    - for each class
      /#      - what its base name is
      /#      - what namespace it is in
      /#      - what its parent(s) is
      /#      - which fields to display
      /#      - which methods to display
      /#      - the associations this class has with other classes
      baselang = self.baselang()

      /# Create a mapping from namespace fqn to dict containing:
      /#   construct: NamespaceConstruct
      /#   scope: metax.attr.ComplexBlock
      /#   classes: collections.OrderedDict()
      /#     Maps class ids to 
      /#
      /# Also create a mapping from class fqn to dict containing:
      /#    name: str
      /#    fqn: str
      /#    namespace: ?  (str or NamespaceConstruct?)
      /#    parent: ?  (str or ClassConstruct?)
      /#    construct: ClassConstruct
      /#    field: collections.OrderedDict()
      /#      name: str
      /#      construct: FieldConstruct
      /#      visibility: str
      /#      level: str
      /#      type: Type
      /#    method: collections.OrderedDict()
      /#      name: str
      /#      construct: MethodConstruct
      /#      visibility: str
      /#      level: str
      /#      type: Type
      allclasses = self.classes()
      namespaces = {}
      classes = {}

      accre = re.compile(r':(get|set)')

      for metafile in metafiles:
        /# Per-metafile processing
        filec = metafile.construct()
        for namespace in filec.attrval('scope:', default=None) or []:
          /# Per-namespace processing
          if namespace.kind() != 'namespace': continue
          nscope = namespace.attr('scope:', default=REQUIRED)
          nclasses = {}
          for klass in nscope.value():
            /# Per-class processing
            if klass.kind() != 'class': continue
            variant = klass.variant()
            if variant == 'user' and not show_user: continue
            if 'meta' in variant and not show_meta: continue
            if 'test' in variant and not show_test: continue
            cfqn = klass.fqn()
            cid = klass.id()

            fields = collections.OrderedDict()
            methods = collections.OrderedDict()
            parents = klass.parentclasses()
            parentinfo = parents[0] if parents else {}
            pfqn = parentinfo.get('metafqn', parentinfo.get('fqn', None))
            cinfo = {
              'name': cid,
              'fqn': cfqn,
              'parent': pfqn,
              'namespace': namespace,
              'construct': klass,
              'field': fields,
              'method': methods,
            }
            for classic in klass.attrval('scope:', default=None) or []:
              kind = classic.kind()
              if kind == 'field':
                fmdata = fields
                fmtype = classic.attrval('type', default=None)
                /# TODO(wmh): Decide how field visibility is going to be
                /# handled. The visibility of the state itself is private by
                /# default, but we probably need to allow for it to be protected
                /# or public.
                visibility = 'private'
              elif kind == 'method':
                fmdata = methods
                fmtype = classic.attrval('returns', default=None)
                visibility = classic.attrval('visibility')
              else:
                continue
              fmdata = cinfo[kind]
              efqn = classic.fqn()
              location = classic.attrval('location')
              attrkind = classic.attrval('kind')
              fmdata[efqn] = {
                'name': classic.id(),
                'construct': classic,
                'visibility': visibility,
                'level': location,
                'type': fmtype,
              }
            classes[cfqn] = cinfo
            nclasses[cid] = cinfo
          ninfo = {
            'construct': namespace,
            'scope': nscope,
            'classes': nclasses
          }
          namespaces[namespace.fqn()] = ninfo

      /# Add an entry to 'classes' for the root class of the baselang.
      /#  - TODO(wmh): Generalize to all baselangs.
      if baselang.id() == 'python':
        classes['object'] = {
          'name': 'object', 
          'fqn': 'object',
          'construct': None,
          'field': {},
          'method': {},
          'namespace': None,
          'parent': None,
        }

      associnfo = config.pop('assocs') if 'assocs' in config else {}
      /# print('associnfo: %s' % str(associnfo))

      def Match(value, restr):
        /# Determine if a value matches a restr.
        if not restr or restr == 'false':
          result = False
        elif restr == 'true':
          result = True
        else:
          r = re.compile(restr)
          result = r.search(value)
        return result

      def Matches(construct, config, level, visibility, debug=False):
        /# Determine if a construct matches a config.
        /#  - if config is empty, we assume no match.
        /#  - if any item in the config fails, it means no match
        /#  - only if all items in the config match is it a match.
        if not config: return False
        kind = construct.kind()
        kindid = construct.kindid()
        cfg = config.get(kind, None)
        if cfg is None: return False
        fails = []
        data = {'name': construct.id(), 'level': level, 'visibility': visibility}
        for key in data:
          if key in cfg:
            value = data[key]
            if not Match(value, cfg[key]):
              fails.append(
                '%s has %s %s !~ %s' % (kindid, key, value, cfg[key]))
        if debug and fails:
          print('#' * 40)
          print(construct.kindid())
          print('=' * 40)
          pprint.pprint(fails)
        return len(fails) == 0

      def MethodSignature(method, cfg):
        result = accre.sub('', method.id())
        if result == '__init__':
          klass = method.ancestor('class')
          result = klass.id()
        ptype = cfg.get('params', 'none')
        plist = []
        if ptype != 'none':
          params = method.attrval('params:', default=None) or []
          reqonly = 'required' in ptype
          namesonly = '-names' in ptype
          for var in params:
            default = var.attrval('default', default=None)
            if default is not None and reqonly:
              /# We've finished parsing all the required args and are not to
              /# include optional args.
              plist.append('...')
              break
            psig = var.id()
            if not namesonly:
              ptype = var.attrval('type')
              psig += ' : ' + ptype.raw()
              /# TODO(wmh): Fix this ... all* isn't a type in v2
              if default is not None and ptype == 'all*':
                psig += ' = ' + default
            plist.append(psig)
          result += '(' + ', '.join(plist) + ')'
        return result

      def DotSafeId(name):
        /# Convert an identifier to one that is safe for use in graphviz dot.
        return name.replace('.', '_')

      def DotSafeField(field):
        /# Convert a field (an entry within a record-valued label) to dot safety.
        return field.replace('<', '\\<').replace('>', '\\>').replace('|', '\\|')

      vismap = {
        /# http://www.uml-diagrams.org/visibility.html
        'pubget': '+',
        'public': '+',
        'protected': '#',
        'private': '-',
        'package': '~',
      }

      /# Each element is a dict containing
      /#   src: str (required)
      /#     a fully qualified class name
      /#   dest: str (required)
      /#     a fully qualified class name
      /#   edge: dict (optional)
      /#     graphviz edge key/value pairs. Common keys include:
      /#       arrowtail
      /#       headlabel
      /#       taillabel
      /#       constraint
      /#     See http://www.graphviz.org/doc/info/attrs.html for details
      associations = []

      /# Analyze namespaces, classes, methods and fields looking for UML-related
      /# constructs.  This includes:
      /#  - inheritance relationships between classes
      /#  - the collection of fields defined within each class (and their
      /#    types and visibility)
      /#  - the collection of methods defined within each class (and their
      /#    return types, visibility and args).
      /#  - the associations between classes:
      /#     - any field whose type is a non-library class defines an
      /#       association between the class containing the field and the
      /#       class identified by the type of the field.
      /#        - whether it is composition or delegation
      for nmsp, nmdata in namespaces.items():
        namespace = nmdata['construct']
        if debug:
          print('  ' + namespace.kindid())
        for clsname, clsdata in nmdata['classes'].items():
          classy = clsdata['construct']
          if debug:
            print('    ' + classy.kindid())
          clsdata['uml_fields'] = []
          clsdata['uml_methods'] = []
          for fmkind in ('field', 'method'):
            for fmid, fmdata in clsdata[fmkind].items():
              fmcons = fmdata['construct']
              vis = fmdata['visibility']
              level= fmdata['level']
              if Matches(fmcons, config, level, vis):
                if debug:
                  print('      ' + fmcons.kindid())
                fmtype = fmdata['type']
                if fmtype is None:
                  print('WARNING: No type for %s' % fmcons.kindfqn())
                  fmtype = Type.Instance('void')

                /# Establish any extra text to appear after the name
                /# before the type.
                extra = ''
                if fmkind == 'field':
                  signature = fmcons.id()
                elif fmkind == 'method':
                  /# TODO(wmh): Conditionally add parameters (or params plus
                  /# types). Various config options:
                  /#  - do not show any params
                  /#  - show only required param names
                  /#  - show only required param names and types
                  /#  - show only required param names and types, with a
                  /#    special indicator if there are optional params.
                  /#  - show positional and optional names (with indicator
                  /#    for optional names).
                  /#  - show positional and optional names and types
                  /#  - show positional and optional names and types, and
                  /#    default values for optional params.
                  signature = MethodSignature(fmcons, config.get(fmkind, None))

                /# Indicate the level.
                if level == 'meta':
                  signature = '<u>' + signature + '</u>'

                /# Add an entry for this field/method.
                umlkey = 'uml_' + fmkind + 's'
                fmtypestr = '' if fmtype.raw() == 'void' else ' : %s' % fmtype.raw()
                clsdata[umlkey].append(
                  '%s %s%s' % (vismap[vis], signature, fmtypestr))

              if fmkind == 'field':
                /# We analyze the fields looking for references to other
                /# classes, which indicates an association
                fmtype = fmdata['type']
                basetype = fmtype.base()
                if fmtype.isPrimitive():
                  pass
                elif fmtype.isNative():
                  /# TODO(wmh): For all container-based native types, we need
                  /# to see if the elements are class types.
                  if basetype == 'vec':
                    /# Check if elements are class types.
                    if False:
                      print('FixMe: Currently ignoring %s.%s.%s : %s' % (
                        nmsp, clsname, fmid, fmtype.raw()))
                  elif 'map' in basetype:
                    /# Check if values are class types.
                    if False:
                      print('FixMe: Currently ignoring %s.%s.%s : %s' % (
                        nmsp, clsname, fmid, fmtype.raw()))
                else:
                  /# Not primitive and not native means class type.
                  assoc_fqn = fmtype.base()
                  if assoc_fqn is None:
                    /# The type is not legal. Could be a disjunctive type.
                    assoc_nmsp = None
                    assoc_name = None
                  else:
                    assoc_nmsp, assoc_name = assoc_fqn.rsplit('.', 1)

                  good = assoc_fqn in classes
                  if debug:
                    print('%s%s.%s.%s : %s [%s]' % (
                      '*' if good else ' ',
                      nmsp, clsname, fmid, fmtype.raw(), assoc_fqn))
                  if good:
                    edge = {
                      'arrowtail': 'odiamond',
                      'taillabel': '"1"',
                      'headlabel': '"0..1"' if fmtype.isPtr() else '"1"',
                      'label': '"%s"' % fmid,
                    }
                    associations.append(
                      {'src': DotSafeId(clsdata['fqn']),
                       'dest': DotSafeId(assoc_fqn),
                       'edge': edge})

      /# Now create the .dot file.
      /#  - See http://www.graphviz.org/doc/info/attrs.html for details on what
      /#    attributes exist for nodes, edges, etc.
      if ',' not in size: size = '%s,%s' % (size, size)
      with fs.open(destpath, 'w') as fp:
        fp.write("""
          >|digraph G {
          >|  fontname = "Bitstream Vera Sans"
          >|  fontsize = 8
          >|  size = "%(size)s!"
          >|
          >|  node [
          >|    fontname = "Bitstream Vera Sans"
          >|    fontsize = 8
          >|    shape = "record"
          >|    style = "filled"
          >|    fillcolor = "gray95"
          >|    height = 0.25
          >|  ]
          >|
          >|  edge [
          >|    fontname = "Bitstream Vera Sans"
          >|    fontsize = 8
          >|  ]
          >|""" % {'size': size})
        /# Print out the namespaces and each class within them.
        max_entries = 50
        for nmsp in sorted(namespaces):
          fp.write('\n')
          fp.write('  subgraph cluster_%s {\n' % DotSafeId(nmsp))
          fp.write('    label = "Namespace %s"\n\n' % nmsp)
          cmap = namespaces[nmsp]['classes']
          for name in sorted(cmap):
            clsdata = cmap[name]

            /# TODO(wmh): Is this restricting of sizes necessary any more?
            fields = clsdata['uml_fields']
            if len(fields) > max_entries:
              fields = fields[:max_entries-1] + ['...']
            methods = clsdata['uml_methods']
            if len(methods) > max_entries:
              methods = methods[:max_entries-1] + ['...']

            fqn = clsdata['fqn']
            fp.write('    %s [\n' % DotSafeId(fqn))

            /# Now render the label for this class. At the very least, it contains
            /# the name of the class, but may also include 0 or more fields and
            /# 0 or more methods.
            /#
            /# TODO(wmh): Consider switching to using HTML-like labels per
            /#   http://www.graphviz.org/doc/info/shapes.html/#html
            /# They are more flexible relative to the more concise format in
            /#   http://www.graphviz.org/doc/info/shapes.html/#record
            /# for example:
            /#   HTML supports <u>, <s>, etc. whereas I don't think it is possible
            /#   to underline or strikethru in record labels without html syntax.
            /# but there are some questions to resolve:
            /#  - how to specify newlines in a particular row of the table?
            /#    Presumably just <br>?
            /#  -
            if fields or methods:
              fp.write(
                /# NOTE(wmh): It is apparently necessary to end the fields and
                /# mehods lists with a \l so that the last field doesn't get
                /# centered instead of left-justified.  This is probably a bug in
                /# graphviz that will get fixed ... consider testing this later
                /# (2016/08/28).
                '      label = "{%s|%s\l|%s\l}"\n' %
                (name,
                 '\\l'.join([DotSafeField(field) for field in fields]),
                 '\\l'.join([DotSafeField(method) for method in methods])))
            else:
              fp.write('      label = "{%s}"\n' % name)
            fp.write('    ]\n')
          fp.write('  }\n')

        /# Find all classes that are in the inheritance hierarchy that we
        /# haven't created nodes for.
        missing = []
        for fqn in sorted(classes):
          cmap = classes[fqn]
          fqparent = cmap['parent']
          if fqparent and fqparent not in classes:
            if fqparent not in missing:
              /# Remeber the parent
              missing.append(fqparent)
              pklass = allclasses.get(fqparent, None)
              if pklass:
                ppcs = pklass.parentclasses()
                pc = ppcs[0] if ppcs else None
                ppc = pc['fqn'] if pc else None
                /# print(' *** MISSING %s = %s' % (fqparent, ppc))
                classes[fqparent] = {
                  'name': fqparent, 'fqn': fqparent, 'parent': ppc}
              else:
                print('WARNING: Failed to kind parent "%s" for "%s"' % (fqparent, fqn))

        /# Create an 'external' subgraph and add all missing classes to it.
        fp.write('  subgraph cluster_external {\n')
        fp.write('    label = "Classes not in this compilation"\n')
        for fqn in missing:
          fp.write('    %s [\n' % DotSafeId(fqn))
          fp.write('      label = "{%s}"\n' % fqn)
          fp.write('    ]\n')
          /# Remember that we've generated this class.
          classes[fqn] = {
            'name': fqn, 'fqn': fqn, 'parent': None}
        fp.write('  }\n')

        /# Now specify the parent/child inheritance relationships.
        fp.write("""
          >|  edge [
          >|    dir = "back"
          >|    arrowtail = "empty"
          >|  ]
          >|""")
        for fqn in sorted(classes):
          cmap = classes[fqn]
          parent = cmap['parent']
          if parent is None:
            pass
          elif parent in classes:
            fp.write('  %s -> %s\n' % (DotSafeId(parent), DotSafeId(fqn)))
          else:
            /# The 'parent' is probably a baselang parent not defined in Meta.
            /# We dump it verbatim.
            fp.write('  %s -> %s\n' % (DotSafeId(parent), DotSafeId(fqn)))
            /# print('WARNING: %s has unknown parent %s' % (fqn, parent))

        /# Now specify associations.
        if False:
          for assoc in associations:
            edgecfg = assoc.get('edge', {})
            fp.write(
              '  %s -> %s [%s]\n' %
              (assoc['src'], assoc['dest'],
               ', '.join(['%s=%s' % (k,edgecfg[k]) for k in sorted(edgecfg)])))

        /# Finish the dot file.
        fp.write('}\n')
        if verbose:
          print('Wrote ' + destpath)

      /# Now create the image file.
      args = ['dot', '-Tpng', '-o', impath, destpath]
      if verbose:
        print('Command: ' + ' '.join(args))
      p = subprocess.Popen(
        args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
      stdout, stderr = p.communicate()
      if stderr:
        print('ERROR: %s' % stderr)
      else:
        if verbose:
          print('Wrote ' + impath)

        /# Now display the image file.
        if display:
          args = ['display', impath]
          if verbose:
            print('Command: ' + ' '.join(args))
          try:
            subprocess.check_output(args)
          except KeyboardInterrupt:
            pass
    test:
      metafile, file_scope, namespace, path = test.getMetaFile(
        'oopl', 'cards2', expand=True, imports=True)
      metac = metafile.compiler()
      config = metac.__class__.CONFIG
      fs = metac.fs()

      /# TODO(wmh): Decide where to generate temporary files.
      if False:
        dotpath = fs.join(config['src_root'], 'src', 'kernel', 'tmp.dot')
        metac.generateUmlDiagram([metafile], dotpath, config={})
    end method generateUmlDiagram;

    meta
    method MakeSnapshot #:
      Create a new snapshot (and, optionally, release).

      A snapshot is a private copy of the meta and baselang source code needed
      to implement Meta.
      - Snapshots are used to ameliorate the issues with writing self-modifying code
        - The meta compiler uses classes in metax.*, and invoking the meta
          compiler writes classes in metax.*, so any bugs introduced breaks
          the compiler.
        - By being able to use an snapshot of the metax.* code instead of the
          'live' metax.* code, we can recover from such issues.
        - Snapshots are a fourth layer to the traditional three-layer version:
            <major>.<minor>.<release>.<snapshot>
      
      A release is a public copy of the meta and baselang source code needed to
      implement Meta.
      - Releases will be available on http://metaxy.org for download

      TODO(wmh): Consider making this a meta method in metax.c.Compiler. But it
      is more high-level than the compiler. Maybe define metax.c.Env?
    params:
      var fs : metax.fs.FileSystem #:
        The filesystem instance to use for I/O operations.
      var verbose : bool = false #:
        If true, print out actions performed.
      var make_release : bool = false #:
        If true, make a public release (creates .tgz file)
    scope:
      /###  
      /# We first check if there are any .meta symlinks below the kernel dir.
      /#  - such symlinks usually occur because of an accidental invocation of
      /#    meta within a subdir.
      /#  - if there is a .meta symlink inside a directory that is included
      /#    as a resource, we will have a problem when we use 'tar czhf' to
      /#    tar up files ... symlinks are followed, and having spurious .meta
      /#    links around brings in a massive amount of additional unnecessary files.
      /#  - we'll need to loosen this up a bit in the future, but better safe than
      /#    broken.
      config = meta.Config()
      
      kerneldir = fs.join(config['src_root'], 'src', 'kernel')
      for path in (
        fs.join(kerneldir, 'testdata', '.meta'),
      ):
        if fs.exists(path):
          fs.unlink(path)
          if verbose:
            print('NOTE: Removed ' + path)
      problems = subprocess.check_output(
        ['find', '.', '-type', 'l', '-a', '-name', '.meta', '-a',
         '-mindepth', '2',  '-print'],
        cwd=kerneldir)
      if problems:
        print('WARNING: Not producing snapshot because of spurious .meta links.')
        print(problems)
        sys.exit(1)
      bazel_links = subprocess.check_output(
        ['find', '.', '-type', 'l', '-a', '-name', 'bazel-*', '-print'],
        cwd=kerneldir)
      if bazel_links:
        print('WARNING: Found bazel-* links.')
        print(bazel_links)
        ans = raw_input('Remove (yes|no)? ').strip()
        if ans.lower() == 'yes':
          for path in bazel_links.strip().split('\n'):
            fs.unlink(path)
            if verbose:
              print('Removed ' + path)
        bazel_links = subprocess.check_output(
          ['find', '.', '-type', 'l', '-a', '-name', 'bazel-*', '-print'],
          cwd=kerneldir)
        if bazel_links:
          print('Not proceeding.')
          sys.exit(1)

      /###
      /# Establish the new version number
      /# CODETANGLE(version_path): in metastrap.py
      release_dir = fs.join(config['src_root'], 'lib', 'versions')
      vre = re.compile(r'^v(\d+)\.(\d+)\.(\d+)(?:\.(\d+))?$')
      versions = []
      for base in fs.listdir(release_dir):
        m = vre.match(base)
        if m:
          major = int(m.group(1))
          minor = int(m.group(2))
          release = int(m.group(3))
          snapshot = int(m.group(4) or 0)
          assert major == 0   # for now
          assert minor == 7   # for now
          versions.append((base, major, minor, release, snapshot))
      versions = sorted(
        versions, cmp=lambda p1, p2: (
          cmp(p1[1], p2[1]) or cmp(p1[2], p2[2]) or cmp(p1[3], p2[3]) or
          cmp(p1[4], p2[4])))
      previous_version, major, minor, release, snapshot = versions[-1]

      release_version = None
      if make_release:
        release_version = 'v%d.%d.%d' % (major, minor, release + 1)
        new_version = release_version + '.00'
      else:
        new_version = 'v%d.%d.%d.%02d' % (major, minor, release, snapshot + 1)
        
      newpath = fs.join(release_dir, new_version)

      /###
      /# Create the new version dir
      assert not fs.exists(newpath)
      fs.mkdir(newpath, 0o755)
      if verbose:
        print('NOTE: Created %s' % newpath)

      /###
      /# Copy metastrap.py <newpath>/src
      import metastrap
      metastrap_path = metastrap.__file__
      if metastrap_path.endswith('.pyc'):
        metastrap_path = metastrap_path.replace('.pyc', '.py')
      metastrap_dest = fs.join(newpath, 'metastrap.py')
      fs.copyfile(metastrap_path, metastrap_dest)
      if verbose:
        print('NOTE: Copied %s to %s' % (metastrap_path, metastrap_dest))

      /###
      /# Copy <<src_root>>/src/{kernel,lib}/*.meta to <newpath>/src/{kernel,lib}
      destsrcdir = fs.join(newpath, 'src')
      fs.mkdir(destsrcdir, 0o755)  
      for srcsub in ('kernel', 'lib'):
        srcpath = fs.join(config['src_root'], 'src', srcsub)
        destpath = fs.join(destsrcdir, srcsub)
        fs.mkdir(destpath, 0o755)  
        for base in fs.listdir(srcpath):
          if '.meta' in base and base != '.meta':
            srcfile = fs.join(srcpath, base)
            destfile = fs.join(destpath, base)
            fs.copyfile(srcfile, destfile)
            if verbose:
              print('NOTE: Copied %s to %s' % (srcfile, destfile))
            
      /###
      /# Copy <<repository_path>>/oopl/python/metax to <newpath>/lib
      /#  - we specifically want symlinks to be converted into real files so
      /#    that the copy is self-contained. HOWEVER, this is dangerous if
      /#    there are symlinks that are massive ... how to address this?
      repometax = fs.join(
        config['repository_path'], 'oopl', 'python', 'metax')
      libdir = fs.join(newpath, 'lib')
      fs.mkdir(libdir, 0o755)
      destmetax = fs.join(libdir, 'metax')
      fs.copytree(repometax, destmetax, symlinks=False)
      if verbose:
        print('NOTE: Copied %s to %s' % (repometax, destmetax))

      /###
      /# Copy <<src_root>>/src/schema/{meta,oopl}/schema.meta to <newpath>/schema
      schemasrc = fs.join(config['src_root'], 'src', 'schema')  
      schemadir = fs.join(newpath, 'schema')
      fs.mkdir(schemadir, 0o755)  
      for metal in ('meta', 'oopl', 'doc'):
        subdir = fs.join(schemadir, metal)
        fs.mkdir(subdir, 0o755)  
        schema_src = fs.join(schemasrc, metal, 'schema.meta')
        schema_dst = fs.join(subdir, 'schema.meta')
        fs.copyfile(schema_src, schema_dst)
        if verbose:
          print('NOTE: Copied %s to %s' % (schema_src, schema_dst))
      if False:
        /# TODO(wmh): Remove following ... above code replaces.
        metadir = fs.join(schemadir, 'meta')
        oopldir = fs.join(schemadir, 'oopl')
        fs.mkdir(metadir, 0o755)  
        fs.mkdir(oopldir, 0o755)
        meta_schema_src = fs.join(schemasrc, 'meta', 'schema.meta')
        oopl_schema_src = fs.join(schemasrc, 'oopl', 'schema.meta')
        meta_schema_dst = fs.join(metadir, 'schema.meta')
        oopl_schema_dst = fs.join(oopldir, 'schema.meta')
        fs.copyfile(meta_schema_src, meta_schema_dst)
        if verbose:
          print('NOTE: Copied %s to %s' % (meta_schema_src, meta_schema_dst))
        fs.copyfile(oopl_schema_src, oopl_schema_dst)
        if verbose:
          print('NOTE: Copied %s to %s' % (oopl_schema_src, oopl_schema_dst))

      /###
      /# Copy $HOME/.config/metameta to <newpath>/config/metameta
      configdir = fs.join(newpath, 'config')
      fs.mkdir(configdir, 0o755)
      config_src = fs.join(fs.getenv('HOME'), '.config', 'metaxy')
      config_dst = fs.join(configdir, 'metaxy')
      fs.copytree(config_src, config_dst)
      if verbose:
        print('NOTE: Copied %s to %s' % (config_src, config_dst))

      /###
      /# Update the 'current' link
      current_link = fs.join(release_dir, 'current')
      if fs.lexists(current_link):
        if not fs.islink(current_link):
          raise IOError('Expecting %s to be a symlink' % current_link)
        fs.unlink(current_link)
      fs.symlink(
        /# newpath,
        new_version,
        current_link)

      /###
      /# Update the 'stable' link
      stable_link = fs.join(release_dir, 'stable')
      if fs.lexists(stable_link):
        if not fs.islink(stable_link):
          raise IOError('Expecting %s to be a symlink' % stable_link)
        fs.unlink(stable_link)
      fs.symlink(
        /# fs.join(release_dir, previous_version),
        previous_version,
        stable_link)

      /###
      /# Create a tar file (for releases)
      /#  - see https://superuser.com/questions/119928/weird-bug-in-tar-not-including-files-named-init-py
      /#    for details on why the env.vars. are being set.
      if make_release:
        release_path = fs.join(release_dir, release_version)
        fs.symlink(
          /# newpath,
          new_version,
          release_path)
        tarbase = release_version + '.tgz'
        tarpath = fs.join(release_dir, tarbase)
        env = copy.copy(fs.environ())
        env['COPY_EXTENDED_ATTRIBUTES_DISABLE'] = 'true'
        env['COPYFILE_DISABLE'] = 'true'
        tarcmd = ['tar', '-czhf', tarbase, release_version]
        subprocess.call(tarcmd, cwd=release_dir, env=env)
        if verbose:
          print('NOTE: Created ' + tarpath)
    end method MakeSnapshot;

    method maybeRecompileMeta : trilean #:
      For a given python file, check if its meta source needs compiling.

      Returns:
        True if compilation succeeded
        False if errors occurred.
        None if parsing did not happen
    params:
      var pyfile : str #:
        The python file to potentially update.
      var fp : ostream = err #:
        Where to write output.
    scope:
      result = None
      fs = self.fs()
      metafile_path, meta_exists = self.basePathToMeta(pyfile)
      if metafile_path:
        if meta_exists:
          metamodtime = fs.mtime(metafile_path)
          basemodtime = fs.mtime(pyfile)
          /# print('%d=%s\n%d=%s' % (metamodtime, metafile_path, basemodtime, pyfile))
          if metamodtime > basemodtime:
            fp.write(
              u'NOTE: compiling %s (%d seconds newer than %s)\n' %
              (fs.relpath(metafile_path),
              metamodtime - basemodtime,
              fs.relpath(pyfile)))

            /# TODO(wmh): We are NOT invoking a subprocess as we want this to be
            /# as efficient as possible. We may be able to significantly improve
            /# implicit compilation performance by using getMeta() instead of
            /# processMeta(), so that code needed by one metafile that has been
            /# compiled earlier can be reused instead of having to reparse from
            /# scratch. Only relevant if we expect many files to have changed,
            /# which should be rare.
            try:
              metafile, errors, warnings = self.processMeta(metafile_path)
            except Exception as e:
              text = traceback.format_exc()
              if False:
                print('#' * 70)
                print(text)
                print('=' * 70)
              ifp = io.StringIO(text)
              /# Note that the baselang being compiled is NOT what is important
              /# when performing baseling-to-metaline conversions ... it is the
              /# baselang being used to compile the code that is important!
              /# This parser.meta code is currently assuming a python implementation,
              /# so that is the baselang we use.
              baselang = self.metalang().baselangNamed('python')
              self.filterMetaOutput(baselang=baselang, ifp=ifp, debug=False)
              result = False
              sys.exit(1)
            else:
              if errors:
                result = False
                print('ERROR: Failed to compile %s' % metafile_path)
                sys.exit(1)
              else:
                /# If there were no changes between the python file on disk and
                /# the version created via compilation, the file is not
                /# rewritten and thus the modified timestamp is not changed
                /# either. This means that if metac is invoked again, the same
                /# file will look stale and in need of recompilation. For now,
                /# we touch the file to avoid this problem. I'd like to verify
                /# though that the only way this happens is when a cosmetic
                /# change is made to a meta file (a change that doesn't affect
                /# the underlying python code that gets generated).
                fs.touch(pyfile)
                self.writeSummary([metafile], fp=fp)
                result = True
        else:
          print('WARNING: metafile %s is missing' % metafile_path)
      else:
        if not pyfile.endswith('__init__.py'):
          print('WARNING: Failed to find metafile for %s' % pyfile)
      return result
    test:
      metac = metax.c.Compiler(metal='oopl', basel='python')
      fs = metac.fs()
      pypath = fs.join(
        metac.workspaceDirectory(), 'demo', 'cards0', '__init__.py')
      fp1 = test.fp()
      test.isnull(metac.maybeRecompileMeta(pypath, fp=fp1))

      /# Now we touch testdata/ex2.meta, which defines demo.cards0, and verify
      /# that we recompile.
      metapath = test.resourcePath('ex2')
      fs.touch(metapath)
      fp2 = test.fp()
      test.istrue(metac.maybeRecompileMeta(pypath, fp=fp2))
    end method maybeRecompileMeta;

    method handleCompilationException : any #:
      When an exception is used during compilation of .meta files, this method
      performs baselang-to-metafile remapping of the exception stack trace.
    params:
      var e : Exception #:
        The exception raised (currently unused).
    scope:
      text = traceback.format_exc()
      if True:
        print('#' * 70)
        print(
          'TODO(wmh): Add this output to the unittest for '
          'metax.c.Compiler.handleCompilationException in parser.meta')
        print(sys.exc_info())
        print('#' * 70)
        print(text)
        print('=' * 70)
      ifp = io.StringIO(unicode(text))
      /# Note that the baselang being compiled is NOT what is important
      /# when performing baseling-to-metaline conversions ... it is the
      /# baselang being used to compile the code that is important!
      /# This parser.meta code is currently assuming a python implementation,
      /# so that is the baselang we use.
      metaoopl = self.metalangNamed('oopl')
      baselang = metaoopl.baselangNamed('python')
      self.filterMetaOutput(baselang=baselang, ifp=ifp, debug=False)
    test:
      /# Waiting for good output
      /# TODO(wmh): Fix this when we have some.
      pass
    end method handleCompilationException;

    method generateHtml #:
      Generate a self-contained html file for a meta file specified by path.
    params:
      var path : str = null #:
        The metafile to parse.
      var width : int = 100 #:
        The number of characters to display horizontally.  Note that 5
        characters are needed along the left margin for line numbers, and
        should be accounted for in this value.
      var showbox : bool = false #:
        If true, show the show/hide/toggle control box in top left corner.
      var htmldir : str = null #:
        Where to write html files. If not present, the default is to use
        $repository_path/meta/<namespace_subpath>.
      var hide : bool = false #:
        If true, hide all blocks initially.
      var fontsize : str = '80%' #:
        The font size of the generated code.
      var basefilter : str = null #:
        If specified, it is a regexp to apply to baselang files. Only those that
        match are printed. If null, all basefiles are printed.
      var verbose : bool = false #:
        If true, print out files written.
      var uplift : bool = false #:
        If true, namespace scope: not printed, but children printed at same
        level.
      var showall : bool = false #:
        Show all attributes of all constructs.
    scope:
      /# The list of paths created.
      result = []

      /# Some useful vars
      cls = self.__class__
      fs = self.fs()
      flags = self.cli()
      debug = flags.debug if flags else False
      metalang = self.metalang()
      baselang = self.baselang()
      blsuffix = baselang.suffix()[1:]
      context = metalang.context()
      errors = 0
      chatty = True

      /#print('Here with width=%s showbox=%s htmldir=%s' % (width, showbox, htmldir))

      /# Establish the rootdir for .html files.
      /#  - one possibility is to write hidden .html files adjacent to
      /#    each .meta file
      /#  - another possibility is to write into
      /#       <<repository_path>>/<metalang>/meta/<namespace>
      /#    for each namespace in the .meta files.
      /# Although there are pros and cons of both, there is utility in
      /# putting as much generated data as possible into the repository,
      /# so that we can do post-analysis, display via the shell, etc.
      metadir = fs.join(
        self.repositoryPath(), metalang.id(), 'meta')

      /# Parse the file.
      metafile = self.parseMeta(
        path, debuglevel=debug, context=context)
      with fs.open(path, 'r') as mfp:
        metatext = mfp.read()
      meta_line_count = metatext.count('\n')
      meta_byte_count = len(metatext)

      if not metafile.hasErrors(show=True):
        /# Generate the HTML file BEFORE we expand the metafile.
        /#  - Although it is important to obtain the HTML file before expansion,
        /#    we *do* have to perform file-level pre-expansion in order to get
        /#    File-level classes properly placed in their implicit namespaces.
        /#  - We make a copy of the filecons constructs in case the list gets
        /#    modified dynamically during iteration.
        filecons = metafile.construct()
        metalang.preExpandFileConstruct(filecons)

        namespaces = list(filecons.attr('scope:').value())
        for namespace in namespaces:
          outlines = []

          /# Obtain the htmlish contents.
          hfp = io.StringIO()
          mode = {'form': 'html', 'out': {}, 'uplift': uplift}
          if showall:
            mode['details'] = 'all'

          namespace.write(fp=hfp, mode=mode)
          hstr = hfp.getvalue()
          lines = hstr.split('\n')
          lines.pop()

          out = mode['out']
          allids_json = json.dumps(out)
          import pprint
          /# pprint.pprint(out)

          if showbox:
            outlines.append(u'<div class="metadex">')
            outlines.append(u'  <center><b>%s</b></center>' % namespace.id())
            outlines.append(u'  <table>')
            bout = out['block']
            for i, bkey in enumerate(sorted(bout)):
              argstr = "allids.block['%s']" % bkey
              /# TODO(wmh): Why aren't classes working on the following <td>
              /# elements? I want to have the color of the first S H T to be
              /# red, and planned to use two classes to control the diff, but
              /# this is not working.
              css = 'ctrl1' if i == 0 else 'ctrl2'
              tdhack = ' style="color: red;"' if i == 0 else ''
              outlines.append(
                u'    <tr>'
                '<td>%s</td>'
                '<td></td>'
                '<td>%s</td>'
                '<td onclick="ulist(%s)" title="Hide %s blocks" class="%s"%s>H</td>'
                '<td onclick="slist(%s)" title="Show %s blocks" class="%s"%s>S</td>'
                '<td onclick="tlist(%s)" title="Toggle %s blocks" class="%s"%s>T</td>'
                '</tr>' %
                ('block' if i == 0 else '',
                 bkey,
                 argstr, bkey, css, tdhack,
                 argstr, bkey, css, tdhack,
                 argstr, bkey, css, tdhack))
            lout = out['lang']
            if len(lout) > 1:
              css = 'ctrl2'
              for i, lkey in enumerate(sorted(lout)):
                baseout = lout[lkey]
                for j, bkey in enumerate(sorted(baseout)):
                  argstr = "allids.lang.%s['%s']" % (lkey, bkey)
                  outlines.append(
                    u'    <tr>'
                    '<td>%s</td>'
                    '<td>%s</td>'
                    '<td>%s</td>'
                    '<td onclick="ulist(%s)" title="Hide %s %s blocks" class="%s">H</td>'
                    '<td onclick="slist(%s)" title="Show %s %s blocks" class="%s">S</td>'
                    '<td onclick="tlist(%s)" title="Toggle %s %s blocks" class="%s">T</td>'
                    '</tr>' %
                    ('baselang' if (i == 0 and j == 0) else '',
                     lkey if j == 0 else '',
                     bkey,
                     argstr, bkey, lkey, css,
                     argstr, bkey, lkey, css,
                     argstr, bkey, lkey, css))
              /# cout = out['construct']
            outlines.append(u'  </table>')
            outlines.append(u'</div>')

          /# Now wrap the htmlized lines into an overarching structure
          /# that shows line numbers, indents blocks, allows blocks to
          /# be opened and closed, etc.
          outlines.append(u'<div class="metafile">')
          dentlevel = 0
          linenum = 0
          for line in lines:
            indent = u'  ' * (dentlevel + 1)
            if line and line[0] == '':
              /# Escape sequence indicating block start/end.
              _, block_kind, conskind, block_uid, attrkey, basel, se = line.split(' ')
              if se == 'start':
                /# print('starting %s %s' % (consfqn, attrkey))
                dentlevel += 1
                classes = []
                is_code = 'scope' in attrkey or 'test' in attrkey
                if block_kind == 'simple' and is_code:
                  classes.append('baselang')
                  classes.append(basel)
                if attrkey in ('comment:', '#:'):
                  classes.append('face-comment')
                outlines.append(
                  indent + '<div id="%s" class="%s">' % (
                    block_uid, ' '.join(classes)))
              else:
                /# print('ending   %s %s' % (consfqn, attrkey))
                dentlevel -= 1
                outlines.append(indent[2:] + '</div>')
            else:
              /# We first remove the indentation from the beginning of the
              /# line.
              idx = dentlevel * 2
              prefix = line[:idx]
              line = line[idx:]

              linenum += 1
              if chatty:
                subindent = indent + '  '
                outlines.append(indent + '<div>')
                outlines.append(
                  subindent + '<span class="linenum">%d</span>' % linenum)
                outlines.append(
                  subindent + '<span class="indent%d"></span>' % dentlevel)
                outlines.append(
                  subindent + '<span class="linetext"><code>%s</code></span>' % line)
                outlines.append(indent + '</div>')
              else:
                outlines.append(
                  u'%s<div>'
                  '<span class="linenum">%d</span>'
                  '<span class="indent%d"></span>'
                  '<span class="linetext"><code>%s</code></span>'
                  '</div>' %
                  (indent, linenum, dentlevel, line))

          /# Write the result to the dest file.
          parts = namespace.id().split('.')
          if htmldir is None:
            htmldir = fs.join(metadir, *parts)
          if not fs.exists(htmldir):
            fs.makedirs(htmldir, 0o755)
          htmlbase = metax.c.PathFromMeta(
            fs.basename(metafile.path()), '_' + blsuffix +'.html')
          htmlpath = fs.join(htmldir, htmlbase)
          with fs.open(htmlpath, 'w') as fp:
            result.append(htmlpath)
            html_params =  {
              'fontsize': fontsize,
              'allids': str(allids_json),
              'width': width,
              'margin': 210 if showbox else 0,
              'onload': 'highlightCode',
            }
            html_params.update(Compiler.MetaConstructColorMap)
            html_head = cls.HTML_HEAD % html_params
            fp.write(
              '<html>\n  <head>\n%s\n  </head>\n' % html_head)
            fp.write('  <body>\n')
            for line in outlines:
              fp.write(line)
              fp.write('\n')
            if hide:
              fp.write("  <script>ulist(allids.block['all']);</script>\n");
            fp.write('  </body>\n')
            fp.write('</html>\n')
            if verbose:
              print('Wrote ' + htmlpath)

        /# Now expand and translate.
        filecons.expandMeta()
        if not metafile.hasErrors(show=True):
          filecons.translateMeta()
          if not metafile.hasErrors(show=True):
            /# Create a single HTML file showing all generated baselang files.
            html2base = metax.c.PathFromMeta(
              fs.basename(metafile.path()), '_' + blsuffix + '_base.html')
            html2path = fs.join(htmldir, html2base)
            html_params =  {
              'fontsize': fontsize,
              'allids': '[]',
              'width': width,
              'margin': 210 if showbox else 0,
              'onload': 'null',
            }
            html_params.update(Compiler.MetaConstructColorMap)
            html_head = cls.HTML_HEAD % html_params

            /# Establish how many baselang files, lines and bytes are produced.
            counts = {'files': 0, 'lines': 0, 'bytes': 0}
            filemap = fs.filemap()
            base_re = re.compile(basefilter) if basefilter else None
            subpaths = []
            for subpath in sorted(filemap):
              subbase = fs.basename(subpath)
              if subbase[0] == '.':
                /# Don't include hidden files (e.g. python per-class files, .bld files, .map files, etc.)
                continue
              if subbase.endswith('.html'):
                /# Don't include .html files (baselang files shouldn't contain
                /# .html, and including them confuses the insertion code).
                continue
              if base_re and not base_re.search(subbase):
                /# A filter regexp was specified and the current file does not
                /# match, so it isn't shown.
                continue
              subpaths.append(subpath)
              basefile = filemap[subpath]
              contents = basefile.contents()
              if contents is None:
                print('******** HERE with empty %s' % subpath)
              else:
                base_line_count = contents.count('\n')
                base_byte_count = len(contents)
                /# print('Here with %-50s = %4d  %4d' % (subpath, base_line_count, base_byte_count))
                counts['files'] += 1
                counts['lines'] += base_line_count
                counts['bytes'] += base_byte_count

            /# Create the baselang .html file.
            with fs.open(html2path, 'w') as fp:
              result.append(html2path)
              fp.write(
                '<html>\n  <head>\n%s\n  </head>\n' % html_head)
              fp.write('  <body>\n')
              fp.write(
                '<span style="font-size: 12px;">%s (%d lines, %d bytes) in %s (%d files, %d lines, %d bytes)</span><br><br>\n' %
                (fs.basename(path), meta_line_count, meta_byte_count, baselang.name(),
                 counts['files'], counts['lines'], counts['bytes']))
              for subpath in subpaths:
                basefile = filemap[subpath]
                contents = basefile.contents()
                assert subpath == basefile.subpath(), '%s (%s) vs %s (%s)' % (
                  subpath, type(subpath), basefile.subpath(), type(basefile.subpath()))
                if contents is None:
                  print('***** HERE with %s = %s' % (subpath, contents))
                  raise Error('Failed')
                else:
                  _, suffix = fs.splitext(subpath)
                  pure_suffix = suffix[1:]
                  hljs_class = blsuffix if pure_suffix in baselang.suffixes() else 'plaintext'
                  fp.write('\n<!-- %s\n%s\n-->\n\n' % ('*' * 70, subpath))
                  fp.write('<div class="baselangbox">\n')
                  fp.write('  <code>%s</code>\n' % subpath)
                  fp.write('  <div class="baselangcode">\n')
                  fp.write('<pre><code class="%s" id="%s">' % (hljs_class, subpath))
                  fp.write(contents)
                  fp.write('</code></pre>\n')
                  fp.write('  </div>\n')
                  fp.write('</div>\n')

              fp.write('\n<!-- %s\n%s\n-->\n\n' % ('*' * 70, 'Highlight and line number'))
              fp.write('    <script>\n')
              for subpath in subpaths:
                fp.write('      highlightBaseCode("%s");\n' % subpath)
              fp.write('    </script>\n')
              fp.write('  </body>\n')
              fp.write('</html>\n')
              if verbose:
                print('Wrote ' + html2path)
      return result
    test:
      metac = metax.c.Compiler(metal='oopl', basel='python')
      fs = metac.fs()
      metapath = test.resourcePath('ex2')
      test.iseq(
        ['ex2_py.html', 'ex2_py_base.html'],
        [fs.basename(path) for path in metac.generateHtml(metapath)])
    end method generateHtml;

    method monitorMetaFiles : any #:
      Monitor a collection of .metafiles, recompiling them if they change.
    params:
      var paths : vec<str> #:
        The paths to monitor
      var seconds_between_rounds : int = 60 #:
        Number of seconds between checks.
      var min_age : int = 300 #:
        We do not recompile unless the difference between last change and
        current time is at least this much.
      var min_unchanged : int = 300 #:
        A file must remain unchanged for this many seconds (after having
        changed) before we recompile it.
    scope:
      fs = self.fs()
      print('NOTE: Monitoring %d files...' % len(paths))

      def time2hms(ts):
        return datetime.datetime.fromtimestamp(mtime).strftime('%H:%M:%S')
      
      /# Maps path to mtime, so we can detect changes.
      pathmap = {}

      while True:
        start = time.time()
        updated = {}
        /# print('%s: Checking %d paths' % (datetime.datetime.now(), len(paths)))

        /# Find paths that have changed since last round
        for path in paths:
          mtime = fs.mtime(path)
          if path in pathmap:
            if mtime > pathmap[path]:
              /# The path has been updated.
              updated[path] = mtime  # this must be mtime, as we rely on it later
              /# print('NOTE: %s changed at %s (vs %s)' % (path, time2hms(mtime), time2hms(pathmap[path])))
          else:
            /# We don't have enough info about path yet, so we just add it for
            /# the next round.
            pathmap[path] = mtime

        /# Compile all updated paths.
        fp = sys.stdout
        try:
          metafiles, errors, warnings = self.getMetas(
            sorted(updated), debug=False, fp=fp)
        except Exception as e:
          self.handleCompilationException(e)
          sys.exit(1)
        else:
          if updated:
            print('%s: Found changes in %d of %d files' % (
              time2hms(start), len(updated), len(paths)))
            self.writeSummary(metafiles, indent='  ')

        /# Update times of all compiled files.
        for path, mtime in updated.items():
          pathmap[path] = mtime

        /# Wait until next round
        current = time.time()
        round_seconds = current - start
        if round_seconds < seconds_between_rounds:
          time.sleep(seconds_between_rounds - round_seconds)
    test:
      /# TODO(wmh): Need to mock out the timming code and establish a means
      /# of terminating the execute.
      pass
    end method monitorMetaFiles;

    command metac #:
      The public interface to the Meta compiler.
    scope:
      /# This initial block creates a Command instance and performs some
      /# initial sanity checks.
      Compiler.Initialize()
      metax.root.Object.Init(cli=cli)
      meta__names.append(False)  # to handle default arg.

      /# We update MetaObject's idea of instantiated command.
      assert metax.root.MetaObject.CLI() is not None
      metax.root.MetaObject.CLI()._command_Is(meta__command)

      /# Check if there are any .meta files with explicit baselangs specified.
      explicits = set()
      for arg in sys.argv[1:]:
        m = metax.c.SUFFIX_RE.match(arg)
        if m:
          base, rawsuff = m.groups()
          if rawsuff:
            explicits.add(rawsuff)
      if len(explicits) > 1:
        print('ERROR: Cannot compile into multiple baselangs in same metac invocation')
        sys.exit(1)
      elif len(explicits) == 1:
        basel = explicits.pop()
        if basel in ('doc', 'story', 'family'):
          /# TODO(wmh): We do not use implicit baselang determination from
          /# meta suffix when that suffix actually refers to a Meta language
          /# (e.g. metadoc, metastory, metafamily, etc.). Generalize this code
          /# by obtaining all Meta language ids and aliases and looking therein.
          basel = cli.baselang
        else:
          metal = cli.metalang.lower()
          suffix_hack = Compiler.SUFFIX_HACK.get(metal, None)
          baselang_flag = meta__command.findPart('baselang')
          if suffix_hack and baselang_flag.start():
            /# The --baselang flag was explicitly specified. We ensure it doesn't
            /# conflict.
            /#  - this is complicated by the fact that we do not yet have a
            /#    MetaLanguage instance. For now we use Compiler.SUFFIX_HACK
            canbasel = suffix_hack.get(baselang_flag.value(), None)
            if canbasel is None:
              print('ERROR: Unknown baselang "%s" in Compiler.SUFFIX_HACK' % baselang_flag.value())
              sys.exit(1)
            else:
              cansuff = suffix_hack.get(basel, None)
              if cansuff is None:
                print('ERROR: Unknown baselang suffix "%s"' % basel)
                sys.exit(1)
              elif cansuff != canbasel:
                print('ERROR: Explicit --baselang %s (%s) does not match baselang %s (%s) implied by source suffixes' % (
                  baselang_flag.value(), canbasel, basel, cansuff))
                sys.exit(1)
          
      else:
        /# TODO(wmh): If -b was explicitly provided (rather than being obtained
        /# from default), we should report a warning or error.
        basel = cli.baselang

      /# Create the Compiler instance.
      metac = metax.c.Compiler(metal=cli.metalang, basel=basel)
      metax.c.Compiler.CurrentIs(metac)
      /# Ensure that the repository directory exists.
      if not metac.verifyDirectory(metadir='.meta'):
        sys.exit(1)

      /# The MetaxEntry method is either a meta-method or a static method.
      /# Either way, it is not an instance of the current class, but the methods
      /# generated to represent named subcommands *are* instance methods. The
      /# preamble of the top-level command is expected to create an instance of
      /# the class as part of entry semantics, and that instance must be
      /# assigned to the variable 'the<ClassName>'. Thus, if a 'command'
      /# construct appears in the scope: of a Person class, the variable should
      /# be thePerson.
      theCompiler = metac

    interface:

      flag baselang @ b : str = 'python' #:
        The baselang to compile into.
        If this is <special>, a metalang-specific default is used.
      flag basebinary @ B : str = 'default' #:
        An experimental means of specifying a non-default binary. For example,
        by default Meta<Python> currently generates v2 code (although this will
        change to be v3 sometime). In order to use a non-default binary for
        python, one can specify the 'binary' attribute on top-level 'command'
        constructs, but that doesn't help for test invocations. This flag
        allows support for this. It can either be an existng path, or one of
        'default', 'old', or 'new' (semantics is baselang dependent).
      flag metalang @ L : str = 'oopl' #:
        The metalang the code is defined in.
      flag optimize_level @ O : str = 'high' #:
        enum<off|low|avg|high|max>
        The amount of optimization to enable compiled files.
      flag metadir : str = '.meta' #:
        The subdir to write code to.
        A value of .meta is treated specially (is symlinked to repo).
      flag inmemory : bool = false #:
        If true, use memory filesystem instead of disk filesystem.
      flag metasrcfile : str = '' #:
        A specially formatted file specifying meta source files to compile.
        Each line contains <title>: <metafile>...
      flag debug @ A : int = 0 #:
        Controls meta parsing debug level.
      flag disable_imports : bool = false #:
        If true, do not invoke importMeta during compilation.
      flag summary_files : bool = true #:
        If true, show file counts in compilation summaries.
      flag summary_counts : bool = false #:
        If true, show construct counts in compilation summaries.
      flag summary_times : bool = false #:
        If true, show timing results in compilation summaries.
      flag summary_autogen : bool = false #:
        If true, show autogened constructs when counting constructs in compilation summaries.
      flag summary_nofiles : bool = false #:
        If true, only show group and total, not per-file counts.
      flag test2 @ t : bool = false #:
        If true, invoke unit tests on all namespaces in all metafiles processed.
        TODO(wmh): Remove this in favor of 'test' command.
      flag showfs : bool = false #:
        If true, print out filesystem after compilation.

      flag implicit_scopes : bool = false #:
        If true, methods without scopes are given a default body.
        By default, methods without scopes produce an error.
      flag raw : bool = false #:
        If True, do not convert file references to meta (keep baselang paths).
      flag verbose @ v :  bool = false #:
        If true, print out additional diagnostics.
      flag verbosity @ V : int = 0 #:
        Levels of verbosity. Tied to --verbose.
      flag write_goldens @ W : bool = false #:
        If true, tests involving goldens write instead of compare.
      flag hack : bool = false #:
        If true, enable some special code (used during prototyping)

      flag rawtests2 @ r : bool = false #:
        If true, do not use bazel to run tests.
        Some baselangs can invoke the test harness without bazel, and for such
        baselangs this flag disables bazel.
        TODO(wmh): This is conflciting with metacold if 'rawtest' is used.

      named
      command canonical #:
        Canonicalize the specified meta files and report diffs.
      interface:
        flag pre_expand : bool = false #:
          If true, perform pre-expansion (but not expansion, unless --expand)
        flag expand : bool = false #:
          If true, perform expansion
        flag uplift : bool = false #:
          If true, namespace scope: not printed, but children printed at same
          level.
        flag details : str = 'user' #:
          Which details to show.
      scope:
        cli = self.cli()
        argmap = self._parseArgs(cli.rest)
        metafile_paths = argmap['metafiles']
        context = self.metalang().context()
        errors = 0
        mode = {
          'uplift': cli.uplift,
          'details': cli.details,
        }

        for path in metafile_paths:
          metafile = self.parseMeta(
            path, debuglevel=cli.debug, context=context)
          if metafile.hasErrors(show=True):
            errors += 1
          else:
            if cli.expand:
              metafile.construct().expandMeta()
            elif cli.pre_expand and not cli.expand:
              self.metalang().preExpandFileConstruct(metafile.construct())
            if metafile.hasErrors(show=True):
              errors += 1
            if errors == 0:
              print('#' * 80)
              print(path)
              for construct in metafile.construct().attr('scope:').value():
                construct.write(mode=mode)
      end command canonical;

      named
      command checkmap #:
        Verify that a baselang map file is correct.
      scope:
        print('WARNING: Command "checkmap" is not yet implemented.')
      end command checkmap;

      named
      command checkrepo #:
        Verify that the Meta repository is sane.
      scope:
        self.parseRepository()
      end command checkrepo;

      named
      command checkhack #:
        Until checkrep is fully implemented, we use the 'metac-files' Makefile
        in $HOME to obtain all .meta files.
      scope:
        /# TODO(wmh): Fix reference to os.system. Define fs.system?
        import os
        fs = self.fs()
        wmh = fs.getenv('WMH')
        path = fs.join(wmh, 'files.metac')
        if not fs.exists(path):
          os.system('cd %s; make metac-files' % wmh)
        dfre = re.compile('^(DIR|FILES): (.*)')
        metapaths = []
        metaspecs = []
        with fs.open(path, 'r') as fp:
          cdir = None
          for line in fp:
            m = dfre.match(line)
            if m:
              kind, info = m.groups()
              if kind == 'DIR':
                cdir = info
              elif kind == 'FILES':
                metaspec = '%s/{%s}' % (cdir, info.replace(' ',','))
                /# print(metaspec)
                metaspecs.append(metaspec)
                for subpath in info.split():
                  metapath = fs.normpath(fs.join(cdir, subpath))
                  if fs.exists(metapath):
                    metapaths.append(metapath)
                    /# print(metapath)
                  else:
                    print('ERROR: %s does not exist' % metapath)
        command = 'metac --summary_counts --summary_times --summary_files %s' % ' '.join(metaspecs)
        print(command)
        os.system(command)

        command = 'metac --summary_autogen --summary_counts --summary_times --summary_files %s' % ' '.join(metaspecs)
        print(command)
        os.system(command)
      end command;

      named
      command clean #:
        Remove a class from the Meta repository
      scope:
        print('WARNING: Command "clean" is not yet implemented.')
      end command clean;

      named
      command compare #:
        Run normal code and experimental code and compare generated results.
      scope:
        print('WARNING: Command "compare" is not yet implemented.')
      end command compare;

      named
      command compile #:
        Compile specified .meta files.
      scope:
        /# TODO(wmh): Get aliases working on primary keys so we can
        /# implement 'arg'!
        /# arg args : list<str>;
        flags = self.cli()
        argmap = self._parseArgs(flags.rest, implicit=True)

        /# TODO(wmh): Fix this ... dictate from some flag.
        debug = False

        metafile_paths = argmap['metafiles']
        fp = sys.stdout
        try:
          metafiles, errors, warnings = self.getMetas(
            metafile_paths, debug=debug, fp=fp)
        except Exception as e:
          self.handleCompilationException(e)
          sys.exit(1)
        else:
          self.writeSummary(metafiles, groups=argmap['groups'])

        if flags.test2:
          targets = []
          for metafile in metafiles:
            for namespace in metafile.construct().attrval('scope:', default=EMPTY):
              if namespace.variant() == 'user':
                targets.append(namespace.fqn())
          flags.rawtests = True
          if targets:
            self.runUnitTests(
              targets, verbose=flags.verbose, basebinary=flags.basebinary)
        return errors == 0
      end command compile;

      named
      command config #:
        Print out the config values
      scope:
        config = Compiler.CONFIG
        cli = self.cli()
        if len(cli.rest) == 1:
          var = cli.rest[0]
          print(config.get(var, '<INVALID>'))
        else:
          vars = cli.rest or sorted(config)
          for var in vars:
            print('%-20s = %s' % (var, config.get(var, '<INVALID>')))
      end command config;

      named
      command debug2 #:
        Invoke a base-lang specific debugger
        TODO(wmh): Conflicts with --debug (but shouldn't ... flags and args
        can conceptually be given same name, although this may be problematic
        in current implementation).
                                           
      scope:
        print('baselang debugging not yet implemented')
      end command debug2;

      named
      command doc #:
        Compile a Meta(Doc) file.
      scope:
        flags = self.cli()
        argmap = self._parseArgs(flags.rest, implicit=True)
        metafile_paths = argmap['metafiles']
        for path in metafile_paths:
          metafile = self.getMeta(path)
          /# metafile.construct().write()
      end command doc;

      named
      command expand #:
        Expand a specified .meta file.  Consider using 'get' instead.
      scope:
        cli = self.cli()
        fs = self.fs()
        argmap = self._parseArgs(cli.rest)
        errors = False
        metafiles = []
        for path in argmap['metafiles']:
          metafile = self.getMeta(
            path, expand=True,
            imports=False, translate=False, compile=False)
          if metafile.hasErrors(show=True):
            pass
          else:
            newpath = path + '.exp'
            newpath = newpath.replace('.meta.exp', '.exp.meta')
            file_construct = metafile.construct()
            with fs.open(newpath, 'w') as fp:
              for construct in file_construct.attrval('scope:', default=None) or []:
                if construct.kind() != 'namespace': continue
                construct.write(fp=fp)
            print('Wrote ' + newpath)
          metafiles.append(metafile)
      end command expand;

      named
      command emacs #:
        Generate an emacs major mode for the metalanguage specified as first
        arg (do NOT use -L!)
      scope:
        cli = self.cli()
        fs = self.fs()
        metal = self.metalang().id()
        if metal != 'oopl':
          print('usage: metac emacs <metalang> [schema_path]   (i.e.g do NOT use -L)')
        else:
          metal = cli.rest[0]
          schema_path = None
          out_path = None
          if len(cli.rest) > 1:
            schema_path = cli.rest[1]
            out_path = fs.join(
              fs.dirname(fs.abspath(schema_path)), 'meta%s-mode.el' % metal)
            print('out_path = %s' % out_path)
          metalang = self.metalangNamed(metal, schema_path=schema_path)
          assert metalang.compiler() is self
          self.generateMajorMode(metalang, out_path=out_path)
      end command emacs;

      named
      command get #:
        Get a .meta file (parse, expand, import, translate and compile).
      scope:
        cli = self.cli()
        argmap = self._parseArgs(cli.rest)
        errors = False
        metafiles = []
        for path in argmap['metafiles']:
          metafile = self.getMeta(
            path, expand=True, imports=True, translate=True, compile=True)
          if metafile.hasErrors(show=True):
            errors = True
            break
          metafiles.append(metafile)
        if not errors:
          self.writeSummary(metafiles)
      end command get;

      command html #:
        Create .html files for the specified metafile(s) and their basefiles.
      interface:
        flag htmldir : str = '' #:
          Where to write generated html files.
        flag htmlwidth : int = 80 #:
          How many chars to reserve for each line. Note that 5 will be added
          to account for line numbers on left side.
        flag unbox : bool = false #:
          If true, do not show the show/hide/toggle control box.
        flag htmlhide : bool = false #:
          If true, hide all blocks initially.
        flag fontsize : str = '80%' #:
          The fontsize of the generated code.
        flag uplift : bool = false #:
          If true, namespace scope: not printed, but children printed at same
          level.
        flag showall : bool = false #:
          If true, show all attributes.
      scope:
        /# IMPORTANT: Not specifying this as a named block because it means
        /# we lose access to htmldir. Not naming the block may pose problems
        /# in other arenas though ... may need to find a difference solution.

        /# We create a local compiler so that we can limit scope to the
        /# files and namespaces specified on the command, rather than all
        /# files parsed in this shell.
        fs = self.fs()
        if False:
          metac = metax.c.Compiler(
            metal=self.metalang().id(),
            basel=self.baselang().id(),
            rootdir=fs.rootdir(),
            metadir=fs.metadir(),
            kind=fs.kind(),
            repodir=self.repodir())
        else:
          metac = self
          
        cli = metac.cli()
        fs = metac.fs()

        argmap = metac._parseArgs(cli.rest)
        paths = argmap['metafiles']
        for path in paths:
          metac.generateHtml(
            path,
            width=cli.htmlwidth + 5,
            showbox=not cli.unbox,
            htmldir=cli.htmldir or None,
            hide=cli.htmlhide,
            fontsize=cli.fontsize,
            uplift=cli.uplift,
            showall=cli.showall,
            verbose=True,
          )
          if cli.inmemory:
            basefile = fs.subpath('../tmp2/person_py_base.html')
            print(basefile.contents())
            fs.summarize()
      end command html;

      named
      command index #:
        Print out the index of namespaces/classes/methods.
      interface:
        flag min @ m : int = 0 #:
          Do not print out constructs with level less than this.
        flag max @ M : int = 100000 #:
          Do not print out constructs with level greater than this.
        flag kind : str = 'org1' #:
          Selects amongst a variety of named formats and delimiters. If
          form is provided explicitly, the form value specified by kind
          is overridden, but the delim of kind is maintained.
          TODO(wmh): Should be of type enum<num|org1|org2>, but
          need to provide user-level access to Meta enum types to support this.
        flag form : str = '' #:
          The 'form' value to pass to Construct.writeIndex. Usually easier
          to use --kind unless the options don't match needs.
        flag suffix : str = '' #:
          The 'suffix' value to pass to Construct.writeIndex
        flag adj : int = 0 #:
          How much to adjust level by when computing indent value.
        flag filter : str = '' #:
          If present, only summary lines matching this regexp are shown.
      scope:
        baselang = self.baselang()
        fs = self.fs()
        flags = self.cli()

        kinds = {
          /# Line number at left margin, then indented kind and id
          'num': {},
          /# Indentation, then '- ', then kind, id and [line]
          'org1': {
            'form': '%(indent)s%(sep)s %(kind)s %(id)s [%(line)d]',
            'delim': ' ',
            'sep': '-',
            'adj': -1,
          },
          /# Indentation using '*', then kind, id and [line]
          'org2': {
            'form': '%(indent)s %(kind)s %(id)s [%(line)d]',
            'delim': '*',
          },
        }

        kwds = {
          'sep': ' ',
          'minlevel': flags.min,
          'maxlevel': flags.max,
          'adj': flags.adj,
        }

        if flags.kind:
          more = kinds.get(flags.kind, None)
          if more is not None:
            kwds.update(more)
          else:
            print('WARNING: --kind %s is unknown (ignored)' % flags.kind)
        if flags.form:
          kwds['form'] = flags.form
        if flags.suffix:
          kwds['suffix'] = flags.suffix
        if flags.filter:
          try:
            kwds['filter'] = re.compile(flags.filter)
          except sre_constants.error as e:
            print('ERROR: regexp "%s" is invalid (ignored)' % flags.filter)

        argmap = self._parseArgs(flags.rest, resolve=True)

        for details in argmap['details']:
          construct = details['construct']
          if construct:
            lines = construct.writeIndex(**kwds)
            for line in lines:
              print(line)
          else:
            print('WARNING: Ignoring %s (%s)' % (
              details['arg'], details['kind']))
      end command index;

      named
      command issue #:
        Create an issue on the https://github.com/metaesque/meta repo.
      interface:
        flag title : str = '' #:
          The title of the issue.
      scope:
        /# Things to do:
        /#  - create a new issue via 'ghi' (parse output to obtain issue number N)
        /#  - bundle up the .meta files listed in the 'issue' command into a .tgz
        /#  - determine how metac will submit these files on the users behalf:
        /#     - was initially thinking that they would just push changes to
        /#       the repo, but that would require everyone to have write
        /#       access. Unless we can limit this to specific subdirs, that isn't
        /#       viable.
        /#     - email the tar bundle to wade@holst.ca?
        /#     - is there an email address associated with github accounts?
        /#     - submit to http://metaxy.org/issue?number=<N>&file=/path/to/file.tgz?
        /#        - but how do we get it from GAE to github? what about storage costs?
        /#     - use https://github.com/sociomantic-tsunami/git-hub instead of
        /#       ghi, which appears to allow one to attach files to an issue
        /#  - ensure that the person has a local github clone that does not
        /#    have any current commits.
        /#  - add an entry to the newly created bug citing the files uploaded.
        repo = metax.c.GithubRepo('metaesque', 'meta')

        fs = self.fs()
        username = fs.getenv('METAX_GITHUB_USERNAME', default=repo.owner())
        password = fs.getenv('METAX_GITHUB_PASSWORD', default=None)
        token = fs.getenv('METAX_GITHUB_TOKEN', default=None)

        print('WARNING: issue command not yet working!')

        if password or token:
          repo.newIssue(
            title = 'Test 3 (improved issue command)',
            body = 'Test body\nwith multiple lines.',
            dates = {'created': datetime.datetime(2018, 1, 1, 1, 1, 1)},
            /# milestone = 1,
            closed = True,
            labels = [],
            username = username,
            password = password,
            token = token,
          )
        else:
          print('ERROR: Must define one of METAX_GITHUB_{PASSWORD,TOKEN}')

      end command issue;

      named
      command mirror #:
        Mirror a meta-generated source hierarchy to another directory.

        Creates symlinks for all production .py files. Useful in providing
        client-facing versions of code that hides away Meta idioms, etc.
        (initially useful in GAE).

        TODO(wmh): Add support for mirroring all sub-namespaces within a
        specified namespace.
      interface:
        flag dir @ d : str = '' #:
          Required flag.

        flag tests @ t : bool = false #:
          If true, include tests.

        flag collapse @ c : bool = false #:
          Currently only relevant for baeslang python. If true, convert
          nm/sp/__init__.py to nm/sp.py unless there is also
          nm/sp/sub/__init__.py.
      scope:
        verbose = True
        cli = self.cli()
        rootdir = self.workspaceDirectory()
        fs = self.fs()

        def CopySrc2Dst(srcpath, verbose=False):
          /# Given a baselang source path and cli, obtain the full destpath
          assert srcpath.startswith(rootdir)
          basedir = fs.dirname(srcpath)
          subdir = basedir[len(rootdir)+1:]
          subparts = subdir.split('/')
          destdir = fs.join(cli.dir, subdir)
          if cli.collapse:
            basename = fs.basename(destdir)
            destdir = fs.dirname(destdir)
            destpath = fs.join(destdir, basename + baselang.suffix())
            subparts.pop()
          else:
            destpath = fs.join(destdir, fs.basename(srcpath))
          if not fs.exists(destdir):
            fs.makedirs(destdir, 0o700)
            if verbose:
              print('Note: Created %s' % destdir)

          fs.copyfile(srcpath, destpath)
          if verbose:
            print('Note: Copied %s to %s' % (srcpath, destpath))

          if baselang.id() == 'python':
            /# Hackery to ensure that __init__.py files exist up the chain.
            tmpdir = destdir
            assert tmpdir.endswith('/'.join(subparts))
            while subparts:
              ipath = fs.join(tmpdir, '__init__.py')
              if not fs.exists(ipath):
                fs.touch(ipath)
                if verbose:
                  print('Note: Touched %s' % ipath)
              subparts.pop()
              tmpdir = fs.dirname(tmpdir)

          return destpath

        argmap = self._parseArgs(cli.rest)
        baselang = self.baselang()
        for details in argmap['details']:
          if details['kind'] == 'fqn':
            basepath = details['path']
            testpath = (
              fs.join(
                fs.dirname(basepath) + '_test', fs.basename(basepath))
              if cli.tests else None)
            CopySrc2Dst(basepath, verbose=verbose)
            if testpath and fs.exists(testpath):
              CopySrc2Dst(testpath, verbose=verbose)
          else:
            print('WARNING: Ignoring arg "%s"' % details['arg'])
      end command mirror;

      named
      command monitor #:
        Monitor .meta files for changes, recompiling when they are detected.
      interface:
        flag cycle : int = 60 #:
          Number of seconds between checks.
      scope:
        cli = self.cli()
        self.monitorMetaFiles(cli.rest, seconds_between_rounds=cli.cycle)
      end command monitor;

      named
      command parents #:
        Print out the parents (and metaparents) of the specified class.
      scope:
        print('WARNING: Command "parents" is not yet implemented.')
      end command parents;

      named
      command parse #:
        Parse a specified .meta file.  Consider using 'get' instead.
      scope:
        cli = self.cli()
        argmap = self._parseArgs(cli.rest)
        errors = False
        metafiles = []
        for path in argmap['metafiles']:
          metafile = self.parseMeta(path)
          if metafile.hasErrors(show=True):
            errors = True
            break
          metafiles.append(metafile)
        if not errors:
          self.writeSummary(metafiles)
      end command parse;

      named
      command repl #:
        Invoke a baselang-specific read-execute-print loop (REPL).
      scope:
        self.baselang().repl()
      end command repl;

      named
      command reverse #:
        Reverse compile baselang files into meta files.
      scope:
        print('WARNING: Command "reverse" is not yet implemented.')
      end command reverse;

      named
      command run #:
        Invoke a class-specific entry point
      scope:
        baselang = self.baselang()
        fs = self.fs()
        flags = self.cli()
        allargs = flags.rest
        if allargs:
          fqcn = allargs[0]
          path = fs.join(
            self.repositoryPath(), self.baselang().classPath(fqcn))
          if fs.exists(path):
            parts = fqcn.split('.')
            clsname = parts.pop()
            nmsp = '.'.join(parts)

            /# TODO(wmh): Create a baselang behavior for this
            if baselang.id() == 'python':
              /# TODO(wmh): How to get this to interact with Bazel?
              module = importlib.import_module(nmsp)
              cls = getattr(module, clsname, None)
              if cls is None:
                /# TODO(wmh): Why didn't we detect this earlier?
                print('ERROR: Unknown class ' + fqcn)
              else:
                entry = getattr(cls, METAX_ENTRY_NAME, None)
                if entry is None:
                  print('ERROR: %s does not have an entry point defined' % fqcn)
                else:
                  args = ['meta-dynamic'] + allargs[1:]
                  entry(args)
            else:
              print('Not yet implementing run for %s' % baselang.id())
          else:
            print('ERROR: Invalid class ' + fqcn)
        else:
          print('usage: metac run <fqcn> [arg]...')
      end command run;

      named
      command schema #:
        Create a .meta file defining classes for each construct.
        Create an HTML file documenting the target schema.
      scope:
        cli = self.cli()
        verbose = cli.verbose
        
        metaoopl = self.metalang()
        if metaoopl.id() != 'oopl':
          print('ERROR: Do not use -L %s' % metaoopl.id())
          print('usage: metac schema <metalang>')
          sys.exit(1)

        if not cli.rest:
          print('usage: metac schema <metalang>')
          sys.exit(1)

        /# Important distinction:
        /#   - metaoopl is the Meta(Oopl) metalanguage, used to create the
        /#     code.
        /#   - metalang is the Meta(<target>) metalanguage, used to obtain
        /#     the schema from which source code is obtained.
        metal = cli.rest.pop(0)
        if cli.rest:
          /# Second arg, if present, is the schema file defining the metalang.
          schema_path = cli.rest[0]
        else:
          print('usage: metac schema <metalang> <schema_file>')
          sys.exit(1)
        metalang = self.metalangNamed(metal, schema_path=schema_path)
        assert metalang.compiler() is self
        metalang.generateMeta()

        /# TODO(wmh): Move the html generating code below someplace else
        /# (maybe it goes into MetaLanguage.generateMeta(), maybe it goes
        /# in Compiler.generateHtml())
        return

        /###
        /# Generate the HTML
        def CommentFor(cons, default=None):
          lines = cons.attrval('comment:', default=None)
          if lines:
            text = '\n'.join(lines)
            /# result = re.sub('\n\s*\n', '</p>\n</p>', text) + '</p>'
            result = text
          else:
            result = default or ''
          return result

        constructs = collections.OrderedDict()
        mname = 'Meta(%s)' % metalang.name(),
        data = {
          'sum': CommentFor(metalang, '?'),
          'title': mname,
          'cat': {
            'Construct': constructs,
          }
        }
        for construct in config:
          cid = construct.id()
          attributes = collections.OrderedDict()
          constructs[cid] = {
            'sum': CommentFor(construct, '?'),
            'title': cid,
            'cat': {
              'Attribute': attributes,
            }
          }
          attr_config = construct.attrval('config:')
          for attrcons in attr_config:
            if attrcons.kind() != 'Attribute': continue
            aid = attrcons.id()
            aid2 = aid.replace(':', '_')
            akind = attrcons.attrval('kind')
            attr_cat = {}
            attributes[aid2] = {
              'sum': CommentFor(attrcons, '?'),
              'title': '%s (%s)' % (aid, akind),
              'cat': attr_cat,
            }
            /# If attrcons is a feature, add a 'Feature Values' key to cat.
            if akind == 'feature':
              fvconfig = attrcons.attrval('config:')
              fvals = collections.OrderedDict()
              attr_cat['FeatureValue'] = fvals
              for fvcons in fvconfig:
                fvid = fvcons.id()
                fvals[fvid] = {
                  'sum': CommentFor(fvcons, '?'),
                  'title': fvid,
                }

        import wmh.weblib
        wmh.weblib.Item.Render(data, 'a.html')
      end command schema;

      named
      command setup #:
        Perform specialized baselang-specific WORKSPACE configuration.
      scope:
        debug = True
        baselang = self.baselang()
        wdir = self.workspaceDirectory()
        metaroot = self.metaRoot()
        fs = self.fs()
        commands = []

        if debug:
          print('baselang          %s' % baselang.id())
          print('workingdir        %s' % wdir)
          print('metaroot          %s' % metaroot)

        /# NOTE(wmh): We currently do NOT untar the oopl.tgz file here ... it is
        /# done at a higher level than a specific baselang. Keep it a manual
        /# process?
        if False:
          oopl_tgz = fs.join(metaroot, 'src', 'templates', 'oopl.tgz')
          if debug:
            print('oopl.tgz          %s' % oopl_tgz)
          if not fs.exists(oopl_tgz):
            raise Error('Failed to find %s' % oopl_tgz)
          repopath = self.repositoryPath()
          commands.append({'args': ['tar', 'xzf', oopl_tgz], 'cwd': repopath})

        /# (Maybe) clean the repository so we can start afresh.
        rc, _, _ = self.executeBazelCommand(
          ['clean', '--expunge'], cwd=wdir, dryrun=False, prompt=True)

        /# As of 2017-12-22, we have a special setup flow for C++, because the
        /# default C++ compiler on macos (clang) does not handle std::any, so
        /# we use g++ instead, which does.
        /#  - a special CROSSTOOL has been created ... we copy it into the
        /#    default location.
        if baselang.id() == 'cpp':

          /# Establish the location of the default crosstool file.
          rc, output_base, stderr = self.executeBazelCommand(
            ['info', 'output_base'], cwd=wdir, prompt=False, dryrun=False)
          if rc:
            raise Error(
              "ERROR executing 'bazel info output_base':\n%s" % stderr)
          default_crosstool = fs.join(
            output_base.strip(), 'external', 'local_config_cc', 'CROSSTOOL')
          if debug:
            print('default_crosstool %s' % default_crosstool)

          /# If the default crosstool file is missing, invoke bazel to
          /# have it auto-generated.
          /#  - TODO(wmh): Is this even necessary if we have our own copy?
          /#    My concern is that the autogen process does more than just
          /#    write the CROSSTOOL file, so safer to do it then tromp.
          if not fs.exists(default_crosstool):
            /# This will happen if the above 'bazel clean --expunge' was
            /# performed.
            rc, _, _ = self.executeBazelCommand(
              ['build', 'metastrap:__Meta__'],
              cwd=wdir, dryrun=False, show=True)

          /# If we have a local crosstool file, replace the default one with it.
          system = platform.system()
          special_crosstool = fs.join(wdir, 'CROSSTOOL.%s.g++' % system)
          if debug:
            print('special_crosstool %s' % special_crosstool)
          if fs.exists(special_crosstool):
            fs.copyfile(special_crosstool, default_crosstool)
            print('NOTE: Replaced\n  %s\nwith\n  %s' % (
              default_crosstool, special_crosstool))
      end command setup;

      named
      command shell @ sh #:
        An interactive shell within which any metac command can be invoked.
      scope:
        shell = metax.c.shell.Shell(self)
        shell.run()
      end command shell;

      named
      command shold #:
        A shell for exploring a MetaFile.
      scope:
        cli = self.cli()
        argmap = self._parseArgs(cli.rest, implicit=True)
        metafiles = argmap['metafiles']
        if len(metafiles) != 1:
          print('ERROR: must provide exactly one meta file to "metac sh".')
          return
        path = metafiles[0]
        metafile = self.getMeta(
          path, imports=False, translate=False, compile=False)

        /# The virtual filesystem contains correpsonds to the fqn of
        /# a construct. Thus, metax.c.Compiler.parseMeta has path
        /# /metax.c/Compiler/parserMeta.

        filecons = metafile.construct()
        root = MetaNode(None, filecons)
        root.populate(
          {'File': ['namespace'],
           'namespace': ['class'],
           'class': ['field', 'method'],
           'field': ['accessor'],
           /# 'method': [],
          })

        current = root
        history = []

        /# Commands:
        /#  up: move up to parent
        /#  cd: move to some other path
        prompt = '>> '
        given_ans = None
        while True:
          if given_ans:
            print('Found given "%s"' % given_ans)
            ans = given_ans
            given_ans = None
          else:
            try:
              ans = raw_input(prompt)
            except EOFError:
              print
              break
          args = shlex.split(ans)
          action = args.pop(0)

          construct = current.construct()

          try:
            save = True
            if action == 'cd':
              /# Change directory
              current = current.cd(args[0])
            elif action == 'up':
              /# Move up to parent
              current = current.cd('..')
            elif action in ('p', 'print'):
              /# Print the current construct
              construct.write(indent='    ')
            elif action in ('s', 'symbols'):
              construct.symbols().show(indent='    ')
            elif action == 'ls':
              /# List the contents of the current node.
              current.list()
            elif action == 'pwd':
              /# List the contents of the current node.
              print(current.path())
            elif action in ('h', 'history'):
              /# List the history.
              for i, cmd in enumerate(history, start=1):
                print('%5d  %s' % (i, cmd))
            elif action[0] == '!':
              /# History reference.
              save = False
              rest = action[1:]
              if action[1] == '!':
                /# Previous command.
                given_arg = history[-1]
              elif rest.isdigit():
                /# Some other historical command.
                index = int(rest)
                given_arg = history[index]
              else:
                /# Error
                print('ERROR: Invalid history request "%s"' % ans)
            else:
              print('Unknown command "%s"' % action)
          except Exception as e:
            print('ERROR: %s' % str(e))
          else:
            if save:
              history.append(ans)
      end command shold;

      named
      command snapshot @ snap #:
        Create a snapshot.
      interface:
        flag release @ rel : bool = false #:
          If true, perform a release rather than a snapshot.
      scope:
        cli = self.cli()
        verbose = cli.verbose or True  # FIX ME
        self.__class__.MakeSnapshot(
          self.fs(), verbose=verbose, make_release=cli.release)
      end command snapshot;

      named
      command symbols #:
        Print out the symboltable of the specified fqns.
      scope:
        debug = False
        cli = self.cli()
        allargs = cli.rest
        if not allargs:
          print('usage: metac symbols {metafile}... {fqn}...')
          return
        argmap = self._parseArgs(
          /# We resolve so that we have access to the constructs.
          allargs, implicit=True, resolve=True, verbose=cli.verbosity > 1)

        /# Compile specified .meta files
        metafile_paths = argmap['metafiles']
        fp = sys.stdout
        try:
          metafiles, errors, warnings = self.getMetas(
            metafile_paths, debug=debug, fp=fp)
        except Exception as e:
          self.handleCompilationException(e)
          sys.exit(1)
        else:
          self.writeSummary(metafiles, groups=argmap['groups'])

        /# Print out desired symboltables.
        fqnmap = argmap['fqns']
        fp = sys.stdout
        for fqn in sorted(fqnmap):
          construct = fqnmap[fqn]['construct']
          if construct:
            construct.symbols().show(fp=fp, indent='')
      end command symbols;

      named
      command summarize #:
        Print out a summary of all specified metafiles.
      scope:
        metafiles = self.metafiles()
        pprint.pprint(metafiles)
        fs = self.fs()
        for metapath in sorted(metafiles):
          metafile = metafiles[metapath]
          if not isinstance(metafile, metax.c.MetaFile):
            /# TOOD(wmh): Why are 'schema' and 'schema_2' keys (with same
            /# values) in this mapping?
            continue
          path = fs.realpath(metapath)
          parts = path.split('/')
          subpath = '/'.join(parts[-3:])
          print(subpath)

          filecons = metafile.construct()
          for construct in filecons.attrval('scope:'):
            fkind = construct.kind()
            if fkind == 'namespace':
              print('  %s scope:' % construct.kindfqn())
              for ncons in construct.attrval('scope:'):
                print('    ' + ncons.kindid())
                if ncons.kind() == 'class':
                  for econs in ncons.attrval('scope:'):
                    print('      ' + econs.kindid())
            elif fkind == 'MetaLanguage':
              print('  %s config:' % construct.kindfqn())
              for mcons in construct.attrval('config:'):
                print('    ' + mcons.kindid())
      end command summarize;

      named
      command test #:
        Test specified namespaces/classes/methods.
      scope:
        cli = self.cli()
        argmap = self.argmap() or self._parseArgs(cli.rest, implicit=True)
        if argmap:
          targets = argmap['fqns']
          flags = self.cli()
          if targets:
            self.runUnitTests(
              targets.keys(), verbose=flags.verbose,
              basebinary=flags.basebinary)
          else:
            print('No targets given to command "test"')
        else:
          print('ERROR: no argmap')
      end command test;

      named
      command uml #:
        Generate a UML diagram of all classes in all specified metafiles.
      interface:
        flag display @ d : bool = false #:
          Display the UML diagram after generating it.
          By default, the image file is produced but not displayed.
        flag showuser : bool = true #:
          Display user-defined classes.
        flag showtest : bool = false #:
          Display testclasses.
        flag showmeta : bool = false #:
          Display metaclasses.
        flag fields @ f : bool = false #:
          Display fields
        flag methods @ m : bool = false #:
          Display methods
        flag size @ s : str = '17.5' #:
          Number of inches of width and height.
          TODO(wmh): Use a more sensible unit.
        flag destdir : str = './tmp' #:
          Directory to write files to.
      scope:
        cli = self.cli()
        fs = self.fs()

        argmap = self._parseArgs(cli.rest)
        errors = False
        paths = argmap['metafiles']
        if paths:
          config = {}
          if cli.fields:
            config['field'] = {}
          if cli.methods:
            config['method'] = {}
          metafiles = []
          for path in paths:
            metafile = self.getMeta(path, compile=False)
            if not metafile.hasErrors(show=True):
              metafiles.append(metafile)
          first = metafiles[0]
          destdir = cli.destdir
          if not fs.exists(destdir):
            fs.makedirs(destdir, 0o700)
          dotpath = fs.join(
            destdir, fs.basename(PathFromMeta(first.path(), '.dot')))
          self.generateUmlDiagram(
            metafiles, dotpath, config=config, display=cli.display,
            show_user=cli.showuser, show_meta=cli.showmeta,
            show_test=cli.showtest, size=cli.size)
          print('Wrote ' + dotpath)
        else:
          print('Must provide metafile(s) to generate uml for')
      end command uml;

      named
      command verify_bazel #:
        Test parsing of bazel logs relative to non-bazel test invocations.

        Verify that bazel test stdout/stderr matches expectations relative to an
        invocation of the test harness without bazel.
      scope:
        argmap = self.argmap()
        for fqn in argmap['fqns']:
          self.verifyBazelOutput(fqn)
      end command verify_bazel;

      named
      command vim #:
        Generate vim plug-in for the current meta language.
      scope:
        pass
      end command;

      command __default__ #:
        Compile specified .meta files.
      scope:
        fs = metac.fs()
        /# As a convenience, if all are .meta files or fqns, we assume the
        /# action is a combination of 'compile' and 'test.
        allargs = cli.rest
        command = allargs[0] if allargs else None
        argmap = theCompiler._parseArgs(
          allargs, implicit=True, verbose=cli.verbosity > 1)
        if (
          not argmap['args']
          and not argmap['badfiles']
          and (argmap['metafiles'] or argmap['fqns'])
        ):
          /# All args are .meta. or fqns. We parse/expand/compile the
          /# .meta files then invoke the blaze test targets associated with
          /# each fqn.
          metac.argmapIs(argmap)
          if metac._compile_command():
            /# Provide some special-case logic
            /#  - if cli.rawtests2 is set and there is exactly one .meta
            /#    source file being compiled and there are no explicit fqns
            /#    specified, then add all top-level fqns of the parsed
            /#    metafile.
            if (
              cli.rawtests2
              and len(argmap['metafiles']) == 1
              and len(argmap['fqns']) == 0
            ):
              sole_path = fs.realpath(argmap['metafiles'][0])
              sole_metafile = metac.metafiles()[sole_path]
              for namespace in sole_metafile.constructs()['namespace']:
                if namespace.isTest(): continue
                /# Implicitly add all non-test namespaces in the sole metafile
                /# we compiled.
                nmsp = namespace.id()
                print('NOTE: Implicitly testing namespace %s' % nmsp)
                argmap['fqns'][nmsp] = {}

            if argmap['fqns']:
              metac._test_command()
        elif argmap['args']:
          print('ERROR: Unknown args: %s' % ' and '.join(argmap['args']))
        else:
          /# pprint.pprint(argmap)
          print('ERROR: Unknown command "%s"' % command)
        if cli.showfs or fs.kind() == 'memory':
          fp = sys.stdout
          fs.summarize(fp=fp)
      end command __default__;
    end command metac;

  end class Compiler;

  abstract
  class MetaEnv #:
    A superclass of classes for defining code that uses a Meta-Language.
  assocs:
    std assoc metastrap #:
      /# Not really std ... make a target!
    cls assoc metax.c.Compiler;
  scope:

    field metal : str #:
      The id of the metalang

    field basel : str #:
      The id of the baselang. May be null if the metalang doesn't have baselangs

    field metac : metax.c.Compiler scope:
      accessor get lazy:
        metac = metastrap.DynamicCompiler(self.metal(), self.basel())
        -> metac

    lifecycle params:
      var metal -> metal;
      var basel -> basel = null;
    scope:
    setup:
      /# Intentionally using Meta(Meta) as that is faster to parse. Use
      /# Meta(Meta) input, like testdata/ex1.meta, not ex2, ex3, or ex4.
      test.metaenv = metax.c.MetaEnv('meta', basel='stub')
    end;

    method parseMeta : tuple<MetaFile,vec<Construct>> #:
      Parse a Meta<basel>(metal) source file into constructs.
    params:
      var metapath : str #:
        The .metabio file to parse.
    scope:
      metac = self.metac()
      metafile = metac.parseMeta(metapath)
      if metafile.hasErrors(show=True):
        result = None
      else:
        /# list of toplevel constructs.
        result = metafile.construct().attrval('scope:')
      return metafile, result
    test:
      metapath = test.resourcePath('ex1')
      metafile, constructs = test.metaenv.parseMeta(metapath)
      test.iseq('MetaLanguage Test', constructs[0].kindfqn())
    end method parseMeta;

    method compileMeta : MetaFile #:
      Perform expansion, importation, translation and compilation.

      Returns:
        The MetaFile instnace. If a 'metafile' keyword is passed in, the return
        will be the same. If not passed in, a new instance is created and
        returned.
    params:
      var path : str = null #:
        The .meta file to process. Can be null if metafile provided.
      var metafile : MetaFile = null #:
        The MetaFile instance to compile into. If not present, a new instance
        is created.
      var expand : bool = true #:
        If false, do not expand (or import or translate or compile)
      var imports : bool = true #:
        If false, do not import (or translate or compile)
      var translate : bool = true #:
        If false, do not translate (or compile)
      var compile : bool = true #:
        If false, do not compile.
    scope:
      metac = self.metac()
      if path is None:
        if metafile is None:
          raise Error('Must provide one of path or metafile')
        path = metafile.path()
      newfile, errors, warnings = metac.processMeta(
        path, metafile=metafile,
        expand=expand, imports=imports, translate=translate, compile=compile)
      if metafile:
        assert newfile is metafile
      return newfile
    test:
      metapath = test.resourcePath('ex1')
      metafile = test.metaenv.compileMeta(metapath)
      test.isinst(metafile, metax.c.MetaFile)
    end method compileMeta;

  end class MetaEnv;

  class GithubRepo #:
    Interface to github
  assocs:
    std assoc json;
    std assoc requests;
  scope:
    field owner : str #:
      The repo owner.
    field name : str #:
      The name of the repository

    lifecycle params:
      var owner -> owner;
      var name -> name;
    scope:
    end;

    method newIssue : any #:
      Create a new github issue.
    params:
      var title : str #:
        Title of issue.
      var body : str = null #:
        The content of the issue.
      var dates : map = null #:
        Maps zero or more of the keys 'created', 'closed', 'updated' to
        either datetime.datetime instances or strings in the format
        'YYYY-mm-ddTHH:MM:SSZ'.
      var assignee : str = null #:
        Who to assign to.
      var milestone : int = null #:
        ???
      var closed : bool = false #:
        If true, mark issue as closed.
      var labels : vec<str> = null #:
        Labels to add.
      var username : str = null #:
        The github username attempting to create the issue. By default, this
        is self.owner(). Must be someone with read/write access to the repo!
      var token : str = null #:
        A token to use for authentication.
        https://developer.github.com/v3/oauth_authorizations/\#create-a-new-authorization
      var password : str = null #:
        The password to use for authentication.
        One of token or password must be provided.
    scope:
      /# See https://gist.github.com/JeffPaine/3145490
      url = 'https://api.github.com/repos/%s/%s/import/issues' % (
        self.owner(), self.name())
        
      issue = {
        'title': title,
        'body': body,
        'assignee': assignee,
        'milestone': milestone,
        'closed': closed,
        'labels': labels,
      }
      if dates:
        for key in dates:
          date = dates[key]
          gitkey = key + '_at'
          if isinstance(date, datetime.datetime):
            datestr = date.strftime('%Y-%m-%dT%H:%M:%SZ')
          else:
            datestr = date
          issue[gitkey] = datestr

      if username is None:
        username = self.owner()

      session = requests.Session()
      data = {'issue': issue}
      payload = json.dumps(data)
      headers = {
        'UserAgent': 'metaeseque',
        'Accept': 'application/vnd.github.golden-comet-preview+json',
      }
      if password:
        session.auth = (username, password)
      elif token:
        headers['Authorization'] = 'token %s' % token
      else:
        raise Error('Must provide one of password or token.')
      r = session.post(url, data=payload, headers=headers)
      print('**** HERE with %s' % r.status_code)
      print(r.content)
      print(r.json())
      if r.status_code == 202:
        print('Successfully created Issue %s' % title)
      else:
        print('Could not create Issue %s' % title)
        print('Response: ' + r.content)
    test:
      repo = metax.c.GithubRepo('metaesque', 'meta')

      /# **** FIX ME! How to get token?
      /# when fixed, we don't actually want to create bugs every time this
      /# test is invoked, so do something else here.
      return

      res = repo.newIssue(
        title = 'Pretty title',
        body = 'Beautiful body',
        created_at = '2014-01-01T12:34:58Z',
        closed_at = '2014-01-02T12:24:56Z',
        updated_at = '2014-01-03T11:34:53Z',
        assignee = 'username',
        milestone = 1,
        closed = False,
        labels = ['bug', 'low', 'energy'])
  end class GithubRepo;

  class MetaNode #:
    Represents a node in the virtual filesystem represening a metafile.
  assocs:
    std assoc collections;
  scope:
    field parent : MetaNode #:
      Parent node.
    field path : str #:
      The full path of this node.
    field construct : Construct #:
      The construct of this node.
    field children : map<str,MetaNode> #:
      The child nodes (order of insertion maintained).

    lifecycle params:
      var parent -> parent;
      var construct -> construct;
    scope:
      self.childrenIs(collections.OrderedDict())
      if parent:
        path = parent.path() + '/' + construct.id()
      else:
        path = ''
      self.pathIs(path)
    setup:
      test.defineClassAndMethods('py')
      test.root = metax.c.MetaNode(None, test.filecons)
      test.namespace_node = metax.c.MetaNode(test.root, test.namespace)
    end;

    method addChild : MetaNode #:
      Add a child construct to this node.
    params:
      var construct : Construct;
    scope:
      cls = self.__class__
      cid = construct.id()
      subnode = cls(self, construct)
      self.children()[cid] = subnode
      return subnode
    test:
      node = test.root
      test.iseq([], node.children().keys())
      node.addChild(test.method)
      test.iseq(['show'], test.root.children().keys())
    end method addChild;

    method populate #:
      Add child nodes based on constructs in scope: that match kinds
    params:
      var kinds : map<str,vec<str>> #:
        Maps kind to list of child kinds to register.
    scope:
      construct = self.construct()
      children = construct.attrval('scope:', default=None) or []
      ckinds = kinds[construct.kind()]
      for child in children:
        ckind = child.kind()
        if ckind not in ckinds: continue
        childnode = self.addChild(child)
        if ckind in kinds:
          childnode.populate(kinds)
    test:
      test.iseq(0, len(test.root.children()))
      test.root.populate(
        {'File': ['namespace'], 'namespace': ['class'], 'class': ['field', 'method']})
      test.iseq(1, len(test.root.children()))
      namespace_node = test.root.children()['nm.sp']
      class_node = namespace_node.children()['Card']
      method_node = class_node.children()['show']
    end method populate;

    method cd : MetaNode #:
      Return a new node based on path.
    params:
      var path : str #:
        The path to change to. Supports '..' for parent and '.' for self.
    scope:
      node = self
      error = False
      parts = path.split('/')
      if parts[0] == '':
        parts.pop(0)
        while node.parent():
          node = node.parent()
      for part in parts:
        if part == '..':
          if node.parent():
            node = node.parent() 
        elif part == '.':
          pass
        else:
          children = node.children()
          subnode = children.get(part, None)
          if subnode:
            node = subnode
          else:
            print('ERROR: failed to find "%s" within "%s"' % (part, node.path()))
      return self if error else node
    test:
      test.root.populate(
        {'File': ['namespace'], 'namespace': ['class'], 'class': ['field', 'method']})
      mnode = test.root.cd('/nm.sp/Card/show')
      test.iseq('/nm.sp/Card/show', mnode.path())
    end method cd;

    method list #:
      List the children of the current node
    params:
      var fp : ostream = out #:
        Where to write output.
    scope:
      for cid, child in self.children().items():
        fp.write(u'' + cid + '\n')
    test:
      node = test.root
      node.addChild(test.method)
      test.iseq(['show'], test.root.children().keys())
      node.list(fp=test.fp())
      out = test.out()
      test.iseq('show\n', out)
    end method list;

  end class MetaNode;

  test
  native scope:
    /# IMPORTANT: TestCase.cachedInfo() returns a cached
    /# baselang/metalang/context/compiler. Assuming none of the test code
    /# modifies the schema/context/compiler, it should be safe to use these
    /# cached values across different tests. However, if you see odd behavior,
    /# consider not using cachedInfo() in specific tests.
    COMPILERS = {}

    /# Odd behavior was indeeded discovered with cachedInfo(), because it reuses
    /# compiler instances, which maintains a mapping from fqn to class, so
    /# anytime registerClass() is invoked twice on the same compiler, we get
    /# warnings.  The slow part of new compilers for each test is parsing the
    /# metalang schema files, so we instead cache schemas.
    METALANGS = {}

    /# For timing things.
    TIME = {}
    def Time(label='?', start=False, timing=False):
      tm = TIME.get('time', 0)
      if timing:
        TIME['timing'] = True
      newtm = time.time()
      TIME['time'] = newtm
      if not start and TIME.get('timing', False):
        print('%s took %1.6fs' % (label, newtm - tm))
  end;

  test
  class TestCase < metax.test.TestCase assocs:
    std assoc io;
    std assoc optparse;
    std assoc time;
    std assoc metastrap #:
      /# TODO(wmh): This is not actually std, but rather lib ... we need to
      /# establish an appropriate build target for it.
    resource testdata path "./testdata";
    resource ex1 path "./testdata/ex1.meta";
    resource ex2 path "./testdata/ex2.meta";
    resource ex3 path "./testdata/ex3.meta";
    resource ex4 path "./testdata/ex4.meta";
    resource cards1 path "./testdata/cards1.meta";
    resource cards2 path "./testdata/cards2.meta";
    resource cards3 path "./testdata/cards3.meta";
    resource sample_logs path "./testdata/sample_logs";
  scope:

    lifecycle clsetup:
      metastrap.Setup()

      /# Populate the METALANGS cache.
      compiler = metax.c.Compiler(metal='oopl', basel='python')
      METALANGS = copy.copy(compiler.metalangs())

    setup:
      /# To ensure complete independence between tests, we should consider
      /# clearing the MetaLanguage repository.
      /# TODO(wmh): Why am I not do this? Too expensive time-wise?
      /# metax.c.MetaLanguage.Repository = {}

      /# Configure the Compiler and parse a command line.
      root_command, _, cli = metax.c.Compiler.Bootstrap(['dummy-binary'])

      /# Useful testcase variables.
      self.command = root_command
      self.cli = cli
      self._oopl = None
      self._meta = None
      self.compiler = None

      self.metameta_consids = [
        'Attribute', 'BaseLanguage', 'Construct', 'FeatureValue', 'File',
        'MetaLanguage', 'Template'
      ]
      self.metaoopl_consids = [
        'Attribute', 'BaseLanguage', 'Construct', 'FeatureValue', 'File',
        'MetaLanguage', 'Template',
        'accessor', 'assoc', 'behavior', 'block',
        'case', 'category', 'class', 'command',
        'field', 'flag',
        'lifecycle', 'loop', 'method', 'namespace', 'native',
        'receiver', 'remark', 'resource', 'switch', 'testx', 'var',
      ]
      self.metaoopl_consids2 = [
        'Attribute', 'BaseLanguage', 'Construct', 'FeatureValue', 'File',
        'MetaLanguage', 'Template',
        'accessor', 'assoc', 'behavior', 'block',
        'case', 'category', 'class', 'command',
        'field', 'flag',
        'lifecycle', 'loop', 'method', 'namespace', 'native', 'receiver',
        'remark', 'resource', 'switch', 'testx', 'var',
      ]

      self._invoked_fixenv = False

      test.samples = {
        'meta': """
          >|MetaLanguage test name Test parent meta toplevel <special> config:
          >|  Construct special clsname CC config:
          >|    primary Attribute special : id = <required;
          >|  scope:
          >|  end Construct special;
          >|
          >|  BaseLanguage base name Base suffixes <base>;
          >|end MetaLanguage;
          >|""",

        /# NOTE: We are NOT adding simple-block text to the methods in the
        /# following, so that we can use this text for ALL baselangs.
        /# TODO(wmh): Change type of height to metax.units.Length, and weight
        /# to metax.units.Mass.
        'oopl': """
          >|namespace demo.tmp scope:
          >|  class Person #:
          >|    First line should be oneline summary.
          >|
          >|    Subsequent lines are for more details and can be formatted in
          >|    Meta(Doc) syntax.
          >|  assocs:
          >|    std assoc os;
          >|  scope:
          >|    field name : str;
          >|    field height : float;
          >|    field weight : float;
          >|
          >|    lifecycle Person params:
          >|      var name -> name;
          >|      var height -> height;
          >|      var weight -> weight;
          >|    scope:
          >|    end;
          >|
          >|    method bmi : float #:
          >|      Calculate body mass index of this person.
          >|      Result is unitless, but relies on height in meters and
          >|      weight in kilograms.
          >|    scope:
          >|    end;
          >|
          >|    method show params: 
          >|      var fp : ostream = out; 
          >|      var indent : str = ''; 
          >|    scope:
          >|    end;
          >|
          >|    cls method ClassMethod ::
          >|    end;
          >|
          >|    static method StaticMethod ::
          >|    end;
          >|
          >|  end;
          >|
          >|  behavior uid : str scope:
          >|    receiver Person ::
          >|      return '1234'
          >|  end behavior;
          >|
          >|class Student < Person #:
          >|  Intentionally at File scope rather than namespace scope.
          >|scope:
          >|end class Student;
          >|
          >|class Error < metax.c.Error;
          >|
          >|test
          >|class TestCase < metax.test.TestCase scope:
          >|  lifecycle setup:
          >|    test.obj = 1
          >|end class TestCase;
          >|""",
        /# TODO(wmh): Remove reliance on 'statements' below in favor of
        /# ooplstmts.
        'ooplstmts': """
          >|namespace demo.tmp scope:
          >|  class Person #:
          >|    First line should be oneline summary.
          >|    Subsequent lines are for more details and
          >|    can be formatted in Meta(Doc) syntax.
          >|  scope:
          >|
          >|    field name : str;
          >|    field height : float;
          >|    field weight : float;
          >|
          >|    lifecycle Person params:
          >|      var name -> name;
          >|      var height -> height;
          >|      var weight -> weight;
          >|    scope:
          >|    end;
          >|
          >|    method bmi : float scope<*>:
          >|      var f : int;
          >|      var g : int = 17;
          >|      var v : vec<int>;
          >|
          >|      loop l1 on i over v ::
          >|        print(i)
          >|
          >|      loop j over v ::
          >|        print(j)
          >|
          >|      switch s1 on f scope:
          >|        case expr 1 ::
          >|          v = 1
          >|        case expr 2 ::
          >|          v = 7
          >|      end;
          >|
          >|      switch h scope:
          >|        case (f == 1) ::
          >|          v = 1
          >|        case (f == 2) ::
          >|          v = 7
          >|    end method bmi;
          >|
          >|    method show params: 
          >|      var fp : ostream = out; 
          >|      var indent : str = ''; 
          >|    scope:
          >|    end;
          >|
          >|  end class Person;
          >|end namespace demo.tmp;
          >|
          >|class Student < Person #:
          >|  Intentionally at File scope rather than namespace scope.
          >|scope:
          >|end class Student;
          >|""",
        /# TODO(wmh): Remove following in favor of 'ooplstmts' above
        'statements': """
          >|namespace demo.tmp scope:
          >|  class Test scope:
          >|    method test scope<*>:
          >|      var f : int;
          >|      var g : int = 17;
          >|      var v : vec<int>;
          >|
          >|      loop l1 on i over v ::
          >|        print(i)
          >|
          >|      loop j over v ::
          >|        print(j)
          >|
          >|      switch s1 on f scope:
          >|        case expr 1 ::
          >|          f = 1
          >|        case expr 2 ::
          >|          f = 7
          >|      end;
          >|
          >|      switch h scope:
          >|        case expr 1 ::
          >|          f = 1
          >|        case expr 2 ::
          >|          f = 7
          >|      end;
          >|    end method test;
          >|  end class Test;
          >|end namespace demo.tmp;
          >|""",
         /# For testing command/flag/arg
         'cmds': """
         >|namespace demo.tmp scope:
         >|  class Test scope:
         >|    command testmain
         >|    interface:
         >|      flag bool @ b : bool = false;
         >|      flag ival @ i : int = 10;
         >|      flag sval @ s : str = 'hello';
         >|      arg first : int;
         >|      arg second : str;
         >|      command sub
         >|      interface:
         >|        flag list @ l : vec<str>;
         >|      scope:
         >|        b = 2
         >|      end;
         >|    scope:
         >|      a = 1
         >|    end;
         >|  end class;
         >|end namespace;
         >|""",
      }
    teardown:
      self.unfixenv()
    end lifecycle;

    method tpy #:
      See newbasic
    params:
      var statements : bool = False #:
        If true, include statements.
      var expand : bool = False #:
        If true, invoke expandMeta on the metafile
      var imports : bool = False #:
        If true, invoke importMeta on the metafile
      var translate : bool = False #:
        If true, invoke translateMeta on the metafile
      var compile : bool = False #:
        If true, invoke compileMeta on the metafile
    scope:
      self.newbasic(
        'python', statements=statements,
        expand=expand, imports=imports, translate=translate, compile=compile)
    end method tpy;   

    method tcc #:
      See newbasic
    params:
      var statements : bool = False #:
        If true, include statements.
      var expand : bool = False #:
        If true, invoke expandMeta on the metafile
      var imports : bool = False #:
        If true, invoke importMeta on the metafile
      var translate : bool = False #:
        If true, invoke translateMeta on the metafile
      var compile : bool = False #:
        If true, invoke compileMeta on the metafile
    scope:
      self.newbasic(
        'cpp', statements=statements,
        expand=expand, imports=imports, translate=translate, compile=compile)
    end method tcc;   

    method tjs #:
      See newbasic
    params:
      var statements : bool = False #:
        If true, include statements.
      var expand : bool = False #:
        If true, invoke expandMeta on the metafile
      var imports : bool = False #:
        If true, invoke importMeta on the metafile
      var translate : bool = False #:
        If true, invoke translateMeta on the metafile
      var compile : bool = False #:
        If true, invoke compileMeta on the metafile
    scope:
      self.newbasic(
        'javascript', statements=statements,
        expand=expand, imports=imports, translate=translate, compile=compile)
    end method tjs;   

    method newbasic #:
      Preferred method to use to initialize the following test fields:
        metafile  (for samples text named 'oopl')
        context
        compiler  (oopl <basel>)
        baselang  (<basel>)
        metalang  (oopl)
        file      (the FileConstruct within the metafile)
        namespace (demo.tmp)
        klass     (demo.tmp.Person)
        field     (demo.tmp.Person.name)
        method    (demo.tmp.Person.bmi)
        cscope    (ComplexBlock for scope: of sample class construct)
        mscope    (ComplexBlock if statements == True else SimpleBlock)
        behavior  (demo.tmp.uid)

      If statements is True, the following are also defined.
       loop      (demo.tmp.Person.bmi.l1)
       switch    (demo.tmp.Person.bmi.s1)
    params:
      var basel : str #:
        The basel to compile into.
      var statements : bool = False #:
        If true, include statements.
      var expand : bool = False #:
        If true, invoke expandMeta on the metafile
      var imports : bool = False #:
        If true, invoke importMeta on the metafile
      var translate : bool = False #:
        If true, invoke translateMeta on the metafile
      var compile : bool = False #:
        If true, invoke compileMeta on the metafile
    scope:
      timing = False  # set this True to see timing information
      sample_key = 'ooplstmts' if statements else 'oopl'
      test.prepMeta(
        name=sample_key, basel=basel, timing=timing,
        expand=expand, imports=imports, translate=translate, compile=compile)

      /# Obtain the various contructs used in tests.
      test.method = test.file.child('/demo.tmp/Person/bmi')
      test.klass = test.method.parentConstruct()
      test.namespace = test.klass.parentConstruct()
      test.nscope = test.namespace.attr('scope:')
      test.cscope = test.klass.attr('scope:')
      test.field = test.cscope.cons('name')
      test.lifecycle = test.cscope.cons('Person')
      test.mscope = test.method.attr('scope:')  # simplex
      test.method2 = test.cscope.cons('show')

      if statements:
        /# mscope is ComplexBlock (if statement is False, it is SimpleBlock)

        /# We validate that the auto-assigned ids haven't changed.
        test.iseqvec(
          ['var f', 'var g', 'var v',
           'loop l1', 'loop Meta__1__',
           'switch s1', 'switch Meta__4__'],
         [c.kindid() for c in test.mscope.value()])

        /# Now obtain some statements.
        test.loop = test.mscope.cons('l1')
        test.loop2 = test.mscope.cons('Meta__1__')
        test.switch = test.mscope.cons('s1')
        test.switch2 = test.mscope.cons('Meta__4__')
      else:
        /# The behavior is not defined in ooplstms, only oopl
        test.behavior = test.nscope.cons('uid')
    test:
    end method newbasic;

    method prepMeta : any #:
      Parse meta source code (either explicit text or named in test.samples).

      Sets following test fields:
        compiler  (oopl <basel>)
        context
        metafile  (for samples text named 'oopl')
        baselang  (<basel>)
        metalang  (oopl)
        file      (the FileConstruct within the metafile)
    params:
      var name : str = null #:
        A key into self.samples representing text to parse. This or text
        must be provided.
      var text : str = null #:
        Meta source text to parse. This or text must be provided.
      var basel : str = 'python' #:
        baselang to compile text into.
      var timing : bool = false #:
        If true, time certain actions.
      var expand : bool = False #:
        If true, invoke expandMeta on the metafile
      var imports : bool = False #:
        If true, invoke importMeta on the metafile
      var translate : bool = False #:
        If true, invoke translateMeta on the metafile
      var compile : bool = False #:
        If true, invoke compileMeta on the metafile
    scope:
      Time(start=True, timing=timing)

      if text is None:
        if name is None:
          raise metax.c.Error('Must provide text or name')
        text = test.samples[name]

      debuglevel = 0
      metal = 'oopl'
      test.compiler = metax.c.Compiler(
        metal=metal, basel=basel, metalangs=METALANGS)
      Time('Creation')

      test.baselang = test.compiler.baselang()
      test.metalang = test.compiler.metalang()

      test.context = test.metalang.context()
      test.metafile = metax.c.MetaFile(
        '/faux/path.meta', test.compiler, text,
        debuglevel=debuglevel)
      Time('MetaFile')

      /# Important to set these for proper execution in various situations.
      test.context.compilerIs(test.compiler)
      test.metafile.contextIs(test.context)
      test.baselang.contextIs(test.context)

      /# Parse the metafile.
      test.metafile.parseMeta(test.context)
      Time('parseMeta')

      if expand:
        test.metafile.expandMeta()
        Time('expandMeta')
      if imports:
        test.metafile.importMeta()
        Time('importMeta')
      if translate:
        test.metafile.translateMeta()
        Time('translateMeta')
      if compile:
        test.metafile.compileMeta()
        Time('compileeMeta')

      test.file = test.metafile.construct()
    end method prepMeta;

    method basics : Construct #:
      Create a compiler, context and construct.
    params:
      var metal : str = 'meta';
      var basel : str = null;
    scope:
      _, _, _, compiler = test.cachedInfo(metal=metal, basel=basel)
      test.compiler = compiler

      context = compiler.bootstrapContext()
      test.context = context
      metafile = metax.c.MetaFile('/faux/a.meta', compiler, 'fake text')
      test.metafile = metafile
      /# Create
      /#   file a.meta scope:
      /#     namespace nm.sp scope:
      /#       public class Person scope:
      /#       end;
      context.metafileIs(metafile)
      file = metax.meta.FileConstruct('a.meta', None, context)
      file_scope = metax.attr.ComplexBlock(file, 'scope:', [], line=0, col=12)
      file.registerAttribute(file_scope)
      namespace = metax.oopl.NamespaceConstruct('nm.sp', file_scope, context)
      file_scope.registerConstruct(namespace)
      namespace_scope = metax.attr.ComplexBlock(
        namespace, 'scope:', [], line=1, col=18)
      namespace.registerAttribute(namespace_scope)
      klass = metax.oopl.ClassConstruct('Person', namespace_scope, context)
      klass.namespaceIs(namespace)
      feature = metax.attr.FeatureAttribute(
        klass, 'visibility', 'public', line=1, col=0)
      klass.registerAttribute(feature)
      primary = metax.attr.IdAttribute(klass, 'class', 'Person', line=1, col=10)
      klass.registerAttribute(primary)
      namespace_scope.registerConstruct(klass)
      class_scope = metax.attr.ComplexBlock(klass, 'scope:', [], line=2, col=17)
      klass.registerAttribute(class_scope)
      klass.termcodeIs(3)

      test.construct = klass
      return klass
    end method basics;

    method metafileFor : MetaFile #:
      Obtain a parser for given text written in a specific metalang.
    params:
      var text : str = null #:
        The text representing the metafile. Either this or 'name' must be
        specified.
      var name : str = null #:
        The name of a key in test.samples (i.e. named text). Either this or
        text must be specified.
      var metal : str = 'oopl';
      var basel : str = null;
      var debuglevel : int = 0;
    scope:
      assert name is not None or text is not None, 'Must provide name or text'
      _, metalang, context, compiler = self.cachedInfo(metal=metal, basel=basel)
      context.compilerIs(compiler)
      if text is None:
        if not name:
          raise Error('Must provide text or name')
        text = test.samples[name]
      metafile = metax.c.MetaFile(
        '/faux/path.meta', compiler, text, debuglevel=debuglevel)
      metafile.contextIs(context)
      return metafile
    end method metafileFor;

    method constructInCode : metax.meta.Construct #:
      Parse text representig a metafile and return a construct within it.

      Important: The constructs have been parsed (via parseMeta()), but no
      expanding, translating or compiling has been done.
    params:
      var child : str #:
        The path to the desired construct within the text.
      var text : str = null #:
        The text representing the metafile. Either this or 'name' must be
        specified.
      var name : str = null #:
        The name of a key in test.samples (i.e. named text). Either this or
        text must be specified.
      var metal : str = 'oopl';
      var basel : str = null;
      var debuglevel : int = 0;
    scope:
      metafile = self.metafileFor(
        text=text, name=name, metal=metal, basel=basel, debuglevel=debuglevel)
      metafile.parseMeta(test.context)
      if metafile.hasErrors(show=True):
        return None
      file_construct = metafile.construct()
      if child:
        fp = io.StringIO()
        result = file_construct.child(child, fp=fp)
        if result is None:
          print('In constructInCode, child "%s" produced errors:' % child)
          print(fp.getvalue())
      else:
        result = file_construct

      test.metafile = metafile
      return result
    test:
    end method constructInCode;

    method fixenv #:
      Set some required environment variables to faux values.
    scope:
      /# Define some environment variables required by Meta
      _, _, _, metameta = test.cachedInfo(metal='meta')
      fs = metameta.fs()
      fs.setenv('METAREP', '/some/path/meta/rep')
      /# Set to /tmp so that the directory exists in bazel (albeit readonly)
      fs.setenv('METAROOT', '/tmp')
      self._invoked_fixenv = True
    end method fixenv;

    method unfixenv #:
      Undo changes made in fixenv
    scope:
      if self._invoked_fixenv:
        _, _, _, metameta = test.cachedInfo(metal='meta')
        fs = metameta.fs()
        fs.unsetenv('METAREP')
        fs.unsetenv('METAROOT')
    end method unfixenv;

    method flags : any #:
      The (default) command-line flags
    scope:
      /# TODO(wmh): This is a subset of the flags defined in metameta.
      /# Find a way to merge the two in such a way that we do not need
      result = metax.c.Compiler.Flags()
      if result is None:
        options = optparse.OptionParser()
        options.add_option(
          '-A', '--debug', dest='debug', default=0, type='int',
          help='Control debugging level')
        options.add_option(
          '-b', '--baselang', dest='baselang', default='python',
          help='The base language to compile into.')
        options.add_option(
          '-L', '--metalang', dest='metalang', default='oopl',
          help='The meta language we are compiling')
        options.add_option(
          '--metadir', dest='metadir', default=metax.c.SPECIAL_CHILD_DIR,
          help='The subdir to write code to')
        options.add_option(
          '-M', '--inmemory', action='store_true', dest='inmemory', default=False,
          help='If True, use memory filesystem instead of disk filesystem.')
        options.add_option(
          '-O', '--optimize_level', dest='optimize_level', default='high', type='choice',
          choices=['off', 'low', 'avg', 'high', 'max'],
          help='The amount of optimization to enable compiled files.')
        options.add_option(
          '-V', '--version', action='store', dest='version', default='current',
          help='Which version of the meta library to use (beta, current, previous).')

        /# Note that we request the filesystem be inmemory, for two reasons:
        /#  - it is messy to get access to the real filesystem within bazel
        /#    (and it is readonly anyways)
        /#  - unittests are an exceelent mechanism for verifying that inmemory
        /#    support is working properly.
        result, _ = options.parse_args(
          ['executable', '--inmemory'])

        assert result.inmemory

        metax.c.Compiler.FlagsIs(result)
      return result
    end method flags;

    method defineAttributes #:
      Create some test attribute instances.
    scope:
      construct = self.basics()
      compiler = self.compiler
      context = self.context

      self.feature = metax.attr.FeatureAttribute(
        construct, 'gender', 'male', line=10, col=2)
      self.id = metax.attr.IdAttribute(
        construct, 'person', 'bob', line=10, col=9)
      self.num = metax.attr.NumAttribute(
        construct, 'count', '42', line=10, col=40)
      self.word = metax.attr.WordAttribute(
        construct, 'default', '<special>', line=10, col=51)
      self.simple = metax.attr.SimpleBlock(
        construct, 'comment:',
        ['this is a', 'test of a simple block'],
        line=11, col=2)

      /# TODO(wmh): Make some constructs to add to this complex block.
      self.complex = metax.attr.ComplexBlock(
        construct, 'scope:', [], line=14, col=2)

      expr = metax.c.Expr('str', '"this is a test"', '"this is a test"')
      self.expr = metax.attr.ExprAttribute(
        construct, 'value', expr, line=10, col=50)

      self.type = metax.attr.TypeAttribute(
        construct, 'type', metax.c.Type.Instance('vec<str>'), line=20, col=42)

      self.enum = metax.attr.EnumAttribute(
        construct, 'fruit', '<apple|banana|cantelope>', line=30, col=17)
    end method defineAttributes;

    method defineConstructs #:
      Create some test construct instances.
    scope:
      test.defineAttributes()
      construct = test.construct
      construct.registerAttribute(test.feature)
      primary = metax.attr.IdAttribute(construct, construct.kind(), construct.id())
      construct.registerAttribute(primary)
      construct.registerAttribute(test.id)
      construct.registerAttribute(test.num)
      construct.registerAttribute(test.word)
      construct.registerAttribute(test.expr)
      construct.registerAttribute(test.type)
      construct.registerAttribute(test.enum)
      construct.registerAttribute(test.simple)
      construct.registerAttribute(test.complex)
      construct.termcodeIs(7);
      return construct
    end method defineConstructs;

    method resourcePath : str #:
      Obtain the path to a resource given the resource name (only for
      resources defined on this class).
      TODO(wmh): Improve metax.root.Object.Resource() to accept an xid
      resname instead of having to pass fqn as a second param).
    params:
      var name : str #:
        The name of a resource defined on TestCase.
    scope:
      result = metax.root.Object.Resource(name, fqn='metax.c_test.TestCase')
      _, _, _, metameta = test.cachedInfo(metal='meta')
      fs = metameta.fs()
      if not fs.exists(result):
        raise metax.c.Error('Resource "%s" (%s) does not exist' % (name, result))
      return result
    end method resourcePath;

    method getMetaFile
    returns tuple<metax.c.MetaFile,metax.attr.ComplexBlock,metax.meta.MetaLanguageConstruct,str>
    params:
      var metal : str #:
        The metalang id.
      var resname : str #:
        The resource name to obtain.
      var context : Context = null #:
        If null, uses compiler.metalang().context().
      var compiler : Compiler = null #:
        Which compiler instance to use.
      var debuglevel : int = 0;
      var expand : bool = false #:
        If true, expand the metafile
      var imports : bool = false #:
        If true, import the metafile deps
    scope:
      path = metax.root.Object.Resource(resname, fqn='metax.c_test.TestCase')

      if compiler:
        metalang = compiler.metalang()
        assert metalang.id() == metal, 'Metalang %s != %s' % (metalang.id(), metal)
      else:
        _, metalang, _, compiler = self.cachedInfo(metal=metal)
        self.compiler = compiler

      if imports and not expand:
        expand = True

      if context is None:
        context = metalang.context()

      /# TODO(wmh): It may be dangerous to re-use a pre-existing parsed file
      /# here!
      fs = compiler.fs()
      realpath = fs.realpath(path) if fs.exists(path) else path
      metafile = compiler.metafiles().get(realpath, None)
      if metafile is None:
        metafile = compiler.parseMeta(
          realpath, debuglevel=debuglevel, context=context)
        if expand and not metafile.hasErrors():
          metafile.expandMeta()
          if imports and not metafile.hasErrors():
            metafile.importMeta()
      else:
        /# print('REUSING %s' % path)
        pass

      file = metafile.construct()
      scope = file.rawattr('scope:')
      value = scope.value()
      construct = value[0] if value else None
      return metafile, scope, construct, path
    end method getMetaFile;

    method schemaParser : tuple<MetaFile,Context> #:
      Create a parser for provided schema text.
    params:
      var text : str #:
        A multi-line string representing a Meta(Meta) file.
    scope:
      test.basics()
      compiler = self.compiler
      context = self.context
      metafile = metax.c.MetaFile('fauxpath', compiler, text, debuglevel=0)
      metafile.contextIs(context)
      context.metafileIs(metafile)
      return metafile, context
    end method schemaParser;

    method newTestSchema : tuple<metax.meta.MetaLanguageConstruct,Context,MetaFile>
    params:
      var text : str #:
        The text making up the metalang schema file.
    scope:
      metafile, context = self.schemaParser(text)
      schema = metax.meta.MetaLanguageConstruct('Test', None, context)
      return schema, context, metafile
    test:
    end method newTestSchema;

    method context : Context #:
      Obtain a Context instance for use in a test.
    scope:
      return self.cachedInfo()[2]
    test:
    end method context;

    method getTestCompiler : Compiler #:
      Obtain a Compiler instance whose filesystem is setup to read from
      ./testdata/repo (writing disallowed by making the directory readonly).
    params:
      var metal : str = 'oopl';
      var basel : str = 'python';
    scope:
      /# NOTE: We intentionally create a new instance each time this is
      /# called, because:
      /#  - Compiler and Filesystem construction is not that expensive
      /#  - this method won't be used all the time and it is best for us to
      /#    be in a clean slate for those test methods that really need it.
      repo_path = metax.root.Object.Resource(
        'test_repo', fqn='metax.c.Compiler')
      compiler = metax.c.Compiler(
        metal=metal, basel=basel, kind='disk',
        rootdir=repo_path, metadir='.', repodir=repo_path)
      return compiler
    end method getTestCompiler;

    method cachedInfo : tuple<BaseLanguage,MetaLanguage,Context,Compiler> #:
      Obtain a cached set of important objects

      SideEffects:
        Sets each of the following fields on the testcase instance:
          baselang
          metalang
          context
          compiler
    params:
      var basel : str = null #:
        The name/id/alias/suffix of a baselang.
      var metal : str = null #:
        The name of the metalang. Needs to be explicitly set to 'meta' if
        the basel isn't for oopl.
    scope:
      if metal is None:
        metal = 'oopl'
      if basel is None:
        defaults = {
          'meta': 'stub',
          'oopl': 'python',
          'doc': 'html',
        }
        basel = defaults[metal]

      key = '%s/%s' % (metal, basel)

      compiler = COMPILERS.get(key, None)
      if compiler is None:
        compiler = metax.c.Compiler(metal=metal, basel=basel)
        baselang = compiler.baselang()
        bls = (
          set([basel, baselang.id(), baselang.name()] + baselang.suffixes()) if baselang
          else ['stub'])
        for bl in bls:
          xkey = '%s/%s' % (metal, bl)
          if xkey in COMPILERS:
            raise metax.c.Error(
              '****** Found %s for %s and %s' % (xkey, compiler, COMPILERS[xkey]))
          COMPILERS[xkey] = compiler

      test.compiler = compiler
      test.baselang = compiler.baselang()
      test.metalang = compiler.metalang()
      test.context = test.metalang.context()

      if False:
        print(
          'basel=%s vs %s  metal=%s vs %s' %
          (basel, test.baselang.id(), metal, test.metalang.id()))

      return test.baselang, test.metalang, test.context, test.compiler
    test:
    end method cachedInfo;

    method defineClassAndMethods #:
      Define a simple class (Card) and method (show).
    params:
      var basenora : str #:
        One of the baselang ids, names, aliases or suffixes.
      var context : metax.c.Context = null #:
        The context to use.
      var init_lines : vec<str> = null #:
        If provided, the lines to use as the body of the initializer.
    scope:
      /# IMPORTANT: DO NOT INVOKE metalangFor() or other service test methods
      /# without being certain they will not modify test fields set here.
      /# For example, we set self.baselang() here, but if you invoke
      /# metalangFor() without specifying basel, test.baselang will be tromped
      /# on (replaced with python regardless of what basenora is).
      /# TODO(wmh): This is fragile code ... clean it up.

      if context is None:
        /# We need the baselang to ensure that the compiler has the correct
        /# baselang, used implicitly be various methods in various classes.
        baselang, _, context, _ = self.cachedInfo(basel=basenora)
      else:
        baselang = context.compiler().baselang()
        if baselang.id() != basenora:
          print(
            '****** WARNING: base %s vs %s. This may indicate an error' %
            (basenora, baselang.id()))
      assert baselang

      /# TODO(wmh): Initialized metalang?
      self.baselang = baselang
      self.context = context

      /# An expr to be used as the 'super' attribute of 'initializer' and
      /# 'method2'.
      dummy_attribute = metax.attr.ExprAttribute(None, 'super', None)
      expr = metax.c.Expr.FromStr(
        '(a, b=1, c=false)', attribute=dummy_attribute)

      /# Define a FileConstruct.
      self.filecons = metax.meta.FileConstruct.NewFromData(
        'dummy.meta', test.context, secondaries=[('scope:', [])])

      /# Define a namespace nm.sp
      self.namespace = metax.oopl.NamespaceConstruct.NewFromData(
        'nm.sp', context, parent=self.filecons.attr('scope:'),
        secondaries=[('scope:', [])])

      /# Define a class Card
      /#  - we invoke initParentClasses() to ensure that klass.parentclasses()
      /#    is initialized. Note that this is baselang specific (e.g. we
      /#    have to have the proper baselang instance in the compiler instance).
      klass = metax.oopl.ClassConstruct.NewFromData(
        'Card', context, parent=self.namespace.attr('scope:'),
        secondaries=[('parent', 'metax.root.Object'), ('scope:', [])])
      klass.namespaceIs(self.namespace)
      klass.initParentClasses()
      klass.variantIs('user')
      kscope = klass.attr('scope:')
      kscope.postcountIs(1)
      self.klass = klass
      self.kscope = kscope
      assert klass.baselang() is baselang

      /# Define the metaclass of Card
      metaclass = metax.oopl.ClassConstruct.NewFromData(
        'CardMeta', context,
        secondaries=[('parent', 'metax.root.ObjectMeta'), ('scope:', [])])
      metaclass.initParentClasses()
      metaclass.variantIs('meta')
      self.metaclass = metaclass
      klass.metaclassIs(metaclass)
      metaclass.userclassIs(klass)
      metaclass.underclassIs(klass)

      /# Define a method 'show' with a comment.
      method = metax.oopl.MethodConstruct.NewFromData(
        'show', context, parent=kscope,
        features=[('kind', 'instance')],
        secondaries=[
          ('comment:', ['This is a test', 'of a multiline comment'])
        ],
        precount=1,
      )
      method.myclassIs(klass)
      self.method = method
      method.namespaceIs(self.namespace)

      /# Define a method 'f' with a super.
      MetaType = metax.c.Type.Instance
      params = metax.oopl.ExecutableConstruct.CreateParams(
        [{'var': 'a', 'secondaries': [(':', MetaType('str'))]},
         {'var': 'b',
          'secondaries': [
            (':', MetaType('int')),
            ('=', metax.c.Expr('num', '1', 1)),
          ]},
         {'var': 'c',
          'secondaries': [
            (':', MetaType('bool')),
            ('=', metax.c.Expr('var', 'false', 'false')),
          ]},
        ],
        context)
      method2 = metax.oopl.MethodConstruct.NewFromData(
        'f', context, parent=test.kscope,
        secondaries=[
          (':', MetaType('int')), ('params:', params), ('super', expr)],
        precount=1,
      )
      method2.myclassIs(klass)
      self.method2 = method2
      method2.namespaceIs(self.namespace)

      /# Define an initializer with a super.
      features = [('kind', 'initializer')]
      secondaries = [('super', expr)]
      if init_lines:
        secondaries.append(('scope:', init_lines))
      initializer = metax.oopl.MethodConstruct.NewFromData(
        '__init__', context, parent=kscope,
        features=features, secondaries=secondaries,
        precount=1, termcode=3,
      )
      initializer.myclassIs(klass)
      self.initializer = initializer
      initializer.namespaceIs(self.namespace)

    end method defineClassAndMethods;

  end class TestCase;

end namespace metax.c;
